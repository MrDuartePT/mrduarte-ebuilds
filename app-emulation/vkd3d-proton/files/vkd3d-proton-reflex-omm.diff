diff --git a/include/private/nvapi.h b/include/private/nvapi.h
new file mode 100644
index 00000000..96ced08d
--- /dev/null
+++ b/include/private/nvapi.h
@@ -0,0 +1,2795 @@
+/*****************************************************************************\
+|*                                                                             *|
+|* Copyright (c) 2019-2022, NVIDIA CORPORATION. All rights reserved.           *|
+|*                                                                             *|
+|* Permission is hereby granted, free of charge, to any person obtaining a     *|
+|* copy of this software and associated documentation files (the "Software"),  *|
+|* to deal in the Software without restriction, including without limitation   *|
+|* the rights to use, copy, modify, merge, publish, distribute, sublicense,    *|
+|* and/or sell copies of the Software, and to permit persons to whom the       *|
+|* Software is furnished to do so, subject to the following conditions:        *|
+|*                                                                             *|
+|* The above copyright notice and this permission notice shall be included in  *|
+|* all copies or substantial portions of the Software.                         *|
+|*                                                                             *|
+|* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR  *|
+|* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,    *|
+|* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL    *|
+|* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER  *|
+|* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING     *| 
+|* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER         *|
+|* DEALINGS IN THE SOFTWARE.                                                   *|
+|*                                                                             *|
+|*                                                                             *|
+\*****************************************************************************/
+///////////////////////////////////////////////////////////////////////////////
+//
+// Date: Feb 27, 2023 
+// File: nvapi.h
+//
+// NvAPI provides an interface to NVIDIA devices. This file contains the 
+// interface constants, structure definitions and function prototypes.
+//
+//   Target Profile: Open-Source
+//  Target Platform: windows
+//
+///////////////////////////////////////////////////////////////////////////////
+#ifndef _NVAPI_H
+#define _NVAPI_H
+
+#include "vkd3d_d3d12.h"
+
+#pragma pack(push,8) // Make sure we have consistent structure packings
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+// ====================================================
+// Universal NvAPI Definitions
+// ====================================================
+#ifndef _WIN32
+#define __cdecl
+#endif
+
+// ====================================================
+// SAL related support
+// ====================================================
+
+#ifndef __ecount
+    #define __nvapi_undef__ecount
+    #define __ecount(size)
+#endif
+#ifndef __bcount
+    #define __nvapi_undef__bcount
+    #define __bcount(size)
+#endif
+#ifndef __in
+    #define __nvapi_undef__in
+    #define __in
+#endif
+#ifndef __in_ecount
+    #define __nvapi_undef__in_ecount
+    #define __in_ecount(size)
+#endif
+#ifndef __in_bcount
+    #define __nvapi_undef__in_bcount
+    #define __in_bcount(size)
+#endif
+#ifndef __in_z
+    #define __nvapi_undef__in_z
+    #define __in_z
+#endif
+#ifndef __in_ecount_z
+    #define __nvapi_undef__in_ecount_z
+    #define __in_ecount_z(size)
+#endif
+#ifndef __in_bcount_z
+    #define __nvapi_undef__in_bcount_z
+    #define __in_bcount_z(size)
+#endif
+#ifndef __in_nz
+    #define __nvapi_undef__in_nz
+    #define __in_nz
+#endif
+#ifndef __in_ecount_nz
+    #define __nvapi_undef__in_ecount_nz
+    #define __in_ecount_nz(size)
+#endif
+#ifndef __in_bcount_nz
+    #define __nvapi_undef__in_bcount_nz
+    #define __in_bcount_nz(size)
+#endif
+#ifndef __out
+    #define __nvapi_undef__out
+    #define __out
+#endif
+#ifndef __out_ecount
+    #define __nvapi_undef__out_ecount
+    #define __out_ecount(size)
+#endif
+#ifndef __out_bcount
+    #define __nvapi_undef__out_bcount
+    #define __out_bcount(size)
+#endif
+#ifndef __out_ecount_part
+    #define __nvapi_undef__out_ecount_part
+    #define __out_ecount_part(size,length)
+#endif
+#ifndef __out_bcount_part
+    #define __nvapi_undef__out_bcount_part
+    #define __out_bcount_part(size,length)
+#endif
+#ifndef __out_ecount_full
+    #define __nvapi_undef__out_ecount_full
+    #define __out_ecount_full(size)
+#endif
+#ifndef __out_bcount_full
+    #define __nvapi_undef__out_bcount_full
+    #define __out_bcount_full(size)
+#endif
+#ifndef __out_z
+    #define __nvapi_undef__out_z
+    #define __out_z
+#endif
+#ifndef __out_z_opt
+    #define __nvapi_undef__out_z_opt
+    #define __out_z_opt
+#endif
+#ifndef __out_ecount_z
+    #define __nvapi_undef__out_ecount_z
+    #define __out_ecount_z(size)
+#endif
+#ifndef __out_bcount_z
+    #define __nvapi_undef__out_bcount_z
+    #define __out_bcount_z(size)
+#endif
+#ifndef __out_ecount_part_z
+    #define __nvapi_undef__out_ecount_part_z
+    #define __out_ecount_part_z(size,length)
+#endif
+#ifndef __out_bcount_part_z
+    #define __nvapi_undef__out_bcount_part_z
+    #define __out_bcount_part_z(size,length)
+#endif
+#ifndef __out_ecount_full_z
+    #define __nvapi_undef__out_ecount_full_z
+    #define __out_ecount_full_z(size)
+#endif
+#ifndef __out_bcount_full_z
+    #define __nvapi_undef__out_bcount_full_z
+    #define __out_bcount_full_z(size)
+#endif
+#ifndef __out_nz
+    #define __nvapi_undef__out_nz
+    #define __out_nz
+#endif
+#ifndef __out_nz_opt
+    #define __nvapi_undef__out_nz_opt
+    #define __out_nz_opt
+#endif
+#ifndef __out_ecount_nz
+    #define __nvapi_undef__out_ecount_nz
+    #define __out_ecount_nz(size)
+#endif
+#ifndef __out_bcount_nz
+    #define __nvapi_undef__out_bcount_nz
+    #define __out_bcount_nz(size)
+#endif
+#ifndef __inout
+    #define __nvapi_undef__inout
+    #define __inout
+#endif
+#ifndef __inout_ecount
+    #define __nvapi_undef__inout_ecount
+    #define __inout_ecount(size)
+#endif
+#ifndef __inout_bcount
+    #define __nvapi_undef__inout_bcount
+    #define __inout_bcount(size)
+#endif
+#ifndef __inout_ecount_part
+    #define __nvapi_undef__inout_ecount_part
+    #define __inout_ecount_part(size,length)
+#endif
+#ifndef __inout_bcount_part
+    #define __nvapi_undef__inout_bcount_part
+    #define __inout_bcount_part(size,length)
+#endif
+#ifndef __inout_ecount_full
+    #define __nvapi_undef__inout_ecount_full
+    #define __inout_ecount_full(size)
+#endif
+#ifndef __inout_bcount_full
+    #define __nvapi_undef__inout_bcount_full
+    #define __inout_bcount_full(size)
+#endif
+#ifndef __inout_z
+    #define __nvapi_undef__inout_z
+    #define __inout_z
+#endif
+#ifndef __inout_ecount_z
+    #define __nvapi_undef__inout_ecount_z
+    #define __inout_ecount_z(size)
+#endif
+#ifndef __inout_bcount_z
+    #define __nvapi_undef__inout_bcount_z
+    #define __inout_bcount_z(size)
+#endif
+#ifndef __inout_nz
+    #define __nvapi_undef__inout_nz
+    #define __inout_nz
+#endif
+#ifndef __inout_ecount_nz
+    #define __nvapi_undef__inout_ecount_nz
+    #define __inout_ecount_nz(size)
+#endif
+#ifndef __inout_bcount_nz
+    #define __nvapi_undef__inout_bcount_nz
+    #define __inout_bcount_nz(size)
+#endif
+#ifndef __ecount_opt
+    #define __nvapi_undef__ecount_opt
+    #define __ecount_opt(size)
+#endif
+#ifndef __bcount_opt
+    #define __nvapi_undef__bcount_opt
+    #define __bcount_opt(size)
+#endif
+#ifndef __in_opt
+    #define __nvapi_undef__in_opt
+    #define __in_opt
+#endif
+#ifndef __in_ecount_opt
+    #define __nvapi_undef__in_ecount_opt
+    #define __in_ecount_opt(size)
+#endif
+#ifndef __in_bcount_opt
+    #define __nvapi_undef__in_bcount_opt
+    #define __in_bcount_opt(size)
+#endif
+#ifndef __in_z_opt
+    #define __nvapi_undef__in_z_opt
+    #define __in_z_opt
+#endif
+#ifndef __in_ecount_z_opt
+    #define __nvapi_undef__in_ecount_z_opt
+    #define __in_ecount_z_opt(size)
+#endif
+#ifndef __in_bcount_z_opt
+    #define __nvapi_undef__in_bcount_z_opt
+    #define __in_bcount_z_opt(size)
+#endif
+#ifndef __in_nz_opt
+    #define __nvapi_undef__in_nz_opt
+    #define __in_nz_opt
+#endif
+#ifndef __in_ecount_nz_opt
+    #define __nvapi_undef__in_ecount_nz_opt
+    #define __in_ecount_nz_opt(size)
+#endif
+#ifndef __in_bcount_nz_opt
+    #define __nvapi_undef__in_bcount_nz_opt
+    #define __in_bcount_nz_opt(size)
+#endif
+#ifndef __out_opt
+    #define __nvapi_undef__out_opt
+    #define __out_opt
+#endif
+#ifndef __out_ecount_opt
+    #define __nvapi_undef__out_ecount_opt
+    #define __out_ecount_opt(size)
+#endif
+#ifndef __out_bcount_opt
+    #define __nvapi_undef__out_bcount_opt
+    #define __out_bcount_opt(size)
+#endif
+#ifndef __out_ecount_part_opt
+    #define __nvapi_undef__out_ecount_part_opt
+    #define __out_ecount_part_opt(size,length)
+#endif
+#ifndef __out_bcount_part_opt
+    #define __nvapi_undef__out_bcount_part_opt
+    #define __out_bcount_part_opt(size,length)
+#endif
+#ifndef __out_ecount_full_opt
+    #define __nvapi_undef__out_ecount_full_opt
+    #define __out_ecount_full_opt(size)
+#endif
+#ifndef __out_bcount_full_opt
+    #define __nvapi_undef__out_bcount_full_opt
+    #define __out_bcount_full_opt(size)
+#endif
+#ifndef __out_ecount_z_opt
+    #define __nvapi_undef__out_ecount_z_opt
+    #define __out_ecount_z_opt(size)
+#endif
+#ifndef __out_bcount_z_opt
+    #define __nvapi_undef__out_bcount_z_opt
+    #define __out_bcount_z_opt(size)
+#endif
+#ifndef __out_ecount_part_z_opt
+    #define __nvapi_undef__out_ecount_part_z_opt
+    #define __out_ecount_part_z_opt(size,length)
+#endif
+#ifndef __out_bcount_part_z_opt
+    #define __nvapi_undef__out_bcount_part_z_opt
+    #define __out_bcount_part_z_opt(size,length)
+#endif
+#ifndef __out_ecount_full_z_opt
+    #define __nvapi_undef__out_ecount_full_z_opt
+    #define __out_ecount_full_z_opt(size)
+#endif
+#ifndef __out_bcount_full_z_opt
+    #define __nvapi_undef__out_bcount_full_z_opt
+    #define __out_bcount_full_z_opt(size)
+#endif
+#ifndef __out_ecount_nz_opt
+    #define __nvapi_undef__out_ecount_nz_opt
+    #define __out_ecount_nz_opt(size)
+#endif
+#ifndef __out_bcount_nz_opt
+    #define __nvapi_undef__out_bcount_nz_opt
+    #define __out_bcount_nz_opt(size)
+#endif
+#ifndef __inout_opt
+    #define __nvapi_undef__inout_opt
+    #define __inout_opt
+#endif
+#ifndef __inout_ecount_opt
+    #define __nvapi_undef__inout_ecount_opt
+    #define __inout_ecount_opt(size)
+#endif
+#ifndef __inout_bcount_opt
+    #define __nvapi_undef__inout_bcount_opt
+    #define __inout_bcount_opt(size)
+#endif
+#ifndef __inout_ecount_part_opt
+    #define __nvapi_undef__inout_ecount_part_opt
+    #define __inout_ecount_part_opt(size,length)
+#endif
+#ifndef __inout_bcount_part_opt
+    #define __nvapi_undef__inout_bcount_part_opt
+    #define __inout_bcount_part_opt(size,length)
+#endif
+#ifndef __inout_ecount_full_opt
+    #define __nvapi_undef__inout_ecount_full_opt
+    #define __inout_ecount_full_opt(size)
+#endif
+#ifndef __inout_bcount_full_opt
+    #define __nvapi_undef__inout_bcount_full_opt
+    #define __inout_bcount_full_opt(size)
+#endif
+#ifndef __inout_z_opt
+    #define __nvapi_undef__inout_z_opt
+    #define __inout_z_opt
+#endif
+#ifndef __inout_ecount_z_opt
+    #define __nvapi_undef__inout_ecount_z_opt
+    #define __inout_ecount_z_opt(size)
+#endif
+#ifndef __inout_ecount_z_opt
+    #define __nvapi_undef__inout_ecount_z_opt
+    #define __inout_ecount_z_opt(size)
+#endif
+#ifndef __inout_bcount_z_opt
+    #define __nvapi_undef__inout_bcount_z_opt
+    #define __inout_bcount_z_opt(size)
+#endif
+#ifndef __inout_nz_opt
+    #define __nvapi_undef__inout_nz_opt
+    #define __inout_nz_opt
+#endif
+#ifndef __inout_ecount_nz_opt
+    #define __nvapi_undef__inout_ecount_nz_opt
+    #define __inout_ecount_nz_opt(size)
+#endif
+#ifndef __inout_bcount_nz_opt
+    #define __nvapi_undef__inout_bcount_nz_opt
+    #define __inout_bcount_nz_opt(size)
+#endif
+#ifndef __deref_ecount
+    #define __nvapi_undef__deref_ecount
+    #define __deref_ecount(size)
+#endif
+#ifndef __deref_bcount
+    #define __nvapi_undef__deref_bcount
+    #define __deref_bcount(size)
+#endif
+#ifndef __deref_out
+    #define __nvapi_undef__deref_out
+    #define __deref_out
+#endif
+#ifndef __deref_out_ecount
+    #define __nvapi_undef__deref_out_ecount
+    #define __deref_out_ecount(size)
+#endif
+#ifndef __deref_out_bcount
+    #define __nvapi_undef__deref_out_bcount
+    #define __deref_out_bcount(size)
+#endif
+#ifndef __deref_out_ecount_part
+    #define __nvapi_undef__deref_out_ecount_part
+    #define __deref_out_ecount_part(size,length)
+#endif
+#ifndef __deref_out_bcount_part
+    #define __nvapi_undef__deref_out_bcount_part
+    #define __deref_out_bcount_part(size,length)
+#endif
+#ifndef __deref_out_ecount_full
+    #define __nvapi_undef__deref_out_ecount_full
+    #define __deref_out_ecount_full(size)
+#endif
+#ifndef __deref_out_bcount_full
+    #define __nvapi_undef__deref_out_bcount_full
+    #define __deref_out_bcount_full(size)
+#endif
+#ifndef __deref_out_z
+    #define __nvapi_undef__deref_out_z
+    #define __deref_out_z
+#endif
+#ifndef __deref_out_ecount_z
+    #define __nvapi_undef__deref_out_ecount_z
+    #define __deref_out_ecount_z(size)
+#endif
+#ifndef __deref_out_bcount_z
+    #define __nvapi_undef__deref_out_bcount_z
+    #define __deref_out_bcount_z(size)
+#endif
+#ifndef __deref_out_nz
+    #define __nvapi_undef__deref_out_nz
+    #define __deref_out_nz
+#endif
+#ifndef __deref_out_ecount_nz
+    #define __nvapi_undef__deref_out_ecount_nz
+    #define __deref_out_ecount_nz(size)
+#endif
+#ifndef __deref_out_bcount_nz
+    #define __nvapi_undef__deref_out_bcount_nz
+    #define __deref_out_bcount_nz(size)
+#endif
+#ifndef __deref_inout
+    #define __nvapi_undef__deref_inout
+    #define __deref_inout
+#endif
+#ifndef __deref_inout_z
+    #define __nvapi_undef__deref_inout_z
+    #define __deref_inout_z
+#endif
+#ifndef __deref_inout_ecount
+    #define __nvapi_undef__deref_inout_ecount
+    #define __deref_inout_ecount(size)
+#endif
+#ifndef __deref_inout_bcount
+    #define __nvapi_undef__deref_inout_bcount
+    #define __deref_inout_bcount(size)
+#endif
+#ifndef __deref_inout_ecount_part
+    #define __nvapi_undef__deref_inout_ecount_part
+    #define __deref_inout_ecount_part(size,length)
+#endif
+#ifndef __deref_inout_bcount_part
+    #define __nvapi_undef__deref_inout_bcount_part
+    #define __deref_inout_bcount_part(size,length)
+#endif
+#ifndef __deref_inout_ecount_full
+    #define __nvapi_undef__deref_inout_ecount_full
+    #define __deref_inout_ecount_full(size)
+#endif
+#ifndef __deref_inout_bcount_full
+    #define __nvapi_undef__deref_inout_bcount_full
+    #define __deref_inout_bcount_full(size)
+#endif
+#ifndef __deref_inout_z
+    #define __nvapi_undef__deref_inout_z
+    #define __deref_inout_z
+#endif
+#ifndef __deref_inout_ecount_z
+    #define __nvapi_undef__deref_inout_ecount_z
+    #define __deref_inout_ecount_z(size)
+#endif
+#ifndef __deref_inout_bcount_z
+    #define __nvapi_undef__deref_inout_bcount_z
+    #define __deref_inout_bcount_z(size)
+#endif
+#ifndef __deref_inout_nz
+    #define __nvapi_undef__deref_inout_nz
+    #define __deref_inout_nz
+#endif
+#ifndef __deref_inout_ecount_nz
+    #define __nvapi_undef__deref_inout_ecount_nz
+    #define __deref_inout_ecount_nz(size)
+#endif
+#ifndef __deref_inout_bcount_nz
+    #define __nvapi_undef__deref_inout_bcount_nz
+    #define __deref_inout_bcount_nz(size)
+#endif
+#ifndef __deref_ecount_opt
+    #define __nvapi_undef__deref_ecount_opt
+    #define __deref_ecount_opt(size)
+#endif
+#ifndef __deref_bcount_opt
+    #define __nvapi_undef__deref_bcount_opt
+    #define __deref_bcount_opt(size)
+#endif
+#ifndef __deref_out_opt
+    #define __nvapi_undef__deref_out_opt
+    #define __deref_out_opt
+#endif
+#ifndef __deref_out_ecount_opt
+    #define __nvapi_undef__deref_out_ecount_opt
+    #define __deref_out_ecount_opt(size)
+#endif
+#ifndef __deref_out_bcount_opt
+    #define __nvapi_undef__deref_out_bcount_opt
+    #define __deref_out_bcount_opt(size)
+#endif
+#ifndef __deref_out_ecount_part_opt
+    #define __nvapi_undef__deref_out_ecount_part_opt
+    #define __deref_out_ecount_part_opt(size,length)
+#endif
+#ifndef __deref_out_bcount_part_opt
+    #define __nvapi_undef__deref_out_bcount_part_opt
+    #define __deref_out_bcount_part_opt(size,length)
+#endif
+#ifndef __deref_out_ecount_full_opt
+    #define __nvapi_undef__deref_out_ecount_full_opt
+    #define __deref_out_ecount_full_opt(size)
+#endif
+#ifndef __deref_out_bcount_full_opt
+    #define __nvapi_undef__deref_out_bcount_full_opt
+    #define __deref_out_bcount_full_opt(size)
+#endif
+#ifndef __deref_out_z_opt
+    #define __nvapi_undef__deref_out_z_opt
+    #define __deref_out_z_opt
+#endif
+#ifndef __deref_out_ecount_z_opt
+    #define __nvapi_undef__deref_out_ecount_z_opt
+    #define __deref_out_ecount_z_opt(size)
+#endif
+#ifndef __deref_out_bcount_z_opt
+    #define __nvapi_undef__deref_out_bcount_z_opt
+    #define __deref_out_bcount_z_opt(size)
+#endif
+#ifndef __deref_out_nz_opt
+    #define __nvapi_undef__deref_out_nz_opt
+    #define __deref_out_nz_opt
+#endif
+#ifndef __deref_out_ecount_nz_opt
+    #define __nvapi_undef__deref_out_ecount_nz_opt
+    #define __deref_out_ecount_nz_opt(size)
+#endif
+#ifndef __deref_out_bcount_nz_opt
+    #define __nvapi_undef__deref_out_bcount_nz_opt
+    #define __deref_out_bcount_nz_opt(size)
+#endif
+#ifndef __deref_inout_opt
+    #define __nvapi_undef__deref_inout_opt
+    #define __deref_inout_opt
+#endif
+#ifndef __deref_inout_ecount_opt
+    #define __nvapi_undef__deref_inout_ecount_opt
+    #define __deref_inout_ecount_opt(size)
+#endif
+#ifndef __deref_inout_bcount_opt
+    #define __nvapi_undef__deref_inout_bcount_opt
+    #define __deref_inout_bcount_opt(size)
+#endif
+#ifndef __deref_inout_ecount_part_opt
+    #define __nvapi_undef__deref_inout_ecount_part_opt
+    #define __deref_inout_ecount_part_opt(size,length)
+#endif
+#ifndef __deref_inout_bcount_part_opt
+    #define __nvapi_undef__deref_inout_bcount_part_opt
+    #define __deref_inout_bcount_part_opt(size,length)
+#endif
+#ifndef __deref_inout_ecount_full_opt
+    #define __nvapi_undef__deref_inout_ecount_full_opt
+    #define __deref_inout_ecount_full_opt(size)
+#endif
+#ifndef __deref_inout_bcount_full_opt
+    #define __nvapi_undef__deref_inout_bcount_full_opt
+    #define __deref_inout_bcount_full_opt(size)
+#endif
+#ifndef __deref_inout_z_opt
+    #define __nvapi_undef__deref_inout_z_opt
+    #define __deref_inout_z_opt
+#endif
+#ifndef __deref_inout_ecount_z_opt
+    #define __nvapi_undef__deref_inout_ecount_z_opt
+    #define __deref_inout_ecount_z_opt(size)
+#endif
+#ifndef __deref_inout_bcount_z_opt
+    #define __nvapi_undef__deref_inout_bcount_z_opt
+    #define __deref_inout_bcount_z_opt(size)
+#endif
+#ifndef __deref_inout_nz_opt
+    #define __nvapi_undef__deref_inout_nz_opt
+    #define __deref_inout_nz_opt
+#endif
+#ifndef __deref_inout_ecount_nz_opt
+    #define __nvapi_undef__deref_inout_ecount_nz_opt
+    #define __deref_inout_ecount_nz_opt(size)
+#endif
+#ifndef __deref_inout_bcount_nz_opt
+    #define __nvapi_undef__deref_inout_bcount_nz_opt
+    #define __deref_inout_bcount_nz_opt(size)
+#endif
+#ifndef __deref_opt_ecount
+    #define __nvapi_undef__deref_opt_ecount
+    #define __deref_opt_ecount(size)
+#endif
+#ifndef __deref_opt_bcount
+    #define __nvapi_undef__deref_opt_bcount
+    #define __deref_opt_bcount(size)
+#endif
+#ifndef __deref_opt_out
+    #define __nvapi_undef__deref_opt_out
+    #define __deref_opt_out
+#endif
+#ifndef __deref_opt_out_z
+    #define __nvapi_undef__deref_opt_out_z
+    #define __deref_opt_out_z
+#endif
+#ifndef __deref_opt_out_ecount
+    #define __nvapi_undef__deref_opt_out_ecount
+    #define __deref_opt_out_ecount(size)
+#endif
+#ifndef __deref_opt_out_bcount
+    #define __nvapi_undef__deref_opt_out_bcount
+    #define __deref_opt_out_bcount(size)
+#endif
+#ifndef __deref_opt_out_ecount_part
+    #define __nvapi_undef__deref_opt_out_ecount_part
+    #define __deref_opt_out_ecount_part(size,length)
+#endif
+#ifndef __deref_opt_out_bcount_part
+    #define __nvapi_undef__deref_opt_out_bcount_part
+    #define __deref_opt_out_bcount_part(size,length)
+#endif
+#ifndef __deref_opt_out_ecount_full
+    #define __nvapi_undef__deref_opt_out_ecount_full
+    #define __deref_opt_out_ecount_full(size)
+#endif
+#ifndef __deref_opt_out_bcount_full
+    #define __nvapi_undef__deref_opt_out_bcount_full
+    #define __deref_opt_out_bcount_full(size)
+#endif
+#ifndef __deref_opt_inout
+    #define __nvapi_undef__deref_opt_inout
+    #define __deref_opt_inout
+#endif
+#ifndef __deref_opt_inout_ecount
+    #define __nvapi_undef__deref_opt_inout_ecount
+    #define __deref_opt_inout_ecount(size)
+#endif
+#ifndef __deref_opt_inout_bcount
+    #define __nvapi_undef__deref_opt_inout_bcount
+    #define __deref_opt_inout_bcount(size)
+#endif
+#ifndef __deref_opt_inout_ecount_part
+    #define __nvapi_undef__deref_opt_inout_ecount_part
+    #define __deref_opt_inout_ecount_part(size,length)
+#endif
+#ifndef __deref_opt_inout_bcount_part
+    #define __nvapi_undef__deref_opt_inout_bcount_part
+    #define __deref_opt_inout_bcount_part(size,length)
+#endif
+#ifndef __deref_opt_inout_ecount_full
+    #define __nvapi_undef__deref_opt_inout_ecount_full
+    #define __deref_opt_inout_ecount_full(size)
+#endif
+#ifndef __deref_opt_inout_bcount_full
+    #define __nvapi_undef__deref_opt_inout_bcount_full
+    #define __deref_opt_inout_bcount_full(size)
+#endif
+#ifndef __deref_opt_inout_z
+    #define __nvapi_undef__deref_opt_inout_z
+    #define __deref_opt_inout_z
+#endif
+#ifndef __deref_opt_inout_ecount_z
+    #define __nvapi_undef__deref_opt_inout_ecount_z
+    #define __deref_opt_inout_ecount_z(size)
+#endif
+#ifndef __deref_opt_inout_bcount_z
+    #define __nvapi_undef__deref_opt_inout_bcount_z
+    #define __deref_opt_inout_bcount_z(size)
+#endif
+#ifndef __deref_opt_inout_nz
+    #define __nvapi_undef__deref_opt_inout_nz
+    #define __deref_opt_inout_nz
+#endif
+#ifndef __deref_opt_inout_ecount_nz
+    #define __nvapi_undef__deref_opt_inout_ecount_nz
+    #define __deref_opt_inout_ecount_nz(size)
+#endif
+#ifndef __deref_opt_inout_bcount_nz
+    #define __nvapi_undef__deref_opt_inout_bcount_nz
+    #define __deref_opt_inout_bcount_nz(size)
+#endif
+#ifndef __deref_opt_ecount_opt
+    #define __nvapi_undef__deref_opt_ecount_opt
+    #define __deref_opt_ecount_opt(size)
+#endif
+#ifndef __deref_opt_bcount_opt
+    #define __nvapi_undef__deref_opt_bcount_opt
+    #define __deref_opt_bcount_opt(size)
+#endif
+#ifndef __deref_opt_out_opt
+    #define __nvapi_undef__deref_opt_out_opt
+    #define __deref_opt_out_opt
+#endif
+#ifndef __deref_opt_out_ecount_opt
+    #define __nvapi_undef__deref_opt_out_ecount_opt
+    #define __deref_opt_out_ecount_opt(size)
+#endif
+#ifndef __deref_opt_out_bcount_opt
+    #define __nvapi_undef__deref_opt_out_bcount_opt
+    #define __deref_opt_out_bcount_opt(size)
+#endif
+#ifndef __deref_opt_out_ecount_part_opt
+    #define __nvapi_undef__deref_opt_out_ecount_part_opt
+    #define __deref_opt_out_ecount_part_opt(size,length)
+#endif
+#ifndef __deref_opt_out_bcount_part_opt
+    #define __nvapi_undef__deref_opt_out_bcount_part_opt
+    #define __deref_opt_out_bcount_part_opt(size,length)
+#endif
+#ifndef __deref_opt_out_ecount_full_opt
+    #define __nvapi_undef__deref_opt_out_ecount_full_opt
+    #define __deref_opt_out_ecount_full_opt(size)
+#endif
+#ifndef __deref_opt_out_bcount_full_opt
+    #define __nvapi_undef__deref_opt_out_bcount_full_opt
+    #define __deref_opt_out_bcount_full_opt(size)
+#endif
+#ifndef __deref_opt_out_z_opt
+    #define __nvapi_undef__deref_opt_out_z_opt
+    #define __deref_opt_out_z_opt
+#endif
+#ifndef __deref_opt_out_ecount_z_opt
+    #define __nvapi_undef__deref_opt_out_ecount_z_opt
+    #define __deref_opt_out_ecount_z_opt(size)
+#endif
+#ifndef __deref_opt_out_bcount_z_opt
+    #define __nvapi_undef__deref_opt_out_bcount_z_opt
+    #define __deref_opt_out_bcount_z_opt(size)
+#endif
+#ifndef __deref_opt_out_nz_opt
+    #define __nvapi_undef__deref_opt_out_nz_opt
+    #define __deref_opt_out_nz_opt
+#endif
+#ifndef __deref_opt_out_ecount_nz_opt
+    #define __nvapi_undef__deref_opt_out_ecount_nz_opt
+    #define __deref_opt_out_ecount_nz_opt(size)
+#endif
+#ifndef __deref_opt_out_bcount_nz_opt
+    #define __nvapi_undef__deref_opt_out_bcount_nz_opt
+    #define __deref_opt_out_bcount_nz_opt(size)
+#endif
+#ifndef __deref_opt_inout_opt
+    #define __nvapi_undef__deref_opt_inout_opt
+    #define __deref_opt_inout_opt
+#endif
+#ifndef __deref_opt_inout_ecount_opt
+    #define __nvapi_undef__deref_opt_inout_ecount_opt
+    #define __deref_opt_inout_ecount_opt(size)
+#endif
+#ifndef __deref_opt_inout_bcount_opt
+    #define __nvapi_undef__deref_opt_inout_bcount_opt
+    #define __deref_opt_inout_bcount_opt(size)
+#endif
+#ifndef __deref_opt_inout_ecount_part_opt
+    #define __nvapi_undef__deref_opt_inout_ecount_part_opt
+    #define __deref_opt_inout_ecount_part_opt(size,length)
+#endif
+#ifndef __deref_opt_inout_bcount_part_opt
+    #define __nvapi_undef__deref_opt_inout_bcount_part_opt
+    #define __deref_opt_inout_bcount_part_opt(size,length)
+#endif
+#ifndef __deref_opt_inout_ecount_full_opt
+    #define __nvapi_undef__deref_opt_inout_ecount_full_opt
+    #define __deref_opt_inout_ecount_full_opt(size)
+#endif
+#ifndef __deref_opt_inout_bcount_full_opt
+    #define __nvapi_undef__deref_opt_inout_bcount_full_opt
+    #define __deref_opt_inout_bcount_full_opt(size)
+#endif
+#ifndef __deref_opt_inout_z_opt
+    #define __nvapi_undef__deref_opt_inout_z_opt
+    #define __deref_opt_inout_z_opt
+#endif
+#ifndef __deref_opt_inout_ecount_z_opt
+    #define __nvapi_undef__deref_opt_inout_ecount_z_opt
+    #define __deref_opt_inout_ecount_z_opt(size)
+#endif
+#ifndef __deref_opt_inout_bcount_z_opt
+    #define __nvapi_undef__deref_opt_inout_bcount_z_opt
+    #define __deref_opt_inout_bcount_z_opt(size)
+#endif
+#ifndef __deref_opt_inout_nz_opt
+    #define __nvapi_undef__deref_opt_inout_nz_opt
+    #define __deref_opt_inout_nz_opt
+#endif
+#ifndef __deref_opt_inout_ecount_nz_opt
+    #define __nvapi_undef__deref_opt_inout_ecount_nz_opt
+    #define __deref_opt_inout_ecount_nz_opt(size)
+#endif
+#ifndef __deref_opt_inout_bcount_nz_opt
+    #define __nvapi_undef__deref_opt_inout_bcount_nz_opt
+    #define __deref_opt_inout_bcount_nz_opt(size)
+#endif
+#ifndef __success
+    #define __nvapi_success
+    #define __success(epxr)
+#endif
+#ifndef _Ret_notnull_
+    #define __nvapi__Ret_notnull_
+    #define _Ret_notnull_
+#endif
+#ifndef _Post_writable_byte_size_
+    #define __nvapi__Post_writable_byte_size_
+    #define _Post_writable_byte_size_(n)
+#endif
+#ifndef _Outptr_ 
+    #define __nvapi_Outptr_ 
+    #define _Outptr_ 
+#endif
+
+
+#define NVAPI_INTERFACE extern __success(return == NVAPI_OK) NvAPI_Status __cdecl
+
+#if (defined(WIN32) || defined(_WIN32)) && defined(_MSC_VER) && (_MSC_VER > 1399) && !defined(NVAPI_INTERNAL) && !defined(NVAPI_DEPRECATED_OLD)
+#ifndef __nvapi_deprecated_function
+#define __nvapi_deprecated_function(message) __declspec(deprecated(message))
+#endif
+#ifndef __nvapi_deprecated_datatype
+#define __nvapi_deprecated_datatype(FirstRelease) __declspec(deprecated("Do not use this data type - it is deprecated in release " #FirstRelease "."))
+#endif
+#else
+#ifndef __nvapi_deprecated_function
+#define __nvapi_deprecated_function(message)
+#endif
+#ifndef __nvapi_deprecated_datatype
+#define __nvapi_deprecated_datatype(FirstRelease)
+#endif
+#endif
+
+
+/* 64-bit types for compilers that support them, plus some obsolete variants */
+#if defined(__GNUC__) || defined(__arm) || defined(__IAR_SYSTEMS_ICC__) || defined(__ghs__) || defined(_WIN64)
+typedef unsigned long long NvU64; /* 0 to 18446744073709551615  */
+typedef long long          NvS64; /* -9223372036854775808 to 9223372036854775807  */
+#else
+typedef unsigned __int64   NvU64; /* 0 to 18446744073709551615  */
+typedef __int64            NvS64; /* -9223372036854775808 to 9223372036854775807  */
+#endif
+
+// mac os 32-bit still needs this
+#if (defined(macintosh) || defined(__APPLE__)) && !defined(__LP64__)
+typedef signed long        NvS32; /* -2147483648 to 2147483647  */   
+#else
+typedef signed int         NvS32; /* -2147483648 to 2147483647 */  
+#endif
+
+#ifndef __unix
+// mac os 32-bit still needs this
+#if ( (defined(macintosh) && defined(__LP64__) && (__NVAPI_RESERVED0__)) || \
+      (!defined(macintosh) && defined(__NVAPI_RESERVED0__)) ) 
+typedef unsigned int       NvU32; /* 0 to 4294967295                         */
+#else
+typedef unsigned long      NvU32; /* 0 to 4294967295                         */
+#endif
+#else
+typedef unsigned int       NvU32; /* 0 to 4294967295                         */
+#endif
+
+typedef unsigned long    temp_NvU32; /* 0 to 4294967295                         */
+typedef signed   short   NvS16;
+typedef unsigned short   NvU16;
+typedef unsigned char    NvU8;
+typedef signed   char    NvS8;
+typedef float            NvF32;
+typedef double           NvF64;
+
+/*!
+ * Macro to convert NvU32 to NvF32.
+ */
+#define NvU32TONvF32(_pData) *(NvF32 *)(_pData)
+/*!
+ * Macro to convert NvF32 to NvU32.
+ */
+#define NvF32TONvU32(_pData) *(NvU32 *)(_pData)
+
+/* Boolean type */
+typedef NvU8 NvBool;
+#define NV_TRUE           ((NvBool)(0 == 0))
+#define NV_FALSE          ((NvBool)(0 != 0))
+
+typedef struct _NV_RECT
+{
+    NvU32    left;
+    NvU32    top;
+    NvU32    right;
+    NvU32    bottom;
+} NV_RECT;
+
+
+#define NV_DECLARE_HANDLE(name) struct name##__ { int unused; }; typedef struct name##__ *name
+
+//! \addtogroup nvapihandles
+//! NVAPI Handles - These handles are retrieved from various calls and passed in to others in NvAPI
+//!                 These are meant to be opaque types.  Do not assume they correspond to indices, HDCs,
+//!                 display indexes or anything else.
+//!
+//!                 Most handles remain valid until a display re-configuration (display mode set) or GPU
+//!                 reconfiguration (going into or out of SLI modes) occurs.  If NVAPI_HANDLE_INVALIDATED
+//!                 is received by an app, it should discard all handles, and re-enumerate them.
+//! @{  
+NV_DECLARE_HANDLE(NvLogicalGpuHandle);             //!< One or more physical GPUs acting in concert (SLI)
+NV_DECLARE_HANDLE(NvPhysicalGpuHandle);            //!< A single physical GPU
+NV_DECLARE_HANDLE(NvDisplayHandle);                //!< Display Device driven by NVIDIA GPU(s) (an attached display)
+NV_DECLARE_HANDLE(NvMonitorHandle);                //!< Monitor handle
+NV_DECLARE_HANDLE(NvUnAttachedDisplayHandle);      //!< Unattached Display Device driven by NVIDIA GPU(s)
+NV_DECLARE_HANDLE(NvVisualComputingDeviceHandle);  //!< A handle to a Visual Computing Device
+NV_DECLARE_HANDLE(NvEventHandle);                  //!< A handle to an event registration instance
+
+
+NV_DECLARE_HANDLE(NvHICHandle);                    //!< A handle to a Host Interface Card
+NV_DECLARE_HANDLE(NvGSyncDeviceHandle);            //!< A handle to a Sync device
+NV_DECLARE_HANDLE(NvVioHandle);                    //!< A handle to an SDI device
+NV_DECLARE_HANDLE(NvTransitionHandle);             //!< A handle to address a single transition request
+NV_DECLARE_HANDLE(NvAudioHandle);                  //!< NVIDIA HD Audio Device
+NV_DECLARE_HANDLE(Nv3DVPContextHandle);            //!< A handle for a 3D Vision Pro (3DVP) context
+NV_DECLARE_HANDLE(Nv3DVPTransceiverHandle);        //!< A handle for a 3DVP RF transceiver
+NV_DECLARE_HANDLE(Nv3DVPGlassesHandle);            //!< A handle for a pair of 3DVP RF shutter glasses
+NV_DECLARE_HANDLE(NvPcfClientHandle);              //!< A handle for NVPCF clients
+
+typedef void* StereoHandle;                        //!< A stereo handle, that corresponds to the device interface
+
+NV_DECLARE_HANDLE(NvSourceHandle);                 //!< Unique source handle on the system
+NV_DECLARE_HANDLE(NvTargetHandle);                 //!< Unique target handle on the system
+NV_DECLARE_HANDLE(NVDX_SwapChainHandle);           //!< DirectX SwapChain objects
+static const NVDX_SwapChainHandle NVDX_SWAPCHAIN_NONE = 0;
+NV_DECLARE_HANDLE(NvPresentBarrierClientHandle);   //!< PresentBarrier client object
+//! @}
+
+//! \ingroup nvapihandles
+//! @{
+#define NVAPI_DEFAULT_HANDLE        0
+#define NV_BIT(x)    (1 << (x)) 
+//! @}
+
+
+
+//! \addtogroup nvapitypes
+//! @{
+#define NVAPI_GENERIC_STRING_MAX    4096
+#define NVAPI_LONG_STRING_MAX       256
+#define NVAPI_SHORT_STRING_MAX      64
+
+typedef struct 
+{
+    NvS32   sX;
+    NvS32   sY;
+    NvS32   sWidth;
+    NvS32   sHeight;
+} NvSBox;
+
+#ifndef NvGUID_Defined
+#define NvGUID_Defined
+
+typedef struct
+{
+    NvU32 data1;
+    NvU16 data2;
+    NvU16 data3;
+    NvU8  data4[8];
+} NvGUID, NvLUID;
+
+
+#endif //#ifndef NvGUID_Defined
+#define NVAPI_MAX_PHYSICAL_GPUS             64
+
+
+#define NVAPI_MAX_PHYSICAL_BRIDGES          100
+#define NVAPI_PHYSICAL_GPUS                 32
+#define NVAPI_MAX_LOGICAL_GPUS              64
+#define NVAPI_MAX_AVAILABLE_GPU_TOPOLOGIES  256
+#define NVAPI_MAX_AVAILABLE_SLI_GROUPS      256
+#define NVAPI_MAX_GPU_TOPOLOGIES            NVAPI_MAX_PHYSICAL_GPUS
+#define NVAPI_MAX_GPU_PER_TOPOLOGY          8
+#define NVAPI_MAX_DISPLAY_HEADS             2
+#define NVAPI_ADVANCED_DISPLAY_HEADS        4
+#define NVAPI_MAX_DISPLAYS                  NVAPI_PHYSICAL_GPUS * NVAPI_ADVANCED_DISPLAY_HEADS
+#define NVAPI_MAX_ACPI_IDS                  16
+#define NVAPI_MAX_VIEW_MODES                8
+
+
+#define NVAPI_SYSTEM_MAX_HWBCS              128
+#define NVAPI_SYSTEM_HWBC_INVALID_ID        0xffffffff
+
+#define NVAPI_SYSTEM_MAX_DISPLAYS           NVAPI_MAX_PHYSICAL_GPUS * NV_MAX_HEADS
+#define NV_MAX_HEADS                        4   //!< Maximum heads, each with NVAPI_DESKTOP_RES resolution
+#define NVAPI_MAX_HEADS_PER_GPU             32
+#define NV_MAX_VID_STREAMS      4   //!< Maximum number of input video streams, each with a #NVAPI_VIDEO_SRC_INFO
+#define NV_MAX_VID_STREAMS_EX  20   //!< Increasing MAX no. of input video streams, each with a #NVAPI_VIDEO_SRC_INFO
+#define NV_MAX_VID_PROFILES     4   //!< Maximum number of output video profiles supported
+
+#define NVAPI_MAX_AUDIO_DEVICES             16
+
+
+typedef char NvAPI_String[NVAPI_GENERIC_STRING_MAX];
+typedef char NvAPI_LongString[NVAPI_LONG_STRING_MAX];
+typedef char NvAPI_ShortString[NVAPI_SHORT_STRING_MAX];
+typedef NvU16 NvAPI_UnicodeShortString[NVAPI_SHORT_STRING_MAX];
+//! @}
+
+
+// =========================================================================================
+//!  NvAPI Version Definition \n
+//!  Maintain per structure specific version define using the MAKE_NVAPI_VERSION macro. \n
+//!  Usage: #define NV_GENLOCK_STATUS_VER  MAKE_NVAPI_VERSION(NV_GENLOCK_STATUS, 1)
+//!  \ingroup nvapitypes
+// =========================================================================================
+#define MAKE_NVAPI_VERSION(typeName,ver) (NvU32)(sizeof(typeName) | ((ver)<<16))
+
+//!  \ingroup nvapitypes
+#define GET_NVAPI_VERSION(ver) (NvU32)((ver)>>16)
+
+//!  \ingroup nvapitypes
+#define GET_NVAPI_SIZE(ver) (NvU32)((ver) & 0xffff)
+
+
+// ====================================================
+//! NvAPI Status Values
+//!   All NvAPI functions return one of these codes.
+//!   \ingroup nvapistatus 
+// ====================================================
+
+
+typedef enum _NvAPI_Status
+{
+    NVAPI_OK                                    =  0,      //!< Success. Request is completed.
+    NVAPI_ERROR                                 = -1,      //!< Generic error
+    NVAPI_LIBRARY_NOT_FOUND                     = -2,      //!< NVAPI support library cannot be loaded.
+    NVAPI_NO_IMPLEMENTATION                     = -3,      //!< not implemented in current driver installation
+    NVAPI_API_NOT_INITIALIZED                   = -4,      //!< NvAPI_Initialize has not been called (successfully)
+    NVAPI_INVALID_ARGUMENT                      = -5,      //!< The argument/parameter value is not valid or NULL.
+    NVAPI_NVIDIA_DEVICE_NOT_FOUND               = -6,      //!< No NVIDIA display driver, or NVIDIA GPU driving a display, was found.
+    NVAPI_END_ENUMERATION                       = -7,      //!< No more items to enumerate
+    NVAPI_INVALID_HANDLE                        = -8,      //!< Invalid handle
+    NVAPI_INCOMPATIBLE_STRUCT_VERSION           = -9,      //!< An argument's structure version is not supported
+    NVAPI_HANDLE_INVALIDATED                    = -10,     //!< The handle is no longer valid (likely due to GPU or display re-configuration)
+    NVAPI_OPENGL_CONTEXT_NOT_CURRENT            = -11,     //!< No NVIDIA OpenGL context is current (but needs to be)
+    NVAPI_INVALID_POINTER                       = -14,     //!< An invalid pointer, usually NULL, was passed as a parameter
+    NVAPI_NO_GL_EXPERT                          = -12,     //!< OpenGL Expert is not supported by the current drivers
+    NVAPI_INSTRUMENTATION_DISABLED              = -13,     //!< OpenGL Expert is supported, but driver instrumentation is currently disabled
+    NVAPI_NO_GL_NSIGHT                          = -15,     //!< OpenGL does not support Nsight
+
+    NVAPI_EXPECTED_LOGICAL_GPU_HANDLE           = -100,    //!< Expected a logical GPU handle for one or more parameters
+    NVAPI_EXPECTED_PHYSICAL_GPU_HANDLE          = -101,    //!< Expected a physical GPU handle for one or more parameters
+    NVAPI_EXPECTED_DISPLAY_HANDLE               = -102,    //!< Expected an NV display handle for one or more parameters
+    NVAPI_INVALID_COMBINATION                   = -103,    //!< The combination of parameters is not valid. 
+    NVAPI_NOT_SUPPORTED                         = -104,    //!< Requested feature is not supported in the selected GPU
+    NVAPI_PORTID_NOT_FOUND                      = -105,    //!< No port ID was found for the I2C transaction
+    NVAPI_EXPECTED_UNATTACHED_DISPLAY_HANDLE    = -106,    //!< Expected an unattached display handle as one of the input parameters.
+    NVAPI_INVALID_PERF_LEVEL                    = -107,    //!< Invalid perf level 
+    NVAPI_DEVICE_BUSY                           = -108,    //!< Device is busy; request not fulfilled
+    NVAPI_NV_PERSIST_FILE_NOT_FOUND             = -109,    //!< NV persist file is not found
+    NVAPI_PERSIST_DATA_NOT_FOUND                = -110,    //!< NV persist data is not found
+    NVAPI_EXPECTED_TV_DISPLAY                   = -111,    //!< Expected a TV output display
+    NVAPI_EXPECTED_TV_DISPLAY_ON_DCONNECTOR     = -112,    //!< Expected a TV output on the D Connector - HDTV_EIAJ4120.
+    NVAPI_NO_ACTIVE_SLI_TOPOLOGY                = -113,    //!< SLI is not active on this device.
+    NVAPI_SLI_RENDERING_MODE_NOTALLOWED         = -114,    //!< Setup of SLI rendering mode is not possible right now.
+    NVAPI_EXPECTED_DIGITAL_FLAT_PANEL           = -115,    //!< Expected a digital flat panel.
+    NVAPI_ARGUMENT_EXCEED_MAX_SIZE              = -116,    //!< Argument exceeds the expected size.
+    NVAPI_DEVICE_SWITCHING_NOT_ALLOWED          = -117,    //!< Inhibit is ON due to one of the flags in NV_GPU_DISPLAY_CHANGE_INHIBIT or SLI active.
+    NVAPI_TESTING_CLOCKS_NOT_SUPPORTED          = -118,    //!< Testing of clocks is not supported.
+    NVAPI_UNKNOWN_UNDERSCAN_CONFIG              = -119,    //!< The specified underscan config is from an unknown source (e.g. INF)
+    NVAPI_TIMEOUT_RECONFIGURING_GPU_TOPO        = -120,    //!< Timeout while reconfiguring GPUs
+    NVAPI_DATA_NOT_FOUND                        = -121,    //!< Requested data was not found
+    NVAPI_EXPECTED_ANALOG_DISPLAY               = -122,    //!< Expected an analog display
+    NVAPI_NO_VIDLINK                            = -123,    //!< No SLI video bridge is present
+    NVAPI_REQUIRES_REBOOT                       = -124,    //!< NVAPI requires a reboot for the settings to take effect
+    NVAPI_INVALID_HYBRID_MODE                   = -125,    //!< The function is not supported with the current Hybrid mode.
+    NVAPI_MIXED_TARGET_TYPES                    = -126,    //!< The target types are not all the same
+    NVAPI_SYSWOW64_NOT_SUPPORTED                = -127,    //!< The function is not supported from 32-bit on a 64-bit system.
+    NVAPI_IMPLICIT_SET_GPU_TOPOLOGY_CHANGE_NOT_ALLOWED = -128,    //!< There is no implicit GPU topology active. Use NVAPI_SetHybridMode to change topology.
+    NVAPI_REQUEST_USER_TO_CLOSE_NON_MIGRATABLE_APPS = -129,      //!< Prompt the user to close all non-migratable applications.    
+    NVAPI_OUT_OF_MEMORY                         = -130,    //!< Could not allocate sufficient memory to complete the call.
+    NVAPI_WAS_STILL_DRAWING                     = -131,    //!< The previous operation that is transferring information to or from this surface is incomplete.
+    NVAPI_FILE_NOT_FOUND                        = -132,    //!< The file was not found.
+    NVAPI_TOO_MANY_UNIQUE_STATE_OBJECTS         = -133,    //!< There are too many unique instances of a particular type of state object.
+    NVAPI_INVALID_CALL                          = -134,    //!< The method call is invalid. For example, a method's parameter may not be a valid pointer.
+    NVAPI_D3D10_1_LIBRARY_NOT_FOUND             = -135,    //!< d3d10_1.dll cannot be loaded.
+    NVAPI_FUNCTION_NOT_FOUND                    = -136,    //!< Couldn't find the function in the loaded DLL.
+    NVAPI_INVALID_USER_PRIVILEGE                = -137,    //!< The application will require Administrator privileges to access this API.
+	                                                       //!< The application can be elevated to a higher permission level by selecting "Run as Administrator".
+    NVAPI_EXPECTED_NON_PRIMARY_DISPLAY_HANDLE   = -138,    //!< The handle corresponds to GDIPrimary.
+    NVAPI_EXPECTED_COMPUTE_GPU_HANDLE           = -139,    //!< Setting Physx GPU requires that the GPU is compute-capable.
+    NVAPI_STEREO_NOT_INITIALIZED                = -140,    //!< The Stereo part of NVAPI failed to initialize completely. Check if the stereo driver is installed.
+    NVAPI_STEREO_REGISTRY_ACCESS_FAILED         = -141,    //!< Access to stereo-related registry keys or values has failed.
+    NVAPI_STEREO_REGISTRY_PROFILE_TYPE_NOT_SUPPORTED = -142, //!< The given registry profile type is not supported.
+    NVAPI_STEREO_REGISTRY_VALUE_NOT_SUPPORTED   = -143,    //!< The given registry value is not supported.
+    NVAPI_STEREO_NOT_ENABLED                    = -144,    //!< Stereo is not enabled and the function needed it to execute completely.
+    NVAPI_STEREO_NOT_TURNED_ON                  = -145,    //!< Stereo is not turned on and the function needed it to execute completely.
+    NVAPI_STEREO_INVALID_DEVICE_INTERFACE       = -146,    //!< Invalid device interface.
+    NVAPI_STEREO_PARAMETER_OUT_OF_RANGE         = -147,    //!< Separation percentage or JPEG image capture quality is out of [0-100] range.
+    NVAPI_STEREO_FRUSTUM_ADJUST_MODE_NOT_SUPPORTED = -148, //!< The given frustum adjust mode is not supported.
+    NVAPI_TOPO_NOT_POSSIBLE                     = -149,    //!< The mosaic topology is not possible given the current state of the hardware.
+    NVAPI_MODE_CHANGE_FAILED                    = -150,    //!< An attempt to do a display resolution mode change has failed.        
+    NVAPI_D3D11_LIBRARY_NOT_FOUND               = -151,    //!< d3d11.dll/d3d11_beta.dll cannot be loaded.
+    NVAPI_INVALID_ADDRESS                       = -152,    //!< Address is outside of valid range.
+    NVAPI_STRING_TOO_SMALL                      = -153,    //!< The pre-allocated string is too small to hold the result.
+    NVAPI_MATCHING_DEVICE_NOT_FOUND             = -154,    //!< The input does not match any of the available devices.
+    NVAPI_DRIVER_RUNNING                        = -155,    //!< Driver is running.
+    NVAPI_DRIVER_NOTRUNNING                     = -156,    //!< Driver is not running.
+    NVAPI_ERROR_DRIVER_RELOAD_REQUIRED          = -157,    //!< A driver reload is required to apply these settings.
+    NVAPI_SET_NOT_ALLOWED                       = -158,    //!< Intended setting is not allowed.
+    NVAPI_ADVANCED_DISPLAY_TOPOLOGY_REQUIRED    = -159,    //!< Information can't be returned due to "advanced display topology".
+    NVAPI_SETTING_NOT_FOUND                     = -160,    //!< Setting is not found.
+    NVAPI_SETTING_SIZE_TOO_LARGE                = -161,    //!< Setting size is too large.
+    NVAPI_TOO_MANY_SETTINGS_IN_PROFILE          = -162,    //!< There are too many settings for a profile. 
+    NVAPI_PROFILE_NOT_FOUND                     = -163,    //!< Profile is not found.
+    NVAPI_PROFILE_NAME_IN_USE                   = -164,    //!< Profile name is duplicated.
+    NVAPI_PROFILE_NAME_EMPTY                    = -165,    //!< Profile name is empty.
+    NVAPI_EXECUTABLE_NOT_FOUND                  = -166,    //!< Application not found in the Profile.
+    NVAPI_EXECUTABLE_ALREADY_IN_USE             = -167,    //!< Application already exists in the other profile.
+    NVAPI_DATATYPE_MISMATCH                     = -168,    //!< Data Type mismatch 
+    NVAPI_PROFILE_REMOVED                       = -169,    //!< The profile passed as parameter has been removed and is no longer valid.
+    NVAPI_UNREGISTERED_RESOURCE                 = -170,    //!< An unregistered resource was passed as a parameter. 
+    NVAPI_ID_OUT_OF_RANGE                       = -171,    //!< The DisplayId corresponds to a display which is not within the normal outputId range.
+    NVAPI_DISPLAYCONFIG_VALIDATION_FAILED       = -172,    //!< Display topology is not valid so the driver cannot do a mode set on this configuration.
+    NVAPI_DPMST_CHANGED                         = -173,    //!< Display Port Multi-Stream topology has been changed.
+    NVAPI_INSUFFICIENT_BUFFER                   = -174,    //!< Input buffer is insufficient to hold the contents.    
+    NVAPI_ACCESS_DENIED                         = -175,    //!< No access to the caller.
+    NVAPI_MOSAIC_NOT_ACTIVE                     = -176,    //!< The requested action cannot be performed without Mosaic being enabled.
+    NVAPI_SHARE_RESOURCE_RELOCATED              = -177,    //!< The surface is relocated away from video memory.
+    NVAPI_REQUEST_USER_TO_DISABLE_DWM           = -178,    //!< The user should disable DWM before calling NvAPI.
+    NVAPI_D3D_DEVICE_LOST                       = -179,    //!< D3D device status is D3DERR_DEVICELOST or D3DERR_DEVICENOTRESET - the user has to reset the device.
+    NVAPI_INVALID_CONFIGURATION                 = -180,    //!< The requested action cannot be performed in the current state.
+    NVAPI_STEREO_HANDSHAKE_NOT_DONE             = -181,    //!< Call failed as stereo handshake not completed.
+    NVAPI_EXECUTABLE_PATH_IS_AMBIGUOUS          = -182,    //!< The path provided was too short to determine the correct NVDRS_APPLICATION
+    NVAPI_DEFAULT_STEREO_PROFILE_IS_NOT_DEFINED = -183,    //!< Default stereo profile is not currently defined
+    NVAPI_DEFAULT_STEREO_PROFILE_DOES_NOT_EXIST = -184,    //!< Default stereo profile does not exist
+    NVAPI_CLUSTER_ALREADY_EXISTS                = -185,    //!< A cluster is already defined with the given configuration.
+    NVAPI_DPMST_DISPLAY_ID_EXPECTED             = -186,    //!< The input display id is not that of a multi stream enabled connector or a display device in a multi stream topology 
+    NVAPI_INVALID_DISPLAY_ID                    = -187,    //!< The input display id is not valid or the monitor associated to it does not support the current operation
+    NVAPI_STREAM_IS_OUT_OF_SYNC                 = -188,    //!< While playing secure audio stream, stream goes out of sync
+    NVAPI_INCOMPATIBLE_AUDIO_DRIVER             = -189,    //!< Older audio driver version than required
+    NVAPI_VALUE_ALREADY_SET                     = -190,    //!< Value already set, setting again not allowed.
+    NVAPI_TIMEOUT                               = -191,    //!< Requested operation timed out 
+    NVAPI_GPU_WORKSTATION_FEATURE_INCOMPLETE    = -192,    //!< The requested workstation feature set has incomplete driver internal allocation resources
+    NVAPI_STEREO_INIT_ACTIVATION_NOT_DONE       = -193,    //!< Call failed because InitActivation was not called.
+    NVAPI_SYNC_NOT_ACTIVE                       = -194,    //!< The requested action cannot be performed without Sync being enabled.    
+    NVAPI_SYNC_MASTER_NOT_FOUND                 = -195,    //!< The requested action cannot be performed without Sync Master being enabled.
+    NVAPI_INVALID_SYNC_TOPOLOGY                 = -196,    //!< Invalid displays passed in the NV_GSYNC_DISPLAY pointer.
+    NVAPI_ECID_SIGN_ALGO_UNSUPPORTED            = -197,    //!< The specified signing algorithm is not supported. Either an incorrect value was entered or the current installed driver/hardware does not support the input value.
+    NVAPI_ECID_KEY_VERIFICATION_FAILED          = -198,    //!< The encrypted public key verification has failed.
+    NVAPI_FIRMWARE_OUT_OF_DATE                  = -199,    //!< The device's firmware is out of date.
+    NVAPI_FIRMWARE_REVISION_NOT_SUPPORTED       = -200,    //!< The device's firmware is not supported.
+    NVAPI_LICENSE_CALLER_AUTHENTICATION_FAILED  = -201,    //!< The caller is not authorized to modify the License.
+    NVAPI_D3D_DEVICE_NOT_REGISTERED             = -202,    //!< The user tried to use a deferred context without registering the device first  
+    NVAPI_RESOURCE_NOT_ACQUIRED                 = -203,    //!< Head or SourceId was not reserved for the VR Display before doing the Modeset or the dedicated display.
+    NVAPI_TIMING_NOT_SUPPORTED                  = -204,    //!< Provided timing is not supported.
+    NVAPI_HDCP_ENCRYPTION_FAILED                = -205,    //!< HDCP Encryption Failed for the device. Would be applicable when the device is HDCP Capable.
+    NVAPI_PCLK_LIMITATION_FAILED                = -206,    //!< Provided mode is over sink device pclk limitation.
+    NVAPI_NO_CONNECTOR_FOUND                    = -207,    //!< No connector on GPU found. 
+    NVAPI_HDCP_DISABLED                         = -208,    //!< When a non-HDCP capable HMD is connected, we would inform user by this code.
+    NVAPI_API_IN_USE                            = -209,    //!< Atleast an API is still being called
+    NVAPI_NVIDIA_DISPLAY_NOT_FOUND              = -210,    //!< No display found on Nvidia GPU(s).
+    NVAPI_PRIV_SEC_VIOLATION                    = -211,    //!< Priv security violation, improper access to a secured register.
+    NVAPI_INCORRECT_VENDOR                      = -212,    //!< NVAPI cannot be called by this vendor
+    NVAPI_DISPLAY_IN_USE                        = -213,    //!< DirectMode Display is already in use
+    NVAPI_UNSUPPORTED_CONFIG_NON_HDCP_HMD       = -214,    //!< The Config is having Non-NVidia GPU with Non-HDCP HMD connected
+    NVAPI_MAX_DISPLAY_LIMIT_REACHED             = -215,    //!< GPU's Max Display Limit has Reached
+    NVAPI_INVALID_DIRECT_MODE_DISPLAY           = -216,    //!< DirectMode not Enabled on the Display
+    NVAPI_GPU_IN_DEBUG_MODE                     = -217,    //!< GPU is in debug mode, OC is NOT allowed.
+    NVAPI_D3D_CONTEXT_NOT_FOUND                 = -218,    //!< No NvAPI context was found for this D3D object
+    NVAPI_STEREO_VERSION_MISMATCH               = -219,    //!< there is version mismatch between stereo driver and dx driver
+    NVAPI_GPU_NOT_POWERED                       = -220,    //!< GPU is not powered and so the request cannot be completed.
+    NVAPI_ERROR_DRIVER_RELOAD_IN_PROGRESS       = -221,    //!< The display driver update in progress.
+    NVAPI_WAIT_FOR_HW_RESOURCE                  = -222,    //!< Wait for HW resources allocation
+    NVAPI_REQUIRE_FURTHER_HDCP_ACTION           = -223,    //!< operation requires further HDCP action
+    NVAPI_DISPLAY_MUX_TRANSITION_FAILED         = -224,    //!< Dynamic Mux transition failure
+    NVAPI_INVALID_DSC_VERSION                   = -225,    //!< Invalid DSC version
+    NVAPI_INVALID_DSC_SLICECOUNT                = -226,    //!< Invalid DSC slice count
+    NVAPI_INVALID_DSC_OUTPUT_BPP                = -227,    //!< Invalid DSC output BPP
+    NVAPI_FAILED_TO_LOAD_FROM_DRIVER_STORE      = -228,    //!< There was an error while loading nvapi.dll from the driver store.
+    NVAPI_NO_VULKAN                             = -229,    //!< OpenGL does not export Vulkan fake extensions
+    NVAPI_REQUEST_PENDING                       = -230,    //!< A request for NvTOPPs telemetry CData has already been made and is pending a response.
+    NVAPI_RESOURCE_IN_USE                       = -231,    //!< Operation cannot be performed because the resource is in use.
+    NVAPI_INVALID_IMAGE                         = -232,    //!< Device kernel image is invalid
+    NVAPI_INVALID_PTX                           = -233,    //!< PTX JIT compilation failed
+    NVAPI_NVLINK_UNCORRECTABLE                  = -234,    //!< Uncorrectable NVLink error was detected during the execution
+    NVAPI_JIT_COMPILER_NOT_FOUND                = -235,    //!< PTX JIT compiler library was not found.
+    NVAPI_INVALID_SOURCE                        = -236,    //!< Device kernel source is invalid.
+    NVAPI_ILLEGAL_INSTRUCTION                   = -237,    //!< While executing a kernel, the device encountered an illegal instruction.
+    NVAPI_INVALID_PC                            = -238,    //!< While executing a kernel, the device program counter wrapped its address space
+    NVAPI_LAUNCH_FAILED                         = -239,    //!< An exception occurred on the device while executing a kernel
+    NVAPI_NOT_PERMITTED                         = -240,    //!< Attempted operation is not permitted.
+    NVAPI_CALLBACK_ALREADY_REGISTERED           = -241,    //!< The callback function has already been registered.
+    NVAPI_CALLBACK_NOT_FOUND                    = -242,    //!< The callback function is not found or not registered.
+} NvAPI_Status;
+
+
+//! @}
+
+#if defined(__vkd3d_d3d12_h__)
+//! Flags specifying raytracing thread reordering hardware support.
+//! Additional flags will be added as support becomes available.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_THREAD_REORDERING_CAPS
+{
+    NVAPI_D3D12_RAYTRACING_THREAD_REORDERING_CAP_NONE     = 0x0,       //!< Thread reordering acts as a no-op
+    NVAPI_D3D12_RAYTRACING_THREAD_REORDERING_CAP_STANDARD = NV_BIT(0)  //!< Standard thread reordering is supported
+} NVAPI_D3D12_RAYTRACING_THREAD_REORDERING_CAPS;
+
+//! Flags specifying raytracing Opacity Micromap support.
+//! Additional flags will be added as support becomes available.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_CAPS
+{
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_CAP_NONE     = 0x0,       //!< Opacity Micromap support is not available.
+                                                                      //!< The application must not attempt to use any OMM entrypoints or flags.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_CAP_STANDARD = NV_BIT(0)  //!< Standard Opacity Micromap support is available
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_CAPS;
+
+//! List of Raytracing CAPS types that can be queried.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_CAPS_TYPE
+{
+    NVAPI_D3D12_RAYTRACING_CAPS_TYPE_THREAD_REORDERING      =  0,
+    NVAPI_D3D12_RAYTRACING_CAPS_TYPE_OPACITY_MICROMAP       =  1,
+    NVAPI_D3D12_RAYTRACING_CAPS_TYPE_INVALID                = -1
+} NVAPI_D3D12_RAYTRACING_CAPS_TYPE;
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_GetRaytracingCaps
+//
+//! DESCRIPTION: Query raytracing capabilities of a device.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in]     pDevice     Pointer to the device on which raytracing caps should be queried from.
+//! \param [in]     type        Raytracing caps type requested. (ex: NVAPI_D3D12_RAYTRACING_CAPS_TYPE_THREAD_REORDERING)
+//! \param [out]    pData       Pointer to memory that receives caps. (ex: NVAPI_D3D12_RAYTRACING_THREAD_REORDERING_CAPS*)
+//! \param [in]     dataSize    Size in bytes to return to pData. Must match the size of the caps data requested. (ex: sizeof(NVAPI_D3D12_RAYTRACING_THREAD_REORDERING_CAPS))
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \retval ::NVAPI_OK                   Completed request
+//! \retval ::NVAPI_INVALID_POINTER      A null pointer was passed as an argument
+//! \retval ::NVAPI_INVALID_ARGUMENT     At least one of the arguments are invalid
+//! \retval ::NVAPI_ERROR                Error occurred
+//! \ingroup dx
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_GetRaytracingCaps(
+    __in    ID3D12Device* pDevice,
+    __in    NVAPI_D3D12_RAYTRACING_CAPS_TYPE type,
+    __out   void* pData,
+    __in    size_t dataSize);
+#endif // defined(__vkd3d_d3d12_h__)
+
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+#if defined(__vkd3d_d3d12_h__) && (defined(__ID3D12Device5_INTERFACE_DEFINED__) || defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__))
+
+// Types used by both device and command list functions.
+
+//! Flags specifying building instructions and hints when constructing an OMM Array.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAGS
+{
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAG_NONE              = 0x0,       //!< No options specified for the OMM Array build.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAG_PREFER_FAST_TRACE = NV_BIT(0), //!< Allow the OMM Array build to take a little longer in order to optimize for traversal performance.
+                                                                                            //!< This flag is incompatible with #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAG_PREFER_FAST_BUILD.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAG_PREFER_FAST_BUILD = NV_BIT(1)  //!< Spend as little time as possible on the OMM Array build with some potential loss to traversal performance.
+                                                                                            //!< This flag is incompatible with #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAG_PREFER_FAST_TRACE.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAGS;
+
+//! Specifies the input Opacity Micromap formats.
+//! The OC1 (Opacity Compression 1) format follows the space-filling curve in barycentric space over the uniformly tessellated micro-triangles.
+//!
+//! \note This is a 16-bit value when used in #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_DESC.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT
+{
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT_OC1_2_STATE = 0x1, //!< 2-state (Transparent/Opaque) format.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT_OC1_4_STATE = 0x2  //!< 4-state (Transparent/Opaque, Known/Unknown) format.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT;
+
+//! Number of OMMs of a specific configuration in an OMM Array.
+//! Used to compute conservative buffer size estimates for OMM Array builds.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT
+{
+    NvU32                                          count;            //!< Total number of OMMs in the OMM Array with the particular \p subdivisionLevel and \p format specified in this descriptor.
+    NvU32                                          subdivisionLevel; //!< Number of subdivisions for the OMM; valid inputs are [0, 12] (#NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_OC1_MAX_SUBDIVISION_LEVEL).
+                                                                     //!< The total number of micro-triangles is 4<sup><tt>subdivisionLevel</tt></sup>.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT format;           //!< Opacity Micromap format.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT;
+
+//! Describes one Opacity Micromap.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_DESC
+{
+    NvU32 byteOffset;       //!< Byte offset from the \c inputBuffer, specified in the input structure #NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_INPUTS, to where the input OMM data is located.
+    NvU16 subdivisionLevel; //!< Number of subdivisions for the OMM; valid inputs are [0, 12] (#NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_OC1_MAX_SUBDIVISION_LEVEL).
+                            //!< The total number of micro-triangles is 4<sup><tt>subdivisionLevel</tt></sup>.
+    NvU16 format;           //!< Format of the OMM of type #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_DESC;
+
+//! Input structure to OMM Array construction.
+//! Individual OMMs are accessed via indices when used in bottom-level acceleration structure (BLAS) construction.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_INPUTS
+{
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAGS  flags;             //!< Flags which apply to all OMMs in the array.
+    NvU32                                                      numOMMUsageCounts; //!< Number of OMM usage count entries in the \p pOMMUsageCounts array.
+    const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT* pOMMUsageCounts;   //!< Usage counts for each subdivision level and format combination across all the OMM entries in the build.
+    D3D12_GPU_VIRTUAL_ADDRESS                                  inputBuffer;       //!< Address for raw OMM input data; it must be 256-byte aligned.
+                                                                                  //!< It is recommended to try to organize OMMs together in memory that are expected to be used close together spatially.
+    D3D12_GPU_VIRTUAL_ADDRESS_AND_STRIDE                       perOMMDescs;       //!< GPU array with one #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_DESC entry per OMM.
+} NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_INPUTS;
+
+#endif // defined(__vkd3d_d3d12_h__) && (defined(__ID3D12Device5_INTERFACE_DEFINED__) || defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__))
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+//! Conservative memory requirements for building an OMM Array.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO
+{
+    NvU64 resultDataMaxSizeInBytes; //!< Size required to hold the result of an OMM Array build based on the specified inputs.
+    NvU64 scratchDataSizeInBytes;   //!< Scratch storage on GPU required during OMM Array build based on the specified inputs.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO;
+
+//! Parameters given to NvAPI_D3D12_GetRaytracingOpacityMicromapArrayPrebuildInfo().
+//!
+//! \ingroup dx
+typedef struct _NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_V1
+{
+    NvU32                                                             version; //!< [in]  Structure version; it should be set to #NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_VER.
+    const NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_INPUTS* pDesc;   //!< [in]  Description of the OMM Array build.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO*      pInfo;   //!< [out] Result of the query.
+} NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_V1;
+#define NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_V1, 1)
+typedef NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_V1            NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS;
+#define NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_VER           NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_GetRaytracingOpacityMicromapArrayPrebuildInfo
+//
+//! DESCRIPTION: Query conservative memory requirements for building an OMM (Opacity Micromap) Array.
+//!              The returned size is conservative for OMM Array builds containing
+//!              a lower or equal number of entries for each resolution and format combination.
+//!
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in]     pDevice                      Device on which the OMM Array will be built.
+//! \param [in,out] pParams                      Wrapper around the inputs and outputs of the function.
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_GetRaytracingOpacityMicromapArrayPrebuildInfo(
+    __in    ID3D12Device5* pDevice,
+    __inout NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS* pParams);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+//! Pipeline creation state flags.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_PIPELINE_CREATION_STATE_FLAGS
+{
+    NVAPI_D3D12_PIPELINE_CREATION_STATE_FLAGS_NONE               = 0,         //!< [in] No pipeline flags.
+    NVAPI_D3D12_PIPELINE_CREATION_STATE_FLAGS_ENABLE_OMM_SUPPORT = NV_BIT(0), //!< [in] Change whether raytracing pipelines are created with support for Opacity Micromaps.
+                                                                              //!<      If a triangle with an OMM is encountered during traversal and the pipeline was not created with support for them, behavior is undefined.
+                                                                              //!<      Support should only be enabled if there are OMMs present, since it may incur a small penalty on traversal performance overall.
+} NVAPI_D3D12_PIPELINE_CREATION_STATE_FLAGS;
+
+//! State used when creating new pipelines.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_V1
+{
+    NvU32 version; //!< [in] Structure version; it should be set to #NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_VER.
+    NvU32 flags;   //!< [in] A bitwise OR of one or more #NVAPI_D3D12_PIPELINE_CREATION_STATE_FLAGS flags for raytracing pipeline creation.
+} NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_V1;
+#define NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_V1, 1)
+typedef NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_V1            NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS;
+#define NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_VER           NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_SetCreatePipelineStateOptions
+//
+//! DESCRIPTION: Globally change the state affecting pipeline creations.
+//!              This affects all pipelines created after this call, and until this function is called again.
+//!
+//! \note Only supported on GPUs capable of DXR.
+//!       Some of the flags and fields have further restrictions, in which case their description will include a note with more details.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in]  pDevice                         Device on which the pipelines will be created.
+//! \param [in]  pState                          State to be applied to all future pipeline creations.
+
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_SetCreatePipelineStateOptions(
+    __in ID3D12Device5* pDevice,
+    __in const NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS* pState);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+//! Type of serialized data.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_SERIALIZED_DATA_TYPE_EX
+{
+    // D3D12_SERIALIZED_DATA_TYPE flags
+    NVAPI_D3D12_SERIALIZED_DATA_RAYTRACING_ACCELERATION_STRUCTURE_EX = 0x0,      //!< Serialized data contains a raytracing acceleration structure.
+                                                                                 //!< Starting from offset 0, the first bytes of the serialized acceleration structure can be reinterpreted as \c D3D12_SERIALIZED_RAYTRACING_ACCELERATION_STRUCTURE_HEADER.
+                                                                                 //!< That structure contains the identifier to be passed along to NvAPI_D3D12_CheckDriverMatchingIdentifierEx().
+
+    // NVAPI_D3D12_SERIALIZED_DATA_TYPE_EX specific flags
+    NVAPI_D3D12_SERIALIZED_DATA_RAYTRACING_OPACITY_MICROMAP_ARRAY_EX = 0x1,      //!< Data blob contains an OMM Array.
+                                                                                 //!< Starting from offset 0, the first bytes of the OMM Array can be reinterpreted as \c D3D12_SERIALIZED_DATA_DRIVER_MATCHING_IDENTIFIER.
+
+} NVAPI_D3D12_SERIALIZED_DATA_TYPE_EX;
+
+//! Parameters given to NvAPI_D3D12_CheckDriverMatchingIdentifierEx().
+//!
+//! \ingroup dx
+typedef struct _NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_V1
+{
+    NvU32                                                   version;            //!< [in]  Structure version; it should be set to #NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_VER.
+    NVAPI_D3D12_SERIALIZED_DATA_TYPE_EX                     serializedDataType; //!< [in]  Type of data to be deserialized; see #NVAPI_D3D12_SERIALIZED_DATA_TYPE_EX.
+    const D3D12_SERIALIZED_DATA_DRIVER_MATCHING_IDENTIFIER* pIdentifierToCheck; //!< [in]  Identifier from the header of the serialized data to check with the driver; see \c D3D12_SERIALIZED_DATA_DRIVER_MATCHING_IDENTIFIER.
+                                                                                //!<       Information about how to retrieve that identifier can be found in the description of each #NVAPI_D3D12_SERIALIZED_DATA_TYPE_EX enum.
+    D3D12_DRIVER_MATCHING_IDENTIFIER_STATUS                 checkStatus;        //!< [out] Result of the check; see \c D3D12_DRIVER_MATCHING_IDENTIFIER_STATUS.
+} NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_V1;
+#define NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_V1, 1)
+typedef NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_V1            NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS;
+#define NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_VER           NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_CheckDriverMatchingIdentifierEx
+//
+//! DESCRIPTION: This function is an extension of <tt>ID3D12Device5::CheckDriverMatchingIdentifier()</tt> with additional serialized data types.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in]     pDevice                      Device on which the data will be deserialized.
+//! \param [in,out] pParams                      Wrapper around the inputs and outputs of the function.
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_CheckDriverMatchingIdentifierEx(
+    __in    ID3D12Device5* pDevice,
+    __inout NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS* pParams);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+//! This enum extends \c D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS with modified and additional values.
+//! Only modified/new values are fully described; for more information on the other values, please check Microsoft's DirectX Raytracing Specification.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS_EX
+{
+    // D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS flags
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_NONE_EX                            = 0x0,       //!< No options specified for the acceleration structure build.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_UPDATE_EX                    = NV_BIT(0), //!< Allow the acceleration structure to later be updated (via the flag #NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_PERFORM_UPDATE_EX), rather than always requiring a full rebuild.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_COMPACTION_EX                = NV_BIT(1), //!< Allow for the acceleration structure to later be compacted.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_PREFER_FAST_TRACE_EX               = NV_BIT(2), //!< Favorize higher raytracing performance at the cost of longer build times.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_PREFER_FAST_BUILD_EX               = NV_BIT(3), //!< Favorize faster build times at the cost of lower raytracing performance.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_MINIMIZE_MEMORY_EX                 = NV_BIT(4), //!< Minimize the memory footprint of the produced acceleration structure, potentially at the cost of longer build time or lower raytracing performance.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_PERFORM_UPDATE_EX                  = NV_BIT(5), //!< Instead of rebuilding the acceleration structure from scratch, the existing acceleration structure will be updated.
+                                                                                                             //!< Added behaviour: If #NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_OMM_UPDATE_EX is specified, OMM references may be changed along with positions when an update is performed.
+
+    // NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS_EX specific flags
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_OMM_UPDATE_EX                = NV_BIT(6), //!< The acceleration structure (AS) supports updating OMM contents (base OMM Array and/or indices).
+                                                                                                             //!< Specifying this flag may result in larger AS size and may reduce traversal performance.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_DISABLE_OMMS_EX              = NV_BIT(7), //!< Only applicable for BLAS builds. If enabled, any instances referencing this BLAS are allowed to disable the OMM test through the #NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_DISABLE_OMMS_EX flag.
+                                                                                                             //!< Specifying this build flag may result in some reductions in traversal performance.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_OMM_OPACITY_STATES_UPDATE_EX = NV_BIT(8), //!< The acceleration structure (AS) supports updating OMM data (encoded opacity values).
+                                                                                                             //!< Specifying this flag may reduce traversal performance.
+
+} NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS_EX;
+
+//! This enum extends \c D3D12_RAYTRACING_GEOMETRY_TYPE with additional values.
+//! Only new values are fully described below; for more information on the other values, please check Microsoft's DirectX Raytracing Specification.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_EX
+{
+    // D3D12_RAYTRACING_GEOMETRY_TYPE flags
+    NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_TRIANGLES_EX                  = 0x0, //!< This geometry is made of basic triangles.
+    NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_PROCEDURAL_PRIMITIVE_AABBS_EX = 0x1, //!< This geometry is made of axis-aligned bounding boxes (AABBs).
+
+    // NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_EX specific flags
+    NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_OMM_TRIANGLES_EX              = 0x2, //!< Shares most fields with the basic triangle geometry type, but allows an OMM Array to be attached to the geometry.
+                                                                              //!< The basic triangle type and this OMM-enabled type geometries may be mixed in the same BLAS build.
+
+
+} NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_EX;
+
+//! If a triangle has a uniform OMM state in a BLAS build, it is preferable to signal this explicitly rather than attaching a single state OMM.
+//! This can be accomplished by supplying these special indices as entries in \c opacityMicromapIndexBuffer, in #NVAPI_D3D12_RAYTRACING_GEOMETRY_OMM_TRIANGLES_DESC.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_SPECIAL_INDEX
+{
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_TRANSPARENT         = -1, //!< Uniform transparent OMM state.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_OPAQUE              = -2, //!< Uniform opaque OMM state.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_UNKNOWN_TRANSPARENT = -3, //!< Uniform unknown-transparent OMM state.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_SPECIAL_INDEX_FULLY_UNKNOWN_OPAQUE      = -4  //!< Uniform unknown-opaque OMM state.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_SPECIAL_INDEX;
+
+//! Geometry descriptor attachment with Opacity Micromaps.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_GEOMETRY_OMM_ATTACHMENT_DESC
+{
+    D3D12_GPU_VIRTUAL_ADDRESS_AND_STRIDE                       opacityMicromapIndexBuffer;  //!< Optional buffer specifying which OMM index to use for each triangle; if \c NULL, there is a 1:1 mapping between input triangles and OMM Array entries.
+                                                                                            //!< Special values can be used to encode OMMs with uniform state for individual triangles (see #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_SPECIAL_INDEX).
+                                                                                            //!< For BLAS updates, this input buffer must match that of the original build if the #NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_OMM_UPDATE_EX build flag is not set.
+    DXGI_FORMAT                                                opacityMicromapIndexFormat;  //!< Format of \c opacityMicromapIndexBuffer, either \c DXGI_FORMAT_R32_UINT or \c DXGI_FORMAT_R16_UINT.
+    NvU32                                                      opacityMicromapBaseLocation; //!< Constant added to all non-negative OMM indices in \p opacityMicromapIndexBuffer.
+    D3D12_GPU_VIRTUAL_ADDRESS                                  opacityMicromapArray;        //!< Pointer to an OMM Array used by this geometry; it may be set to \c NULL if no non-uniform OMMs are used.
+                                                                                            //!< Unlike vertex, index, and transform buffers, this resource is dereferenced during raytracing.
+
+    NvU32                                                      numOMMUsageCounts;           //!< Number of OMM usage count entries in the \p pOMMUsageCounts array.
+    const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT* pOMMUsageCounts;             //!< Usage counts for each subdivision level and format combination across all the OMM entries referred-to by the OMM index buffer specified by this geometry.
+
+} NVAPI_D3D12_RAYTRACING_GEOMETRY_OMM_ATTACHMENT_DESC;
+
+//! Geometry triangle descriptor with attached augmented Opacity Micromaps.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_GEOMETRY_OMM_TRIANGLES_DESC
+{
+    D3D12_RAYTRACING_GEOMETRY_TRIANGLES_DESC            triangles;     //!< Triangle mesh descriptor.
+    NVAPI_D3D12_RAYTRACING_GEOMETRY_OMM_ATTACHMENT_DESC ommAttachment; //!< Opacity Micromap attachment descriptor.
+} NVAPI_D3D12_RAYTRACING_GEOMETRY_OMM_TRIANGLES_DESC;
+
+//! This structure extends \c D3D12_RAYTRACING_GEOMETRY_DESC by supporting additional geometry types.
+//! Only new members are fully described below; for more information on the other members, please check Microsoft's DirectX Raytracing Specification.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX
+{
+    NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_EX type;  //!< The type of geometry stored in the union of this structure.
+    D3D12_RAYTRACING_GEOMETRY_FLAGS         flags; //!< Flags affecting how this geometry is processed by the raytracing pipeline.
+    union
+    {
+        D3D12_RAYTRACING_GEOMETRY_TRIANGLES_DESC           triangles;    //!< Describes triangle geometry if \c type is #NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_TRIANGLES_EX.
+                                                                         //!< Otherwise, this parameter is unused (space repurposed in a union).
+        D3D12_RAYTRACING_GEOMETRY_AABBS_DESC               aabbs;        //!< Describes AABB geometry if \c type is #NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_PROCEDURAL_PRIMITIVE_AABBS_EX.
+                                                                         //!< Otherwise, this parameter is unused (space repurposed in a union).
+        NVAPI_D3D12_RAYTRACING_GEOMETRY_OMM_TRIANGLES_DESC ommTriangles; //!< Describes triangle geometry which may optionally use Opacity Micromaps, if \c type is #NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_OMM_TRIANGLES_EX.
+                                                                         //!< Otherwise, this parameter is unused (space repurposed in a union).
+    };
+} NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX;
+
+//! This enum extends \c D3D12_RAYTRACING_INSTANCE_FLAGS with additional values.
+//! Only new values are fully described below; for more information on the other values, please check Microsoft's DirectX Raytracing Specification.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_INSTANCE_FLAGS_EX
+{
+    // D3D12_RAYTRACING_INSTANCE_FLAGS flags
+    NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_NONE_EX                            = 0x0,       //!< No options specified for this instance.
+    NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_TRIANGLE_CULL_DISABLE_EX           = NV_BIT(0), //!< Disable triangle culling for this instance.
+    NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_TRIANGLE_FRONT_COUNTERCLOCKWISE_EX = NV_BIT(1), //!< Use counter-clockwise winding for defining front faces, instead of the default of clockwise winding.
+    NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_FORCE_OPAQUE_EX                    = NV_BIT(2), //!< Force all geometries in this instance to be opaque.
+    NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_FORCE_NON_OPAQUE_EX                = NV_BIT(3), //!< All geometries in this instance will be processed as if they never had the \c D3D12_RAYTRACING_GEOMETRY_FLAG_OPAQUE flag applied to them.
+
+    // NVAPI_D3D12_RAYTRACING_INSTANCE_FLAGS_EX specific flags
+    NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_FORCE_OMM_2_STATE_EX               = NV_BIT(4), //!< Ignore the Unknown state and only consider the Transparent/Opaque bit for all 4-state OMMs encountered during traversal.
+                                                                                         //!< This flag has no effect if #NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_DISABLE_OMMS_EX is set.
+    NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_DISABLE_OMMS_EX                    = NV_BIT(5)  //!< Disable OMMs for all triangles, and revert to using geometry opaque/non-opaque state instead (legacy behavior).
+                                                                                         //!< This flag is only valid if the referenced BLAS was built with the #NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_DISABLE_OMMS_EX flag; omitting that flag during BLAS build will result in undefined behavior.
+} NVAPI_D3D12_RAYTRACING_INSTANCE_FLAGS_EX;
+
+//! This structure extends \c D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS by supporting additional geometry types.
+//! Only modified members are fully described below; for more information on the other members, please check Microsoft's DirectX Raytracing Specification.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX
+{
+    D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TYPE                 type;                      //!< Whether a top-level acceleration structure (TLAS) or bottom-level acceleration structure (BLAS) will be built using this information.
+    NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS_EX flags;                     //!< Options influencing how the acceleration structure is built and which of its features can be used.
+    NvU32                                                        numDescs;                  //!< If \c type is \c D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TOP_LEVEL, it represents the number of descriptions stored in \c instanceDescs.
+                                                                                            //!< Otherwise, it contains the number of geometry descriptions stored in \c pGeometryDescs or \c ppGeometryDescs.
+    D3D12_ELEMENTS_LAYOUT                                        descsLayout;               //!< If \c type is \c D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BOTTOM_LEVEL, it specifies which of \c pGeometryDescs and \c ppGeometryDescs to use.
+                                                                                            //!< Otherwise, this parameter is unused.
+    NvU32                                                        geometryDescStrideInBytes; //!< Stride between consecutive geometry descriptors. Should typically be set to sizeof(NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX).
+                                                                                            //!< Only used if \c type is \c D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL and \c descLayout is \c D3D12_ELEMENTS_LAYOUT_ARRAY.
+                                                                                            //!< This field guarantees backwards compatibility, even if the geometry descriptor size increases in future NVAPI versions.
+    union
+    {
+        D3D12_GPU_VIRTUAL_ADDRESS                            instanceDescs;   //!< If \c type is \c D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TOP_LEVEL, the referenced instance structures can used the extended set of flags #NVAPI_D3D12_RAYTRACING_INSTANCE_FLAGS_EX in place of the \c D3D12_RAYTRACING_INSTANCE_FLAGS mentioned in \c D3D12_RAYTRACING_INSTANCE_DESC.
+                                                                              //!< Otherwise, this parameter is unused (space repurposed in a union).
+        const NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX*       pGeometryDescs;  //!< If \c type is \c D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BOTTOM_LEVEL and \c descLayout is \c D3D12_ELEMENTS_LAYOUT_ARRAY, it contains the descriptions of all geometries to be built into a BLAS.
+                                                                              //!< Otherwise, this parameter is unused (space repurposed in a union).
+        const NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX*const* ppGeometryDescs; //!< If \c type is \c D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BOTTOM_LEVEL and \c descLayout is \c D3D12_ELEMENTS_LAYOUT_ARRAY_OF_POINTERS, it contains the addresses of descriptions for all geometries to be built into a BLAS.
+                                                                              //!< Otherwise, this parameter is unused (space repurposed in a union).
+    };
+} NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX;
+
+//! Parameters given to NvAPI_D3D12_GetRaytracingAccelerationStructurePrebuildInfoEx().
+//!
+//! \ingroup dx
+typedef struct _NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_V1
+{
+    NvU32                                                                version; //!< [in]  Structure version; it should be set to #NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_VER.
+    const NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX* pDesc;   //!< [in]  Description of the acceleration-structure build.
+    D3D12_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO*               pInfo;   //!< [out] Result of the query.
+} NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_V1;
+#define NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_V1, 1)
+typedef NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_V1            NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS;
+#define NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_VER           NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_GetRaytracingAccelerationStructurePrebuildInfoEx
+//
+//! DESCRIPTION: This function is an extension of <tt>ID3D12Device5::GetRaytracingAccelerationStructurePrebuildInfo()</tt> with additional input types.
+//!
+//! \note Only supported on GPUs capable of DXR.
+//!       Some of the flags and fields have further restrictions, in which case their description will include a note with more details.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in]     pDevice                      Device on which the acceleration structure will be built.
+//! \param [in,out] pParams                      Wrapper around the inputs and outputs of the function.
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_GetRaytracingAccelerationStructurePrebuildInfoEx(
+    __in    ID3D12Device5* pDevice,
+    __inout NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS* pParams);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12Device5_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+//! Description of the inputs and memory areas used during the building of OMM Arrays.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_DESC
+{
+    D3D12_GPU_VIRTUAL_ADDRESS                                  destOpacityMicromapArrayData;    //!< Output location for the OMM Array build.
+                                                                                                //!< NvAPI_D3D12_GetRaytracingOpacityMicromapArrayPrebuildInfo() reports the amount of memory required for the result given a set of input parameters.
+                                                                                                //!< The address must be aligned to 256 bytes (#NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BYTE_ALIGNMENT).
+    NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_INPUTS inputs;                          //!< Description of the input data for the OMM Array build.
+    D3D12_GPU_VIRTUAL_ADDRESS                                  scratchOpacityMicromapArrayData; //!< Location where the build will store temporary data.
+                                                                                                //!< NvAPI_D3D12_GetRaytracingOpacityMicromapArrayPrebuildInfo() reports the amount of scratch memory the implementation will need for a given set of input parameters.
+                                                                                                //!< The address must be aligned to 256 bytes (#NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BYTE_ALIGNMENT).
+                                                                                                //!< Contents of this memory going into a build on the GPU timeline are irrelevant and will not be preserved.
+                                                                                                //!< After the build is complete on the GPU timeline, the memory is left with whatever undefined contents the build finished with.
+                                                                                                //!< The memory pointed to must be in state \c D3D12_RESOURCE_STATE_UNORDERED_ACCESS.
+} NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_DESC;
+
+//! Structure emitted by NvAPI_D3D12_EmitRaytracingOpacityMicromapArrayPostbuildInfo(), and optionally NvAPI_D3D12_BuildRaytracingOpacityMicromapArray(), when \c type equals #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_CURRENT_SIZE.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_CURRENT_SIZE_DESC
+{
+    NvU64 currentSizeInBytes; //!< Size of the OMM Array buffer.
+                              //!< The queried size may be smaller than the size reported by NvAPI_D3D12_GetRaytracingOpacityMicromapArrayPrebuildInfo().
+                              //!< This allows the application to move and relocate the OMM Array to a smaller buffer to reclaim any unused memory after the OMM Array build is complete.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_CURRENT_SIZE_DESC;
+
+//! Type of postbuild info to emit after an OMM Array build.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_TYPE
+{
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_CURRENT_SIZE       = 0x0  //!< Size of the current OMM Array. May be smaller than reported by the NvAPI_D3D12_GetRaytracingOpacityMicromapArrayPrebuildInfo() call.
+                                                                                           //!< Unused memory can be reclaimed by copying the OMM Array into a new resource; see #NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_CURRENT_SIZE_DESC.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_TYPE;
+
+//! Description of the postbuild information to generate from an OMM Array.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC
+{
+    D3D12_GPU_VIRTUAL_ADDRESS                                        destBuffer; //!< Result storage.
+                                                                                 //!< Size required and the layout of the contents written by the system depend on \p infoType.
+                                                                                 //!< The memory pointed to must be in state \c D3D12_RESOURCE_STATE_UNORDERED_ACCESS.
+                                                                                 //!< The memory must be aligned to the natural alignment for the members of the particular output structure being generated (e.g. 8 bytes for a struct with the largest member being \c NvU64).
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_TYPE infoType;  //!< Type of postbuild information to retrieve.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC;
+
+//! Parameters given to NvAPI_D3D12_BuildRaytracingOpacityMicromapArray().
+//!
+//! \ingroup dx
+typedef struct _NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1
+{
+    NvU32                                                                    version;               //!< [in] Structure version; it should be set to #NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER.
+    const NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_DESC*          pDesc;                 //!< [in] Description of the OMM Array build.
+    NvU32                                                                    numPostbuildInfoDescs; //!< [in] Size of postbuild info desc array. Set to 0 if none are needed.
+    const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC* pPostbuildInfoDescs;   //!< [in] Optional array of descriptions for postbuild info to generate describing properties of the acceleration structure that was built.
+                                                                                                    //!< [in] Any given postbuild info type, \c D3D12_RAYTRACING_ACCEELRATION_STRUCTURE_POSTBUILD_INFO_TYPE, can only be selected for output by at most one array entry.
+} NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1;
+#define NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1, 1)
+typedef NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1            NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS;
+#define NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER           NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_BuildRaytracingOpacityMicromapArray
+//
+//! DESCRIPTION: Construct OMM Array for a collection of OMMs on the GPU.
+//!              The CPU-side input buffers are not referenced after this call.
+//!              The GPU-side input resources are not referenced after the build has concluded after <tt>ExecuteCommandList()</tt>.
+//!              Additionally, the application may optionally output postbuild information immediately after the build.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in] pCommandList                     Command list on which the command will execute.
+//! \param [in] pParams                          Wrapper around the inputs and outputs of the function.
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \retval NVAPI_INVALID_COMBINATION            <tt>pParams->pPostbuildInfoDescs</tt> was set to \c NULL while <tt>pParams->numPostbuildInfoDescs</tt> is non zero.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_BuildRaytracingOpacityMicromapArray(
+    __in ID3D12GraphicsCommandList4* pCommandList,
+    __in NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS* pParams);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+//! Parameters given to NvAPI_D3D12_RelocateRaytracingOpacityMicromapArray().
+//!
+//! \ingroup dx
+typedef struct _NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1
+{
+    NvU32                     version;              //!< [in] Structure version; it should be set to #NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER.
+    D3D12_GPU_VIRTUAL_ADDRESS opacityMicromapArray; //!< [in] OMM Array current memory address; it must be 256-byte aligned (#NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BYTE_ALIGNMENT).
+} NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1;
+#define NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1, 1)
+typedef NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_V1            NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS;
+#define NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER           NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_RelocateRaytracingOpacityMicromapArray
+//
+//! DESCRIPTION: Makes the OMM Array usable at its current location in memory.
+//!              An OMM Array that has been copied to a new location must be relocated using this function before it may be attached to any BLAS.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in] pCommandList                     Command list on which the command will execute.
+//! \param [in] pParams                          Wrapper around the inputs and outputs of the function.
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_RelocateRaytracingOpacityMicromapArray(
+    __in ID3D12GraphicsCommandList4* pCommandList,
+    __in const NVAPI_RELOCATE_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS* pParams);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+//! Parameters given to NvAPI_D3D12_EmitRaytracingOpacityMicromapArrayPostbuildInfo().
+//!
+//! \ingroup dx
+typedef struct _NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_V1
+{
+    NvU32                                                                    version;    //!< [in] Structure version; it should be set to #NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_VER.
+    const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC* pDesc;      //!< [in] Description of which postbuild info to emit.
+    NvU32                                                                    numSources; //!< [in] Number of OMM Arrays in \p pSources.
+    const D3D12_GPU_VIRTUAL_ADDRESS*                                         pSources;   //!< [in] List of OMM Arrays for which postbuild info should be emitted.
+} NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_V1;
+#define NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_V1, 1)
+typedef NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_V1            NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS;
+#define NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_VER           NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_EmitRaytracingOpacityMicromapArrayPostbuildInfo
+//
+//! DESCRIPTION: Emits information about one or more OMM Arrays, only available after the OMM Array constructions have finished.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in] pCommandList                     Command list on which the command will execute.
+//! \param [in] pParams                          Wrapper around the inputs and outputs of the function.
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_EmitRaytracingOpacityMicromapArrayPostbuildInfo(
+    __in ID3D12GraphicsCommandList4* pCommandList,
+    __in const NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS* pParams);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+//! This structure extends \c D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_DESC by supporting additional geometry types as inputs.
+//! For more information on the different members, please check Microsoft's DirectX Raytracing Specification.
+//!
+//! \ingroup dx
+typedef struct _NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_DESC_EX
+{
+    D3D12_GPU_VIRTUAL_ADDRESS                                     destAccelerationStructureData;    //!< Memory where the resulting acceleration structure will be stored.
+    NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX inputs;                           //!< The inputs to the build process.
+    D3D12_GPU_VIRTUAL_ADDRESS                                     sourceAccelerationStructureData;  //!< The acceleration structure to be updated.
+                                                                                                    //!< Otherwise if the acceleration structure should be rebuilt entirely, this value must be \c NULL.
+    D3D12_GPU_VIRTUAL_ADDRESS                                     scratchAccelerationStructureData; //!< Memory that will be temporarily used during the building process.
+} NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_DESC_EX;
+
+//! Parameters given to NvAPI_D3D12_RelocateRaytracingOpacityMicromapArray().
+//!
+//! \ingroup dx
+typedef struct _NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_V1
+{
+    NvU32                                                              version;               //!< [in] Structure version; it should be set to #NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_VER.
+    const NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_DESC_EX* pDesc;                 //!< [in] Description of the acceleration structure to build.
+    NvU32                                                              numPostbuildInfoDescs; //!< [in] Size of postbuild info desc array. Set to 0 if none are needed.
+    const D3D12_RAYTRACING_ACCELERATION_STRUCTURE_POSTBUILD_INFO_DESC* pPostbuildInfoDescs;   //!< [in] Optional array of descriptions for postbuild info to generate describing properties of the acceleration structure that was built.
+                                                                                              //!<      Any given postbuild info type, \c D3D12_RAYTRACING_ACCEELRATION_STRUCTURE_POSTBUILD_INFO_TYPE, can only be selected for output by at most one array entry.
+} NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_V1;
+#define NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_VER1          MAKE_NVAPI_VERSION(NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_V1, 1)
+typedef NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_V1            NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS;
+#define NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_VER           NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_VER1
+
+///////////////////////////////////////////////////////////////////////////////
+//
+// FUNCTION NAME: NvAPI_D3D12_BuildRaytracingAccelerationStructureEx
+//
+//! DESCRIPTION: Perform an acceleration structure build on the GPU.
+//!              Also optionally output postbuild information immediately after the build.
+//!              This function is an extension of <tt>ID3D12GraphicsCommandList4::BuildRaytracingAccelerationStructure()</tt> with additional serialized data types.
+//!
+//! \note Only supported on GPUs capable of DXR.
+//!       Some of the flags and fields have further restrictions, in which case their description will include a note with more details.
+//!
+//! SUPPORTED OS:  Windows 10 and higher
+//!
+//!
+//! \since Release: 520
+//!
+//! \param [in] pCommandList                     Command list on which the command will execute.
+//! \param [in] pParams                          Wrapper around the inputs and outputs of the function.
+//!
+//! \return This API can return any of the error codes enumerated in #NvAPI_Status.
+//!         If there are return error codes with specific meaning for this API, they are listed below.
+//!
+//! \retval NVAPI_INVALID_COMBINATION            <tt>pParams->pPostbuildInfoDescs</tt> was set to \c NULL while <tt>pParams->numPostbuildInfoDescs</tt> is non zero.
+//!
+//! \ingroup dx 
+///////////////////////////////////////////////////////////////////////////////
+NVAPI_INTERFACE NvAPI_D3D12_BuildRaytracingAccelerationStructureEx(
+    __in ID3D12GraphicsCommandList4* pCommandList,
+    __in const NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS* pParams);
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+#if defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+///////////////////////////////////////////////////////////////////////////////
+// 
+// Miscellaneous
+//
+///////////////////////////////////////////////////////////////////////////////
+
+//! Opacity Micromap micro-triangle states.
+//! Not part of any input, but listed here for convenience.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_STATE
+{
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_STATE_TRANSPARENT         = 0, //!< Transparent OMM state: hit is ignored.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_STATE_OPAQUE              = 1, //!< Opaque OMM state: hit is committed.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_STATE_UNKNOWN_TRANSPARENT = 2, //!< Unknown-transparent OMM state.
+                                                                           //!< * If operating in 2-state mode, ignore hit.
+                                                                           //!< * If operating in 4-state mode, invoke any-hit shader.
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_STATE_UNKNOWN_OPAQUE      = 3  //!< Unknown-opaque OMM state.
+                                                                           //!< * If operating in 2-state mode, commit hit.
+                                                                           //!< * If operating in 4-state mode, invoke any-hit shader.
+} NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_STATE;
+
+//! Mandatory alignment for the address of an OMM Array.
+//!
+//! \ingroup dx
+#define NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BYTE_ALIGNMENT 256
+
+//! Highest subdivision-level allowed with OC1.
+//!
+//! \ingroup dx
+#define NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_OC1_MAX_SUBDIVISION_LEVEL 12
+
+//! A list of flags that can be given to the \c TraceRay() function in HLSL.
+//! Only new or modified values are fully described below; for more information on the other values, please check Microsoft's DirectX Raytracing Specification.
+//!
+//! \ingroup dx
+typedef enum _NVAPI_RAY_FLAGS_EX
+{
+    // RAY_FLAGS flags
+    NVAPI_RAY_FLAG_NONE_EX                            = 0x0,        //!< No flag specified.
+    NVAPI_RAY_FLAG_FORCE_OPAQUE_EX                    = NV_BIT( 0), //!< Consider all intersected geometries to be opaque, regardless of the flags specified at the geometry and instance level.
+    NVAPI_RAY_FLAG_FORCE_NON_OPAQUE_EX                = NV_BIT( 1), //!< Consider all intersected geometries to be non-opaque, regardless of the flags specified at the geometry and instance level.
+    NVAPI_RAY_FLAG_ACCEPT_FIRST_HIT_AND_END_SEARCH_EX = NV_BIT( 2), //!< End the traversal as soon as a geometry is hit, and that hit is not ignored by the any hit shader.
+    NVAPI_RAY_FLAG_SKIP_CLOSEST_HIT_SHADER_EX         = NV_BIT( 3), //!< Do not invoke the closest hit shader once the traversal ends.
+    NVAPI_RAY_FLAG_CULL_BACK_FACING_TRIANGLES_EX      = NV_BIT( 4), //!< Never intersect triangle geometries that are back facing with regard to the ray.
+    NVAPI_RAY_FLAG_CULL_FRONT_FACING_TRIANGLES_EX     = NV_BIT( 5), //!< Never intersect triangle geometries that are front facing with regard to the ray.
+    NVAPI_RAY_FLAG_CULL_OPAQUE_EX                     = NV_BIT( 6), //!< Never intersect geometries that were flagged as opaque.
+    NVAPI_RAY_FLAG_CULL_NON_OPAQUE_EX                 = NV_BIT( 7), //!< Never intersect geometries that were not flagged as opaque.
+    NVAPI_RAY_FLAG_SKIP_TRIANGLES_EX                  = NV_BIT( 8), //!< Never intersect triangle geometries.
+    NVAPI_RAY_FLAG_SKIP_PROCEDURAL_PRIMITIVES_EX      = NV_BIT( 9), //!< Never intersect AABB geometries.
+
+    // NVAPI_RAY_FLAGS_EX specific flags
+    NVAPI_RAY_FLAG_FORCE_OMM_2_STATE_EX               = NV_BIT(10), //!< Treat unknown-opaque and unknown-transparent as opaque and transparent, respectively, during traversal.
+                                                                    //!< If an instance is flagged with #NVAPI_D3D12_RAYTRACING_INSTANCE_FLAG_DISABLE_OMMS_EX, that takes precedence over this flag.
+} NVAPI_RAY_FLAG_EX;
+
+#endif // defined(__vkd3d_d3d12_h__) && defined(__ID3D12GraphicsCommandList4_INTERFACE_DEFINED__)
+
+#ifndef __NVAPI_EMPTY_SAL
+#ifdef __nvapi_undef__ecount
+    #undef __ecount
+    #undef __nvapi_undef__ecount
+#endif
+#ifdef __nvapi_undef__bcount
+    #undef __bcount
+    #undef __nvapi_undef__bcount
+#endif
+#ifdef __nvapi_undef__in
+    #undef __in
+    #undef __nvapi_undef__in
+#endif
+#ifdef __nvapi_undef__in_ecount
+    #undef __in_ecount
+    #undef __nvapi_undef__in_ecount
+#endif
+#ifdef __nvapi_undef__in_bcount
+    #undef __in_bcount
+    #undef __nvapi_undef__in_bcount
+#endif
+#ifdef __nvapi_undef__in_z
+    #undef __in_z
+    #undef __nvapi_undef__in_z
+#endif
+#ifdef __nvapi_undef__in_ecount_z
+    #undef __in_ecount_z
+    #undef __nvapi_undef__in_ecount_z
+#endif
+#ifdef __nvapi_undef__in_bcount_z
+    #undef __in_bcount_z
+    #undef __nvapi_undef__in_bcount_z
+#endif
+#ifdef __nvapi_undef__in_nz
+    #undef __in_nz
+    #undef __nvapi_undef__in_nz
+#endif
+#ifdef __nvapi_undef__in_ecount_nz
+    #undef __in_ecount_nz
+    #undef __nvapi_undef__in_ecount_nz
+#endif
+#ifdef __nvapi_undef__in_bcount_nz
+    #undef __in_bcount_nz
+    #undef __nvapi_undef__in_bcount_nz
+#endif
+#ifdef __nvapi_undef__out
+    #undef __out
+    #undef __nvapi_undef__out
+#endif
+#ifdef __nvapi_undef__out_ecount
+    #undef __out_ecount
+    #undef __nvapi_undef__out_ecount
+#endif
+#ifdef __nvapi_undef__out_bcount
+    #undef __out_bcount
+    #undef __nvapi_undef__out_bcount
+#endif
+#ifdef __nvapi_undef__out_ecount_part
+    #undef __out_ecount_part
+    #undef __nvapi_undef__out_ecount_part
+#endif
+#ifdef __nvapi_undef__out_bcount_part
+    #undef __out_bcount_part
+    #undef __nvapi_undef__out_bcount_part
+#endif
+#ifdef __nvapi_undef__out_ecount_full
+    #undef __out_ecount_full
+    #undef __nvapi_undef__out_ecount_full
+#endif
+#ifdef __nvapi_undef__out_bcount_full
+    #undef __out_bcount_full
+    #undef __nvapi_undef__out_bcount_full
+#endif
+#ifdef __nvapi_undef__out_z
+    #undef __out_z
+    #undef __nvapi_undef__out_z
+#endif
+#ifdef __nvapi_undef__out_z_opt
+    #undef __out_z_opt
+    #undef __nvapi_undef__out_z_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_z
+    #undef __out_ecount_z
+    #undef __nvapi_undef__out_ecount_z
+#endif
+#ifdef __nvapi_undef__out_bcount_z
+    #undef __out_bcount_z
+    #undef __nvapi_undef__out_bcount_z
+#endif
+#ifdef __nvapi_undef__out_ecount_part_z
+    #undef __out_ecount_part_z
+    #undef __nvapi_undef__out_ecount_part_z
+#endif
+#ifdef __nvapi_undef__out_bcount_part_z
+    #undef __out_bcount_part_z
+    #undef __nvapi_undef__out_bcount_part_z
+#endif
+#ifdef __nvapi_undef__out_ecount_full_z
+    #undef __out_ecount_full_z
+    #undef __nvapi_undef__out_ecount_full_z
+#endif
+#ifdef __nvapi_undef__out_bcount_full_z
+    #undef __out_bcount_full_z
+    #undef __nvapi_undef__out_bcount_full_z
+#endif
+#ifdef __nvapi_undef__out_nz
+    #undef __out_nz
+    #undef __nvapi_undef__out_nz
+#endif
+#ifdef __nvapi_undef__out_nz_opt
+    #undef __out_nz_opt
+    #undef __nvapi_undef__out_nz_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_nz
+    #undef __out_ecount_nz
+    #undef __nvapi_undef__out_ecount_nz
+#endif
+#ifdef __nvapi_undef__out_bcount_nz
+    #undef __out_bcount_nz
+    #undef __nvapi_undef__out_bcount_nz
+#endif
+#ifdef __nvapi_undef__inout
+    #undef __inout
+    #undef __nvapi_undef__inout
+#endif
+#ifdef __nvapi_undef__inout_ecount
+    #undef __inout_ecount
+    #undef __nvapi_undef__inout_ecount
+#endif
+#ifdef __nvapi_undef__inout_bcount
+    #undef __inout_bcount
+    #undef __nvapi_undef__inout_bcount
+#endif
+#ifdef __nvapi_undef__inout_ecount_part
+    #undef __inout_ecount_part
+    #undef __nvapi_undef__inout_ecount_part
+#endif
+#ifdef __nvapi_undef__inout_bcount_part
+    #undef __inout_bcount_part
+    #undef __nvapi_undef__inout_bcount_part
+#endif
+#ifdef __nvapi_undef__inout_ecount_full
+    #undef __inout_ecount_full
+    #undef __nvapi_undef__inout_ecount_full
+#endif
+#ifdef __nvapi_undef__inout_bcount_full
+    #undef __inout_bcount_full
+    #undef __nvapi_undef__inout_bcount_full
+#endif
+#ifdef __nvapi_undef__inout_z
+    #undef __inout_z
+    #undef __nvapi_undef__inout_z
+#endif
+#ifdef __nvapi_undef__inout_ecount_z
+    #undef __inout_ecount_z
+    #undef __nvapi_undef__inout_ecount_z
+#endif
+#ifdef __nvapi_undef__inout_bcount_z
+    #undef __inout_bcount_z
+    #undef __nvapi_undef__inout_bcount_z
+#endif
+#ifdef __nvapi_undef__inout_nz
+    #undef __inout_nz
+    #undef __nvapi_undef__inout_nz
+#endif
+#ifdef __nvapi_undef__inout_ecount_nz
+    #undef __inout_ecount_nz
+    #undef __nvapi_undef__inout_ecount_nz
+#endif
+#ifdef __nvapi_undef__inout_bcount_nz
+    #undef __inout_bcount_nz
+    #undef __nvapi_undef__inout_bcount_nz
+#endif
+#ifdef __nvapi_undef__ecount_opt
+    #undef __ecount_opt
+    #undef __nvapi_undef__ecount_opt
+#endif
+#ifdef __nvapi_undef__bcount_opt
+    #undef __bcount_opt
+    #undef __nvapi_undef__bcount_opt
+#endif
+#ifdef __nvapi_undef__in_opt
+    #undef __in_opt
+    #undef __nvapi_undef__in_opt
+#endif
+#ifdef __nvapi_undef__in_ecount_opt
+    #undef __in_ecount_opt
+    #undef __nvapi_undef__in_ecount_opt
+#endif
+#ifdef __nvapi_undef__in_bcount_opt
+    #undef __in_bcount_opt
+    #undef __nvapi_undef__in_bcount_opt
+#endif
+#ifdef __nvapi_undef__in_z_opt
+    #undef __in_z_opt
+    #undef __nvapi_undef__in_z_opt
+#endif
+#ifdef __nvapi_undef__in_ecount_z_opt
+    #undef __in_ecount_z_opt
+    #undef __nvapi_undef__in_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__in_bcount_z_opt
+    #undef __in_bcount_z_opt
+    #undef __nvapi_undef__in_bcount_z_opt
+#endif
+#ifdef __nvapi_undef__in_nz_opt
+    #undef __in_nz_opt
+    #undef __nvapi_undef__in_nz_opt
+#endif
+#ifdef __nvapi_undef__in_ecount_nz_opt
+    #undef __in_ecount_nz_opt
+    #undef __nvapi_undef__in_ecount_nz_opt
+#endif
+#ifdef __nvapi_undef__in_bcount_nz_opt
+    #undef __in_bcount_nz_opt
+    #undef __nvapi_undef__in_bcount_nz_opt
+#endif
+#ifdef __nvapi_undef__out_opt
+    #undef __out_opt
+    #undef __nvapi_undef__out_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_opt
+    #undef __out_ecount_opt
+    #undef __nvapi_undef__out_ecount_opt
+#endif
+#ifdef __nvapi_undef__out_bcount_opt
+    #undef __out_bcount_opt
+    #undef __nvapi_undef__out_bcount_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_part_opt
+    #undef __out_ecount_part_opt
+    #undef __nvapi_undef__out_ecount_part_opt
+#endif
+#ifdef __nvapi_undef__out_bcount_part_opt
+    #undef __out_bcount_part_opt
+    #undef __nvapi_undef__out_bcount_part_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_full_opt
+    #undef __out_ecount_full_opt
+    #undef __nvapi_undef__out_ecount_full_opt
+#endif
+#ifdef __nvapi_undef__out_bcount_full_opt
+    #undef __out_bcount_full_opt
+    #undef __nvapi_undef__out_bcount_full_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_z_opt
+    #undef __out_ecount_z_opt
+    #undef __nvapi_undef__out_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__out_bcount_z_opt
+    #undef __out_bcount_z_opt
+    #undef __nvapi_undef__out_bcount_z_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_part_z_opt
+    #undef __out_ecount_part_z_opt
+    #undef __nvapi_undef__out_ecount_part_z_opt
+#endif
+#ifdef __nvapi_undef__out_bcount_part_z_opt
+    #undef __out_bcount_part_z_opt
+    #undef __nvapi_undef__out_bcount_part_z_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_full_z_opt
+    #undef __out_ecount_full_z_opt
+    #undef __nvapi_undef__out_ecount_full_z_opt
+#endif
+#ifdef __nvapi_undef__out_bcount_full_z_opt
+    #undef __out_bcount_full_z_opt
+    #undef __nvapi_undef__out_bcount_full_z_opt
+#endif
+#ifdef __nvapi_undef__out_ecount_nz_opt
+    #undef __out_ecount_nz_opt
+    #undef __nvapi_undef__out_ecount_nz_opt
+#endif
+#ifdef __nvapi_undef__out_bcount_nz_opt
+    #undef __out_bcount_nz_opt
+    #undef __nvapi_undef__out_bcount_nz_opt
+#endif
+#ifdef __nvapi_undef__inout_opt
+    #undef __inout_opt
+    #undef __nvapi_undef__inout_opt
+#endif
+#ifdef __nvapi_undef__inout_ecount_opt
+    #undef __inout_ecount_opt
+    #undef __nvapi_undef__inout_ecount_opt
+#endif
+#ifdef __nvapi_undef__inout_bcount_opt
+    #undef __inout_bcount_opt
+    #undef __nvapi_undef__inout_bcount_opt
+#endif
+#ifdef __nvapi_undef__inout_ecount_part_opt
+    #undef __inout_ecount_part_opt
+    #undef __nvapi_undef__inout_ecount_part_opt
+#endif
+#ifdef __nvapi_undef__inout_bcount_part_opt
+    #undef __inout_bcount_part_opt
+    #undef __nvapi_undef__inout_bcount_part_opt
+#endif
+#ifdef __nvapi_undef__inout_ecount_full_opt
+    #undef __inout_ecount_full_opt
+    #undef __nvapi_undef__inout_ecount_full_opt
+#endif
+#ifdef __nvapi_undef__inout_bcount_full_opt
+    #undef __inout_bcount_full_opt
+    #undef __nvapi_undef__inout_bcount_full_opt
+#endif
+#ifdef __nvapi_undef__inout_z_opt
+    #undef __inout_z_opt
+    #undef __nvapi_undef__inout_z_opt
+#endif
+#ifdef __nvapi_undef__inout_ecount_z_opt
+    #undef __inout_ecount_z_opt
+    #undef __nvapi_undef__inout_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__inout_ecount_z_opt
+    #undef __inout_ecount_z_opt
+    #undef __nvapi_undef__inout_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__inout_bcount_z_opt
+    #undef __inout_bcount_z_opt
+    #undef __nvapi_undef__inout_bcount_z_opt
+#endif
+#ifdef __nvapi_undef__inout_nz_opt
+    #undef __inout_nz_opt
+    #undef __nvapi_undef__inout_nz_opt
+#endif
+#ifdef __nvapi_undef__inout_ecount_nz_opt
+    #undef __inout_ecount_nz_opt
+    #undef __nvapi_undef__inout_ecount_nz_opt
+#endif
+#ifdef __nvapi_undef__inout_bcount_nz_opt
+    #undef __inout_bcount_nz_opt
+    #undef __nvapi_undef__inout_bcount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_ecount
+    #undef __deref_ecount
+    #undef __nvapi_undef__deref_ecount
+#endif
+#ifdef __nvapi_undef__deref_bcount
+    #undef __deref_bcount
+    #undef __nvapi_undef__deref_bcount
+#endif
+#ifdef __nvapi_undef__deref_out
+    #undef __deref_out
+    #undef __nvapi_undef__deref_out
+#endif
+#ifdef __nvapi_undef__deref_out_ecount
+    #undef __deref_out_ecount
+    #undef __nvapi_undef__deref_out_ecount
+#endif
+#ifdef __nvapi_undef__deref_out_bcount
+    #undef __deref_out_bcount
+    #undef __nvapi_undef__deref_out_bcount
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_part
+    #undef __deref_out_ecount_part
+    #undef __nvapi_undef__deref_out_ecount_part
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_part
+    #undef __deref_out_bcount_part
+    #undef __nvapi_undef__deref_out_bcount_part
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_full
+    #undef __deref_out_ecount_full
+    #undef __nvapi_undef__deref_out_ecount_full
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_full
+    #undef __deref_out_bcount_full
+    #undef __nvapi_undef__deref_out_bcount_full
+#endif
+#ifdef __nvapi_undef__deref_out_z
+    #undef __deref_out_z
+    #undef __nvapi_undef__deref_out_z
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_z
+    #undef __deref_out_ecount_z
+    #undef __nvapi_undef__deref_out_ecount_z
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_z
+    #undef __deref_out_bcount_z
+    #undef __nvapi_undef__deref_out_bcount_z
+#endif
+#ifdef __nvapi_undef__deref_out_nz
+    #undef __deref_out_nz
+    #undef __nvapi_undef__deref_out_nz
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_nz
+    #undef __deref_out_ecount_nz
+    #undef __nvapi_undef__deref_out_ecount_nz
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_nz
+    #undef __deref_out_bcount_nz
+    #undef __nvapi_undef__deref_out_bcount_nz
+#endif
+#ifdef __nvapi_undef__deref_inout
+    #undef __deref_inout
+    #undef __nvapi_undef__deref_inout
+#endif
+#ifdef __nvapi_undef__deref_inout_z
+    #undef __deref_inout_z
+    #undef __nvapi_undef__deref_inout_z
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount
+    #undef __deref_inout_ecount
+    #undef __nvapi_undef__deref_inout_ecount
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount
+    #undef __deref_inout_bcount
+    #undef __nvapi_undef__deref_inout_bcount
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_part
+    #undef __deref_inout_ecount_part
+    #undef __nvapi_undef__deref_inout_ecount_part
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_part
+    #undef __deref_inout_bcount_part
+    #undef __nvapi_undef__deref_inout_bcount_part
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_full
+    #undef __deref_inout_ecount_full
+    #undef __nvapi_undef__deref_inout_ecount_full
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_full
+    #undef __deref_inout_bcount_full
+    #undef __nvapi_undef__deref_inout_bcount_full
+#endif
+#ifdef __nvapi_undef__deref_inout_z
+    #undef __deref_inout_z
+    #undef __nvapi_undef__deref_inout_z
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_z
+    #undef __deref_inout_ecount_z
+    #undef __nvapi_undef__deref_inout_ecount_z
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_z
+    #undef __deref_inout_bcount_z
+    #undef __nvapi_undef__deref_inout_bcount_z
+#endif
+#ifdef __nvapi_undef__deref_inout_nz
+    #undef __deref_inout_nz
+    #undef __nvapi_undef__deref_inout_nz
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_nz
+    #undef __deref_inout_ecount_nz
+    #undef __nvapi_undef__deref_inout_ecount_nz
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_nz
+    #undef __deref_inout_bcount_nz
+    #undef __nvapi_undef__deref_inout_bcount_nz
+#endif
+#ifdef __nvapi_undef__deref_ecount_opt
+    #undef __deref_ecount_opt
+    #undef __nvapi_undef__deref_ecount_opt
+#endif
+#ifdef __nvapi_undef__deref_bcount_opt
+    #undef __deref_bcount_opt
+    #undef __nvapi_undef__deref_bcount_opt
+#endif
+#ifdef __nvapi_undef__deref_out_opt
+    #undef __deref_out_opt
+    #undef __nvapi_undef__deref_out_opt
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_opt
+    #undef __deref_out_ecount_opt
+    #undef __nvapi_undef__deref_out_ecount_opt
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_opt
+    #undef __deref_out_bcount_opt
+    #undef __nvapi_undef__deref_out_bcount_opt
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_part_opt
+    #undef __deref_out_ecount_part_opt
+    #undef __nvapi_undef__deref_out_ecount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_part_opt
+    #undef __deref_out_bcount_part_opt
+    #undef __nvapi_undef__deref_out_bcount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_full_opt
+    #undef __deref_out_ecount_full_opt
+    #undef __nvapi_undef__deref_out_ecount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_full_opt
+    #undef __deref_out_bcount_full_opt
+    #undef __nvapi_undef__deref_out_bcount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_out_z_opt
+    #undef __deref_out_z_opt
+    #undef __nvapi_undef__deref_out_z_opt
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_z_opt
+    #undef __deref_out_ecount_z_opt
+    #undef __nvapi_undef__deref_out_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_z_opt
+    #undef __deref_out_bcount_z_opt
+    #undef __nvapi_undef__deref_out_bcount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_out_nz_opt
+    #undef __deref_out_nz_opt
+    #undef __nvapi_undef__deref_out_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_out_ecount_nz_opt
+    #undef __deref_out_ecount_nz_opt
+    #undef __nvapi_undef__deref_out_ecount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_out_bcount_nz_opt
+    #undef __deref_out_bcount_nz_opt
+    #undef __nvapi_undef__deref_out_bcount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_opt
+    #undef __deref_inout_opt
+    #undef __nvapi_undef__deref_inout_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_opt
+    #undef __deref_inout_ecount_opt
+    #undef __nvapi_undef__deref_inout_ecount_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_opt
+    #undef __deref_inout_bcount_opt
+    #undef __nvapi_undef__deref_inout_bcount_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_part_opt
+    #undef __deref_inout_ecount_part_opt
+    #undef __nvapi_undef__deref_inout_ecount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_part_opt
+    #undef __deref_inout_bcount_part_opt
+    #undef __nvapi_undef__deref_inout_bcount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_full_opt
+    #undef __deref_inout_ecount_full_opt
+    #undef __nvapi_undef__deref_inout_ecount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_full_opt
+    #undef __deref_inout_bcount_full_opt
+    #undef __nvapi_undef__deref_inout_bcount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_z_opt
+    #undef __deref_inout_z_opt
+    #undef __nvapi_undef__deref_inout_z_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_z_opt
+    #undef __deref_inout_ecount_z_opt
+    #undef __nvapi_undef__deref_inout_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_z_opt
+    #undef __deref_inout_bcount_z_opt
+    #undef __nvapi_undef__deref_inout_bcount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_nz_opt
+    #undef __deref_inout_nz_opt
+    #undef __nvapi_undef__deref_inout_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_ecount_nz_opt
+    #undef __deref_inout_ecount_nz_opt
+    #undef __nvapi_undef__deref_inout_ecount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_inout_bcount_nz_opt
+    #undef __deref_inout_bcount_nz_opt
+    #undef __nvapi_undef__deref_inout_bcount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_ecount
+    #undef __deref_opt_ecount
+    #undef __nvapi_undef__deref_opt_ecount
+#endif
+#ifdef __nvapi_undef__deref_opt_bcount
+    #undef __deref_opt_bcount
+    #undef __nvapi_undef__deref_opt_bcount
+#endif
+#ifdef __nvapi_undef__deref_opt_out
+    #undef __deref_opt_out
+    #undef __nvapi_undef__deref_opt_out
+#endif
+#ifdef __nvapi_undef__deref_opt_out_z
+    #undef __deref_opt_out_z
+    #undef __nvapi_undef__deref_opt_out_z
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount
+    #undef __deref_opt_out_ecount
+    #undef __nvapi_undef__deref_opt_out_ecount
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount
+    #undef __deref_opt_out_bcount
+    #undef __nvapi_undef__deref_opt_out_bcount
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount_part
+    #undef __deref_opt_out_ecount_part
+    #undef __nvapi_undef__deref_opt_out_ecount_part
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount_part
+    #undef __deref_opt_out_bcount_part
+    #undef __nvapi_undef__deref_opt_out_bcount_part
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount_full
+    #undef __deref_opt_out_ecount_full
+    #undef __nvapi_undef__deref_opt_out_ecount_full
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount_full
+    #undef __deref_opt_out_bcount_full
+    #undef __nvapi_undef__deref_opt_out_bcount_full
+#endif
+#ifdef __nvapi_undef__deref_opt_inout
+    #undef __deref_opt_inout
+    #undef __nvapi_undef__deref_opt_inout
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount
+    #undef __deref_opt_inout_ecount
+    #undef __nvapi_undef__deref_opt_inout_ecount
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount
+    #undef __deref_opt_inout_bcount
+    #undef __nvapi_undef__deref_opt_inout_bcount
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_part
+    #undef __deref_opt_inout_ecount_part
+    #undef __nvapi_undef__deref_opt_inout_ecount_part
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_part
+    #undef __deref_opt_inout_bcount_part
+    #undef __nvapi_undef__deref_opt_inout_bcount_part
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_full
+    #undef __deref_opt_inout_ecount_full
+    #undef __nvapi_undef__deref_opt_inout_ecount_full
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_full
+    #undef __deref_opt_inout_bcount_full
+    #undef __nvapi_undef__deref_opt_inout_bcount_full
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_z
+    #undef __deref_opt_inout_z
+    #undef __nvapi_undef__deref_opt_inout_z
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_z
+    #undef __deref_opt_inout_ecount_z
+    #undef __nvapi_undef__deref_opt_inout_ecount_z
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_z
+    #undef __deref_opt_inout_bcount_z
+    #undef __nvapi_undef__deref_opt_inout_bcount_z
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_nz
+    #undef __deref_opt_inout_nz
+    #undef __nvapi_undef__deref_opt_inout_nz
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_nz
+    #undef __deref_opt_inout_ecount_nz
+    #undef __nvapi_undef__deref_opt_inout_ecount_nz
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_nz
+    #undef __deref_opt_inout_bcount_nz
+    #undef __nvapi_undef__deref_opt_inout_bcount_nz
+#endif
+#ifdef __nvapi_undef__deref_opt_ecount_opt
+    #undef __deref_opt_ecount_opt
+    #undef __nvapi_undef__deref_opt_ecount_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_bcount_opt
+    #undef __deref_opt_bcount_opt
+    #undef __nvapi_undef__deref_opt_bcount_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_opt
+    #undef __deref_opt_out_opt
+    #undef __nvapi_undef__deref_opt_out_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount_opt
+    #undef __deref_opt_out_ecount_opt
+    #undef __nvapi_undef__deref_opt_out_ecount_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount_opt
+    #undef __deref_opt_out_bcount_opt
+    #undef __nvapi_undef__deref_opt_out_bcount_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount_part_opt
+    #undef __deref_opt_out_ecount_part_opt
+    #undef __nvapi_undef__deref_opt_out_ecount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount_part_opt
+    #undef __deref_opt_out_bcount_part_opt
+    #undef __nvapi_undef__deref_opt_out_bcount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount_full_opt
+    #undef __deref_opt_out_ecount_full_opt
+    #undef __nvapi_undef__deref_opt_out_ecount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount_full_opt
+    #undef __deref_opt_out_bcount_full_opt
+    #undef __nvapi_undef__deref_opt_out_bcount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_z_opt
+    #undef __deref_opt_out_z_opt
+    #undef __nvapi_undef__deref_opt_out_z_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount_z_opt
+    #undef __deref_opt_out_ecount_z_opt
+    #undef __nvapi_undef__deref_opt_out_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount_z_opt
+    #undef __deref_opt_out_bcount_z_opt
+    #undef __nvapi_undef__deref_opt_out_bcount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_nz_opt
+    #undef __deref_opt_out_nz_opt
+    #undef __nvapi_undef__deref_opt_out_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_ecount_nz_opt
+    #undef __deref_opt_out_ecount_nz_opt
+    #undef __nvapi_undef__deref_opt_out_ecount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_out_bcount_nz_opt
+    #undef __deref_opt_out_bcount_nz_opt
+    #undef __nvapi_undef__deref_opt_out_bcount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_opt
+    #undef __deref_opt_inout_opt
+    #undef __nvapi_undef__deref_opt_inout_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_opt
+    #undef __deref_opt_inout_ecount_opt
+    #undef __nvapi_undef__deref_opt_inout_ecount_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_opt
+    #undef __deref_opt_inout_bcount_opt
+    #undef __nvapi_undef__deref_opt_inout_bcount_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_part_opt
+    #undef __deref_opt_inout_ecount_part_opt
+    #undef __nvapi_undef__deref_opt_inout_ecount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_part_opt
+    #undef __deref_opt_inout_bcount_part_opt
+    #undef __nvapi_undef__deref_opt_inout_bcount_part_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_full_opt
+    #undef __deref_opt_inout_ecount_full_opt
+    #undef __nvapi_undef__deref_opt_inout_ecount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_full_opt
+    #undef __deref_opt_inout_bcount_full_opt
+    #undef __nvapi_undef__deref_opt_inout_bcount_full_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_z_opt
+    #undef __deref_opt_inout_z_opt
+    #undef __nvapi_undef__deref_opt_inout_z_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_z_opt
+    #undef __deref_opt_inout_ecount_z_opt
+    #undef __nvapi_undef__deref_opt_inout_ecount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_z_opt
+    #undef __deref_opt_inout_bcount_z_opt
+    #undef __nvapi_undef__deref_opt_inout_bcount_z_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_nz_opt
+    #undef __deref_opt_inout_nz_opt
+    #undef __nvapi_undef__deref_opt_inout_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_ecount_nz_opt
+    #undef __deref_opt_inout_ecount_nz_opt
+    #undef __nvapi_undef__deref_opt_inout_ecount_nz_opt
+#endif
+#ifdef __nvapi_undef__deref_opt_inout_bcount_nz_opt
+    #undef __deref_opt_inout_bcount_nz_opt
+    #undef __nvapi_undef__deref_opt_inout_bcount_nz_opt
+#endif
+#ifdef __nvapi_success
+    #undef __success
+    #undef __nvapi_success
+#endif
+#ifdef __nvapi__Ret_notnull_
+    #undef __nvapi__Ret_notnull_
+    #undef _Ret_notnull_
+#endif
+#ifdef __nvapi__Post_writable_byte_size_
+    #undef __nvapi__Post_writable_byte_size_
+    #undef _Post_writable_byte_size_
+#endif
+#ifdef __nvapi_Outptr_ 
+    #undef __nvapi_Outptr_ 
+    #undef _Outptr_ 
+#endif
+
+#endif // __NVAPI_EMPTY_SAL
+
+#ifdef __cplusplus
+}; //extern "C" {
+
+#endif
+
+#pragma pack(pop)
+
+#endif // _NVAPI_H
\ No newline at end of file
diff --git a/include/vkd3d_command_list_vkd3d_ext.idl b/include/vkd3d_command_list_vkd3d_ext.idl
index e57fe145..f8870974 100644
--- a/include/vkd3d_command_list_vkd3d_ext.idl
+++ b/include/vkd3d_command_list_vkd3d_ext.idl
@@ -40,3 +40,17 @@ interface ID3D12GraphicsCommandListExt1 : ID3D12GraphicsCommandListExt
 {
    HRESULT LaunchCubinShaderEx(D3D12_CUBIN_DATA_HANDLE *handle, UINT32 block_x, UINT32 block_y, UINT32 block_z, UINT32 smem_size, const void *params, UINT32 param_size, const void *raw_params, UINT32 raw_params_count);
 }
+
+[
+    uuid(d53b0028-afb4-4b65-a4f1-7b0daaa65b50),
+    object,
+    local,
+    pointer_default(unique)
+]
+interface ID3D12GraphicsCommandListExt2 : ID3D12GraphicsCommandListExt1
+{
+   HRESULT BuildRaytracingAccelerationStructureEx(const void *params);
+   HRESULT BuildRaytracingOpacityMicromapArray(void *params);
+   HRESULT RelocateRaytracingOpacityMicromapArray(const void *params);
+   HRESULT EmitRaytracingOpacityMicromapArrayPostbuildInfo(const void *params);
+}
diff --git a/include/vkd3d_device_vkd3d_ext.idl b/include/vkd3d_device_vkd3d_ext.idl
index 3e615d76..41dab628 100644
--- a/include/vkd3d_device_vkd3d_ext.idl
+++ b/include/vkd3d_device_vkd3d_ext.idl
@@ -35,6 +35,20 @@ interface ID3D12DeviceExt : IUnknown
     HRESULT CaptureUAVInfo(D3D12_UAV_INFO *uav_info);
 }
 
+[
+    uuid(11ea7a1a-0f6a-49bf-b612-3e30f8e201de),
+    object,
+    local,
+    pointer_default(unique)
+]
+interface ID3D12DeviceExt1 : ID3D12DeviceExt
+{
+    HRESULT SetCreatePipelineStateOptions(const void *params);
+    HRESULT CheckDriverMatchingIdentifierEx(void *params);
+    HRESULT GetRaytracingAccelerationStructurePrebuildInfoEx(void *params);
+    HRESULT GetRaytracingOpacityMicromapArrayPrebuildInfo(void *params);
+}
+
 [
     uuid(39da4e09-bd1c-4198-9fae-86bbe3be41fd),
     object,
diff --git a/include/vkd3d_shader.h b/include/vkd3d_shader.h
index 9066814a..e22c7d3f 100644
--- a/include/vkd3d_shader.h
+++ b/include/vkd3d_shader.h
@@ -368,6 +368,7 @@ enum vkd3d_shader_target_extension
     VKD3D_SHADER_TARGET_EXTENSION_SUPPORT_FP16_DENORM_PRESERVE,
     VKD3D_SHADER_TARGET_EXTENSION_SUPPORT_FP64_DENORM_PRESERVE,
     VKD3D_SHADER_TARGET_EXTENSION_SUPPORT_SUBGROUP_PARTITIONED_NV,
+    VKD3D_SHADER_TARGET_EXTENSION_OPACITY_MICROMAP,
     VKD3D_SHADER_TARGET_EXTENSION_COUNT,
 };
 
diff --git a/include/vkd3d_vk_includes.h b/include/vkd3d_vk_includes.h
index c43e0189..a4afd34b 100644
--- a/include/vkd3d_vk_includes.h
+++ b/include/vkd3d_vk_includes.h
@@ -40,6 +40,7 @@ typedef enum VkImageLayout VkImageLayout;
 
 typedef enum D3D12_VK_EXTENSION
 {
+    D3D12_VK_EXT_OPACITY_MICROMAP   = 0x0,
     D3D12_VK_NVX_BINARY_IMPORT      = 0x1,
     D3D12_VK_NVX_IMAGE_VIEW_HANDLE  = 0x2,
     D3D12_VK_NV_LOW_LATENCY_2       = 0x3
diff --git a/libs/vkd3d-shader/dxil.c b/libs/vkd3d-shader/dxil.c
index dd2f4423..a0aa9229 100644
--- a/libs/vkd3d-shader/dxil.c
+++ b/libs/vkd3d-shader/dxil.c
@@ -919,6 +919,17 @@ int vkd3d_shader_compile_dxil(const struct vkd3d_shader_code *dxbc,
                     goto end;
                 }
             }
+            else if (compiler_args->target_extensions[i] == VKD3D_SHADER_TARGET_EXTENSION_OPACITY_MICROMAP)
+            {
+                static const dxil_spv_option_opacity_micromap helper =
+                        { { DXIL_SPV_OPTION_OPACITY_MICROMAP }, DXIL_SPV_TRUE };
+                if (dxil_spv_converter_add_option(converter, &helper.base) != DXIL_SPV_SUCCESS)
+                {
+                    ERR("dxil-spirv does not support OPACITY_MICROMAP.\n");
+                    ret = VKD3D_ERROR_NOT_IMPLEMENTED;
+                    goto end;
+                }
+            }
         }
 
         if (dxil_spv_converter_add_option(converter, &denorm_preserve.base) != DXIL_SPV_SUCCESS)
@@ -1549,6 +1560,17 @@ int vkd3d_shader_compile_dxil_export(const struct vkd3d_shader_code *dxil,
                     goto end;
                 }
             }
+            else if (compiler_args->target_extensions[i] == VKD3D_SHADER_TARGET_EXTENSION_OPACITY_MICROMAP)
+            {
+                static const dxil_spv_option_opacity_micromap helper =
+                        { { DXIL_SPV_OPTION_OPACITY_MICROMAP }, DXIL_SPV_TRUE };
+                if (dxil_spv_converter_add_option(converter, &helper.base) != DXIL_SPV_SUCCESS)
+                {
+                    ERR("dxil-spirv does not support OPACITY_MICROMAP.\n");
+                    ret = VKD3D_ERROR_NOT_IMPLEMENTED;
+                    goto end;
+                }
+            }
         }
     }
 
diff --git a/libs/vkd3d/acceleration_structure.c b/libs/vkd3d/acceleration_structure.c
index 5e9cda01..19482682 100644
--- a/libs/vkd3d/acceleration_structure.c
+++ b/libs/vkd3d/acceleration_structure.c
@@ -40,6 +40,22 @@ static VkBuildAccelerationStructureFlagsKHR d3d12_build_flags_to_vk(
     return vk_flags;
 }
 
+static VkBuildAccelerationStructureFlagsKHR nv_build_flags_to_vk(
+        NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS_EX flags)
+{
+    VkBuildAccelerationStructureFlagsKHR vk_flags = d3d12_build_flags_to_vk(
+        (D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAGS)flags);
+
+    if (flags & NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_OMM_UPDATE_EX)
+        vk_flags |= VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_OPACITY_MICROMAP_UPDATE_EXT;
+    if (flags & NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_DISABLE_OMMS_EX)
+        vk_flags |= VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_DISABLE_OPACITY_MICROMAPS_EXT;
+    if (flags & NVAPI_D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_ALLOW_OMM_OPACITY_STATES_UPDATE_EX)
+        vk_flags |= VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_OPACITY_MICROMAP_DATA_UPDATE_EXT;
+
+    return vk_flags;
+}
+
 static VkGeometryFlagsKHR d3d12_geometry_flags_to_vk(D3D12_RAYTRACING_GEOMETRY_FLAGS flags)
 {
     VkGeometryFlagsKHR vk_flags = 0;
@@ -61,6 +77,15 @@ uint32_t vkd3d_acceleration_structure_get_geometry_count(
         return desc->NumDescs;
 }
 
+uint32_t vkd3d_acceleration_structure_get_geometry_count_nv(
+        const NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX *desc)
+{
+    if (desc->type == D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL)
+        return 1;
+    else
+        return desc->numDescs;
+}
+
 bool vkd3d_acceleration_structure_convert_inputs(const struct d3d12_device *device,
         const D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS *desc,
         VkAccelerationStructureBuildGeometryInfoKHR *build_info,
@@ -251,6 +276,274 @@ bool vkd3d_acceleration_structure_convert_inputs(const struct d3d12_device *devi
     return true;
 }
 
+bool vkd3d_acceleration_structure_convert_inputs_nv(struct d3d12_device *device,
+        const NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX *desc,
+        VkAccelerationStructureBuildGeometryInfoKHR *build_info,
+        VkAccelerationStructureGeometryKHR *geometry_infos,
+        VkAccelerationStructureTrianglesOpacityMicromapEXT *omm_infos,
+        VkAccelerationStructureBuildRangeInfoKHR *range_infos,
+        uint32_t *primitive_counts)
+{
+    VkAccelerationStructureTrianglesOpacityMicromapEXT *opacity_micromap;
+    VkAccelerationStructureGeometryTrianglesDataKHR *triangles;
+    VkAccelerationStructureGeometryAabbsDataKHR *aabbs;
+    const NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX *geom_desc;
+    bool have_triangles, have_aabbs;
+    uint32_t primitive_count;
+    unsigned int i;
+
+    RT_TRACE("Converting inputs.\n");
+    RT_TRACE("=====================\n");
+
+    memset(build_info, 0, sizeof(*build_info));
+    build_info->sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_GEOMETRY_INFO_KHR;
+
+    if (desc->type == D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL)
+    {
+        build_info->type = VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR;
+        RT_TRACE("Top level build.\n");
+    }
+    else
+    {
+        build_info->type = VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_KHR;
+        RT_TRACE("Bottom level build.\n");
+    }
+
+    build_info->flags = nv_build_flags_to_vk(desc->flags);
+
+    if (desc->flags & D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_PERFORM_UPDATE)
+    {
+        RT_TRACE("BUILD_FLAG_PERFORM_UPDATE.\n");
+        build_info->mode = VK_BUILD_ACCELERATION_STRUCTURE_MODE_UPDATE_KHR;
+    }
+    else
+        build_info->mode = VK_BUILD_ACCELERATION_STRUCTURE_MODE_BUILD_KHR;
+
+    if (desc->type == D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL)
+    {
+        memset(geometry_infos, 0, sizeof(*geometry_infos));
+        geometry_infos[0].sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_KHR;
+        geometry_infos[0].geometryType = VK_GEOMETRY_TYPE_INSTANCES_KHR;
+        geometry_infos[0].geometry.instances.sType =
+                VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_INSTANCES_DATA_KHR;
+        geometry_infos[0].geometry.instances.arrayOfPointers =
+                desc->descsLayout == D3D12_ELEMENTS_LAYOUT_ARRAY_OF_POINTERS ? VK_TRUE : VK_FALSE;
+        geometry_infos[0].geometry.instances.data.deviceAddress = desc->instanceDescs;
+
+        if (primitive_counts)
+            primitive_counts[0] = desc->numDescs;
+
+        if (range_infos)
+        {
+            range_infos[0].primitiveCount = desc->numDescs;
+            range_infos[0].firstVertex = 0;
+            range_infos[0].primitiveOffset = 0;
+            range_infos[0].transformOffset = 0;
+        }
+
+        build_info->geometryCount = 1;
+        RT_TRACE("  ArrayOfPointers: %u.\n",
+                desc->descsLayout == D3D12_ELEMENTS_LAYOUT_ARRAY_OF_POINTERS ? 1 : 0);
+        RT_TRACE("  NumDescs: %u.\n", desc->numDescs);
+    }
+    else
+    {
+        have_triangles = false;
+        have_aabbs = false;
+
+        memset(geometry_infos, 0, sizeof(*geometry_infos) * desc->numDescs);
+        memset(omm_infos, 0, sizeof(*omm_infos) * desc->numDescs);
+
+        if (primitive_counts)
+            memset(primitive_counts, 0, sizeof(*primitive_counts) * desc->numDescs);
+
+        build_info->geometryCount = desc->numDescs;
+
+        for (i = 0; i < desc->numDescs; i++)
+        {
+            geometry_infos[i].sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_KHR;
+            RT_TRACE(" Geom %u:\n", i);
+
+            if (desc->descsLayout == D3D12_ELEMENTS_LAYOUT_ARRAY_OF_POINTERS)
+            {
+                geom_desc = desc->ppGeometryDescs[i];
+                RT_TRACE("  ArrayOfPointers\n");
+            }
+            else
+            {
+                geom_desc = (const NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX *)(((const char *)desc->pGeometryDescs) + desc->geometryDescStrideInBytes * i);
+                RT_TRACE("  PointerToArray\n");
+            }
+
+            geometry_infos[i].flags = d3d12_geometry_flags_to_vk(geom_desc->flags);
+            RT_TRACE("  Flags = #%x\n", geom_desc->flags);
+
+            switch (geom_desc->type)
+            {
+                case D3D12_RAYTRACING_GEOMETRY_TYPE_TRIANGLES:
+                    if (have_aabbs)
+                    {
+                        ERR("Cannot mix and match geometry types in a BLAS.\n");
+                        return false;
+                    }
+                    have_triangles = true;
+
+                    geometry_infos[i].geometryType = VK_GEOMETRY_TYPE_TRIANGLES_KHR;
+                    triangles = &geometry_infos[i].geometry.triangles;
+                    triangles->sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_TRIANGLES_DATA_KHR;
+                    triangles->indexData.deviceAddress = geom_desc->triangles.IndexBuffer;
+                    if (geom_desc->triangles.IndexFormat != DXGI_FORMAT_UNKNOWN)
+                    {
+                        if (!geom_desc->triangles.IndexBuffer)
+                            WARN("Application is using IndexBuffer = 0 and IndexFormat != UNKNOWN. Likely application bug.\n");
+
+                        triangles->indexType =
+                                geom_desc->triangles.IndexFormat == DXGI_FORMAT_R16_UINT ?
+                                        VK_INDEX_TYPE_UINT16 : VK_INDEX_TYPE_UINT32;
+                        primitive_count = geom_desc->triangles.IndexCount / 3;
+                        RT_TRACE("  Indexed : Index count = %u (%u bits)\n",
+                                geom_desc->triangles.IndexCount,
+                                triangles->indexType == VK_INDEX_TYPE_UINT16 ? 16 : 32);
+                        RT_TRACE("  Vertex count: %u\n", geom_desc->triangles.VertexCount);
+                        RT_TRACE("  IBO VA: %"PRIx64".\n", geom_desc->triangles.IndexBuffer);
+                    }
+                    else
+                    {
+                        primitive_count = geom_desc->triangles.VertexCount / 3;
+                        triangles->indexType = VK_INDEX_TYPE_NONE_KHR;
+                        RT_TRACE("  Triangle list : Vertex count: %u\n", geom_desc->triangles.VertexCount);
+                    }
+
+                    triangles->maxVertex = max(1, geom_desc->triangles.VertexCount) - 1;
+                    triangles->vertexStride = geom_desc->triangles.VertexBuffer.StrideInBytes;
+                    triangles->vertexFormat = vkd3d_internal_get_vk_format(device, geom_desc->triangles.VertexFormat);
+                    triangles->vertexData.deviceAddress = geom_desc->triangles.VertexBuffer.StartAddress;
+                    triangles->transformData.deviceAddress = geom_desc->triangles.Transform3x4;
+
+                    RT_TRACE("  Transform3x4: %s\n", geom_desc->triangles.Transform3x4 ? "on" : "off");
+                    RT_TRACE("  Vertex format: %s\n", debug_dxgi_format(geom_desc->triangles.VertexFormat));
+                    RT_TRACE("  VBO VA: %"PRIx64"\n", geom_desc->triangles.VertexBuffer.StartAddress);
+                    RT_TRACE("  Vertex stride: %"PRIu64" bytes\n", geom_desc->triangles.VertexBuffer.StrideInBytes);
+                    break;
+
+                case D3D12_RAYTRACING_GEOMETRY_TYPE_PROCEDURAL_PRIMITIVE_AABBS:
+                    if (have_triangles)
+                    {
+                        ERR("Cannot mix and match geometry types in a BLAS.\n");
+                        return false;
+                    }
+                    have_aabbs = true;
+
+                    geometry_infos[i].geometryType = VK_GEOMETRY_TYPE_AABBS_KHR;
+                    aabbs = &geometry_infos[i].geometry.aabbs;
+                    aabbs->sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_AABBS_DATA_KHR;
+                    aabbs->stride = geom_desc->aabbs.AABBs.StrideInBytes;
+                    aabbs->data.deviceAddress = geom_desc->aabbs.AABBs.StartAddress;
+                    primitive_count = geom_desc->aabbs.AABBCount;
+                    RT_TRACE("  AABB stride: %"PRIu64" bytes\n", geom_desc->aabbs.AABBs.StrideInBytes);
+                    break;
+
+                case NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_OMM_TRIANGLES_EX:
+                    if (have_aabbs)
+                    {
+                        ERR("Cannot mix and match geometry types in a BLAS.\n");
+                        return false;
+                    }
+                    have_triangles = true;
+
+                    geometry_infos[i].geometryType = VK_GEOMETRY_TYPE_TRIANGLES_KHR;
+                    triangles = &geometry_infos[i].geometry.triangles;
+                    triangles->sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_TRIANGLES_DATA_KHR;
+                    triangles->indexData.deviceAddress = geom_desc->ommTriangles.triangles.IndexBuffer;
+                    if (geom_desc->ommTriangles.triangles.IndexFormat != DXGI_FORMAT_UNKNOWN)
+                    {
+                        if (!geom_desc->ommTriangles.triangles.IndexBuffer)
+                            WARN("Application is using IndexBuffer = 0 and IndexFormat != UNKNOWN. Likely application bug.\n");
+
+                        triangles->indexType =
+                                geom_desc->ommTriangles.triangles.IndexFormat == DXGI_FORMAT_R16_UINT ?
+                                        VK_INDEX_TYPE_UINT16 : VK_INDEX_TYPE_UINT32;
+                        primitive_count = geom_desc->ommTriangles.triangles.IndexCount / 3;
+                        RT_TRACE("  Indexed : Index count = %u (%u bits)\n",
+                                geom_desc->ommTriangles.triangles.IndexCount,
+                                triangles->indexType == VK_INDEX_TYPE_UINT16 ? 16 : 32);
+                        RT_TRACE("  Vertex count: %u\n", geom_desc->ommTriangles.triangles.VertexCount);
+                        RT_TRACE("  IBO VA: %"PRIx64".\n", geom_desc->ommTriangles.triangles.IndexBuffer);
+                    }
+                    else
+                    {
+                        primitive_count = geom_desc->ommTriangles.triangles.VertexCount / 3;
+                        triangles->indexType = VK_INDEX_TYPE_NONE_KHR;
+                        RT_TRACE("  Triangle list : Vertex count: %u\n", geom_desc->ommTriangles.triangles.VertexCount);
+                    }
+
+                    triangles->maxVertex = max(1, geom_desc->ommTriangles.triangles.VertexCount) - 1;
+                    triangles->vertexStride = geom_desc->ommTriangles.triangles.VertexBuffer.StrideInBytes;
+                    triangles->vertexFormat = vkd3d_internal_get_vk_format(device, geom_desc->ommTriangles.triangles.VertexFormat);
+                    triangles->vertexData.deviceAddress = geom_desc->ommTriangles.triangles.VertexBuffer.StartAddress;
+                    triangles->transformData.deviceAddress = geom_desc->ommTriangles.triangles.Transform3x4;
+
+                    RT_TRACE("  Transform3x4: %s\n", geom_desc->ommTriangles.triangles.Transform3x4 ? "on" : "off");
+                    RT_TRACE("  Vertex format: %s\n", debug_dxgi_format(geom_desc->ommTriangles.triangles.VertexFormat));
+                    RT_TRACE("  VBO VA: %"PRIx64"\n", geom_desc->ommTriangles.triangles.VertexBuffer.StartAddress);
+                    RT_TRACE("  Vertex stride: %"PRIu64" bytes\n", geom_desc->ommTriangles.triangles.VertexBuffer.StrideInBytes);
+
+                    triangles->pNext = opacity_micromap = &omm_infos[i];
+                    opacity_micromap->sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_TRIANGLES_OPACITY_MICROMAP_EXT;
+                    opacity_micromap->pNext = NULL;
+                    opacity_micromap->indexType =
+                                geom_desc->ommTriangles.ommAttachment.opacityMicromapIndexFormat == DXGI_FORMAT_R16_UINT ?
+                                        VK_INDEX_TYPE_UINT16 : VK_INDEX_TYPE_UINT32;
+                    opacity_micromap->indexBuffer.deviceAddress = geom_desc->ommTriangles.ommAttachment.opacityMicromapIndexBuffer.StartAddress;
+                    opacity_micromap->indexStride = geom_desc->ommTriangles.ommAttachment.opacityMicromapIndexBuffer.StrideInBytes;
+                    opacity_micromap->baseTriangle = geom_desc->ommTriangles.ommAttachment.opacityMicromapBaseLocation;
+
+                    if (geom_desc->ommTriangles.ommAttachment.numOMMUsageCounts && geom_desc->ommTriangles.ommAttachment.pOMMUsageCounts)
+                    {
+                        STATIC_ASSERT(sizeof(VkMicromapUsageEXT) == sizeof(NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT));
+                        STATIC_ASSERT(offsetof(VkMicromapUsageEXT, count) == offsetof(NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT, count));
+                        STATIC_ASSERT(offsetof(VkMicromapUsageEXT, subdivisionLevel) == offsetof(NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT, subdivisionLevel));
+                        STATIC_ASSERT(offsetof(VkMicromapUsageEXT, format) == offsetof(NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT, format));
+                        STATIC_ASSERT(sizeof(uint32_t) == sizeof(NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT));
+                        opacity_micromap->pUsageCounts = (const void *)geom_desc->ommTriangles.ommAttachment.pOMMUsageCounts;
+                        opacity_micromap->usageCountsCount = geom_desc->ommTriangles.ommAttachment.numOMMUsageCounts;
+                    }
+
+                    if (geom_desc->ommTriangles.ommAttachment.opacityMicromapArray)
+                        opacity_micromap->micromap = vkd3d_va_map_place_opacity_micromap(&device->memory_allocator.va_map, device, geom_desc->ommTriangles.ommAttachment.opacityMicromapArray);
+
+                    RT_TRACE("  OMM Index type: %s\n", debug_dxgi_format(geom_desc->ommTriangles.ommAttachment.opacityMicromapIndexFormat));
+                    RT_TRACE("  OMM IBO VA: %"PRIx64"\n", geom_desc->ommTriangles.ommAttachment.opacityMicromapIndexBuffer.StartAddress);
+                    RT_TRACE("  OMM Index stride: %"PRIu64" bytes\n", geom_desc->ommTriangles.ommAttachment.opacityMicromapIndexBuffer.StrideInBytes);
+                    RT_TRACE("  OMM Base: %u\n", geom_desc->ommTriangles.ommAttachment.opacityMicromapBaseLocation);
+                    RT_TRACE("  OMM Usage counts: %u\n", geom_desc->ommTriangles.ommAttachment.numOMMUsageCounts);
+                    RT_TRACE("  OMM Micromap VA: %"PRIx64"\n", geom_desc->ommTriangles.ommAttachment.opacityMicromapArray);
+                    break;
+
+                default:
+                    FIXME("Unsupported geometry type %u.\n", geom_desc->type);
+                    return false;
+            }
+
+            if (primitive_counts)
+                primitive_counts[i] = primitive_count;
+
+            if (range_infos)
+            {
+                range_infos[i].primitiveCount = primitive_count;
+                range_infos[i].firstVertex = 0;
+                range_infos[i].primitiveOffset = 0;
+                range_infos[i].transformOffset = 0;
+            }
+
+            RT_TRACE("  Primitive count %u.\n", primitive_count);
+        }
+    }
+
+    RT_TRACE("=====================\n");
+    return true;
+}
+
 static void vkd3d_acceleration_structure_end_barrier(struct d3d12_command_list *list)
 {
     /* We resolve the query in TRANSFER, but DXR expects UNORDERED_ACCESS. */
diff --git a/libs/vkd3d/breadcrumbs.c b/libs/vkd3d/breadcrumbs.c
index 8dc7b0a0..e36a88c7 100644
--- a/libs/vkd3d/breadcrumbs.c
+++ b/libs/vkd3d/breadcrumbs.c
@@ -76,6 +76,10 @@ static const char *vkd3d_breadcrumb_command_type_to_str(enum vkd3d_breadcrumb_co
             return "copy_rtas";
         case VKD3D_BREADCRUMB_COMMAND_EMIT_RTAS_POSTBUILD:
             return "emit_rtas_postbuild";
+        case VKD3D_BREADCRUMB_COMMAND_BUILD_OMM:
+            return "build_omm";
+        case VKD3D_BREADCRUMB_COMMAND_EMIT_OMM_POSTBUILD:
+            return "emit_omm_postbuild";
         case VKD3D_BREADCRUMB_COMMAND_TRACE_RAYS:
             return "trace_rays";
         case VKD3D_BREADCRUMB_COMMAND_BARRIER:
diff --git a/libs/vkd3d/command.c b/libs/vkd3d/command.c
index 65bfe41d..bb04fe65 100644
--- a/libs/vkd3d/command.c
+++ b/libs/vkd3d/command.c
@@ -74,11 +74,9 @@ static VkImageLayout d3d12_command_list_get_depth_stencil_resource_layout(const
 static void d3d12_command_list_decay_optimal_dsv_resource(struct d3d12_command_list *list,
         const struct d3d12_resource *resource, uint32_t plane_optimal_mask,
         struct d3d12_command_list_barrier_batch *batch);
-static void d3d12_command_list_end_transfer_batch(struct d3d12_command_list *list);
 static void d3d12_command_list_end_wbi_batch(struct d3d12_command_list *list);
 static inline void d3d12_command_list_ensure_transfer_batch(struct d3d12_command_list *list, enum vkd3d_batch_type type);
 static void d3d12_command_list_free_rtas_batch(struct d3d12_command_list *list);
-static void d3d12_command_list_flush_rtas_batch(struct d3d12_command_list *list);
 static void d3d12_command_list_clear_rtas_batch(struct d3d12_command_list *list);
 
 static void d3d12_command_list_flush_query_resolves(struct d3d12_command_list *list);
@@ -1934,7 +1932,6 @@ static HRESULT d3d12_command_allocator_allocate_command_buffer(struct d3d12_comm
 }
 
 static void d3d12_command_list_invalidate_all_state(struct d3d12_command_list *list);
-static void d3d12_command_list_end_current_render_pass(struct d3d12_command_list *list, bool suspend);
 
 static void d3d12_command_list_begin_new_sequence(struct d3d12_command_list *list)
 {
@@ -4569,7 +4566,7 @@ cleanup:
     return result;
 }
 
-static void d3d12_command_list_end_current_render_pass(struct d3d12_command_list *list, bool suspend)
+void d3d12_command_list_end_current_render_pass(struct d3d12_command_list *list, bool suspend)
 {
     const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
     VkMemoryBarrier2 vk_barrier;
@@ -4729,6 +4726,13 @@ static void vk_access_and_stage_flags_from_d3d12_resource_state(const struct d3d
                     *stages |= VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_BUILD_BIT_KHR;
                     *access |= VK_ACCESS_2_ACCELERATION_STRUCTURE_READ_BIT_KHR |
                             VK_ACCESS_2_ACCELERATION_STRUCTURE_WRITE_BIT_KHR;
+
+                    if (device->device_info.opacity_micromap_features.micromap)
+                    {
+                        *stages |= VK_PIPELINE_STAGE_2_MICROMAP_BUILD_BIT_EXT;
+                        *access |= VK_ACCESS_2_MICROMAP_READ_BIT_EXT |
+                                VK_ACCESS_2_MICROMAP_WRITE_BIT_EXT;
+                    }
                 }
                 break;
 
@@ -4740,6 +4744,9 @@ static void vk_access_and_stage_flags_from_d3d12_resource_state(const struct d3d
                             VK_PIPELINE_STAGE_2_RAY_TRACING_SHADER_BIT_KHR;
                     *access |= VK_ACCESS_2_ACCELERATION_STRUCTURE_WRITE_BIT_KHR |
                             VK_ACCESS_2_ACCELERATION_STRUCTURE_READ_BIT_KHR;
+
+                    if (device->device_info.opacity_micromap_features.micromap)
+                        *access |= VK_ACCESS_2_MICROMAP_READ_BIT_EXT;
                 }
                 break;
 
@@ -4766,6 +4773,10 @@ static void vk_access_and_stage_flags_from_d3d12_resource_state(const struct d3d
                     /* Vertex / index / transform buffer inputs are NON_PIXEL_SHADER_RESOURCES in DXR.
                      * They access SHADER_READ_BIT in Vulkan, so just need to add the stage. */
                     *stages |= VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_BUILD_BIT_KHR;
+
+                    if (device->device_info.opacity_micromap_features.micromap)
+                        *stages |= VK_PIPELINE_STAGE_2_MICROMAP_BUILD_BIT_EXT;
+
                 }
                 break;
 
@@ -4968,7 +4979,8 @@ HRESULT STDMETHODCALLTYPE d3d12_command_list_QueryInterface(d3d12_command_list_i
     }
 
     if (IsEqualGUID(iid, &IID_ID3D12GraphicsCommandListExt)
-            || IsEqualGUID(iid, &IID_ID3D12GraphicsCommandListExt1))
+            || IsEqualGUID(iid, &IID_ID3D12GraphicsCommandListExt1)
+            || IsEqualGUID(iid, &IID_ID3D12GraphicsCommandListExt2))
     {
         struct d3d12_command_list *command_list = impl_from_ID3D12GraphicsCommandList(iface);
         d3d12_command_list_vkd3d_ext_AddRef(&command_list->ID3D12GraphicsCommandListExt_iface);
@@ -8078,7 +8090,7 @@ static void STDMETHODCALLTYPE d3d12_command_list_CopyResource(d3d12_command_list
     VKD3D_BREADCRUMB_COMMAND(COPY);
 }
 
-static void d3d12_command_list_end_transfer_batch(struct d3d12_command_list *list)
+void d3d12_command_list_end_transfer_batch(struct d3d12_command_list *list)
 {
     struct d3d12_command_list_barrier_batch barriers;
     size_t i;
@@ -14639,13 +14651,15 @@ static void d3d12_command_list_free_rtas_batch(struct d3d12_command_list *list)
 
     vkd3d_free(rtas_batch->build_infos);
     vkd3d_free(rtas_batch->geometry_infos);
+    vkd3d_free(rtas_batch->omm_infos);
     vkd3d_free(rtas_batch->range_infos);
     vkd3d_free(rtas_batch->range_ptrs);
 }
 
-static bool d3d12_command_list_allocate_rtas_build_info(struct d3d12_command_list *list, uint32_t geometry_count,
+bool d3d12_command_list_allocate_rtas_build_info(struct d3d12_command_list *list, uint32_t geometry_count,
         VkAccelerationStructureBuildGeometryInfoKHR **build_info,
         VkAccelerationStructureGeometryKHR **geometry_infos,
+        VkAccelerationStructureTrianglesOpacityMicromapEXT **omm_infos,
         VkAccelerationStructureBuildRangeInfoKHR **range_infos)
 {
     struct d3d12_rtas_batch_state *rtas_batch = &list->rtas_batch;
@@ -14664,6 +14678,13 @@ static bool d3d12_command_list_allocate_rtas_build_info(struct d3d12_command_lis
         return false;
     }
 
+    if (!vkd3d_array_reserve((void **)&rtas_batch->omm_infos, &rtas_batch->omm_info_size,
+            rtas_batch->geometry_info_count + geometry_count, sizeof(*rtas_batch->omm_infos)))
+    {
+        ERR("Failed to allocate opacity micromap info array.\n");
+        return false;
+    }
+
     if (!vkd3d_array_reserve((void **)&rtas_batch->range_infos, &rtas_batch->range_info_size,
             rtas_batch->geometry_info_count + geometry_count, sizeof(*rtas_batch->range_infos)))
     {
@@ -14673,6 +14694,7 @@ static bool d3d12_command_list_allocate_rtas_build_info(struct d3d12_command_lis
 
     *build_info = &rtas_batch->build_infos[rtas_batch->build_info_count];
     *geometry_infos = &rtas_batch->geometry_infos[rtas_batch->geometry_info_count];
+    *omm_infos = &rtas_batch->omm_infos[rtas_batch->geometry_info_count];
     *range_infos = &rtas_batch->range_infos[rtas_batch->geometry_info_count];
 
     rtas_batch->build_info_count += 1;
@@ -14689,7 +14711,7 @@ static void d3d12_command_list_clear_rtas_batch(struct d3d12_command_list *list)
     rtas_batch->geometry_info_count = 0;
 }
 
-static void d3d12_command_list_flush_rtas_batch(struct d3d12_command_list *list)
+void d3d12_command_list_flush_rtas_batch(struct d3d12_command_list *list)
 {
     const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
     struct d3d12_rtas_batch_state *rtas_batch = &list->rtas_batch;
@@ -14737,6 +14759,7 @@ static void STDMETHODCALLTYPE d3d12_command_list_BuildRaytracingAccelerationStru
     struct d3d12_command_list *list = impl_from_ID3D12GraphicsCommandList(iface);
     const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
     struct d3d12_rtas_batch_state *rtas_batch = &list->rtas_batch;
+    VkAccelerationStructureTrianglesOpacityMicromapEXT *omm_infos;
     VkAccelerationStructureBuildGeometryInfoKHR *build_info;
     VkAccelerationStructureBuildRangeInfoKHR *range_infos;
     VkAccelerationStructureGeometryKHR *geometry_infos;
@@ -14768,6 +14791,12 @@ static void STDMETHODCALLTYPE d3d12_command_list_BuildRaytracingAccelerationStru
         vk_barrier.dstStageMask = VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_BUILD_BIT_KHR;
         vk_barrier.dstAccessMask = VK_ACCESS_2_ACCELERATION_STRUCTURE_READ_BIT_KHR | VK_ACCESS_2_ACCELERATION_STRUCTURE_WRITE_BIT_KHR;
 
+        if (list->device->device_info.opacity_micromap_features.micromap)
+        {
+            vk_barrier.srcAccessMask |= VK_ACCESS_2_MICROMAP_READ_BIT_EXT;
+            vk_barrier.dstAccessMask |= VK_ACCESS_2_MICROMAP_READ_BIT_EXT;
+        }
+
         memset(&dep_info, 0, sizeof(dep_info));
         dep_info.sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO;
         dep_info.memoryBarrierCount = 1;
@@ -14786,7 +14815,7 @@ static void STDMETHODCALLTYPE d3d12_command_list_BuildRaytracingAccelerationStru
 #endif
 
     if (!d3d12_command_list_allocate_rtas_build_info(list, geometry_count,
-            &build_info, &geometry_infos, &range_infos))
+            &build_info, &geometry_infos, &omm_infos, &range_infos))
         return;
 
     if (!vkd3d_acceleration_structure_convert_inputs(list->device, &desc->Inputs,
@@ -15779,7 +15808,7 @@ static struct d3d12_command_list *unsafe_impl_from_ID3D12CommandList(ID3D12Comma
     return CONTAINING_RECORD(iface, struct d3d12_command_list, ID3D12GraphicsCommandList_iface);
 }
 
-extern CONST_VTBL struct ID3D12GraphicsCommandListExt1Vtbl d3d12_command_list_vkd3d_ext_vtbl;
+extern CONST_VTBL struct ID3D12GraphicsCommandListExt2Vtbl d3d12_command_list_vkd3d_ext_vtbl;
 
 static void d3d12_command_list_init_attachment_info(VkRenderingAttachmentInfo *attachment_info)
 {
diff --git a/libs/vkd3d/command_list_vkd3d_ext.c b/libs/vkd3d/command_list_vkd3d_ext.c
index 7e54fae6..dd867978 100644
--- a/libs/vkd3d/command_list_vkd3d_ext.c
+++ b/libs/vkd3d/command_list_vkd3d_ext.c
@@ -120,7 +120,373 @@ static HRESULT STDMETHODCALLTYPE d3d12_command_list_vkd3d_ext_LaunchCubinShader(
                                                             0 /* raw_params_count */);
 }
 
-CONST_VTBL struct ID3D12GraphicsCommandListExt1Vtbl d3d12_command_list_vkd3d_ext_vtbl =
+static HRESULT STDMETHODCALLTYPE d3d12_command_list_vkd3d_ext_BuildRaytracingAccelerationStructureEx(d3d12_command_list_vkd3d_ext_iface *iface,
+        const void *params)
+{
+    struct d3d12_command_list *list = d3d12_command_list_from_ID3D12GraphicsCommandListExt(iface);
+    const NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS *nvParams = params;
+    const NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_DESC_EX *desc;
+    const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
+    struct d3d12_rtas_batch_state *rtas_batch = &list->rtas_batch;
+    VkAccelerationStructureTrianglesOpacityMicromapEXT *omm_infos;
+    VkAccelerationStructureBuildGeometryInfoKHR *build_info;
+    VkAccelerationStructureBuildRangeInfoKHR *range_infos;
+    VkAccelerationStructureGeometryKHR *geometry_infos;
+    uint32_t *primitive_counts = NULL;
+    VkMemoryBarrier2 vk_barrier;
+    VkDependencyInfo dep_info;
+    uint32_t geometry_count;
+    TRACE("iface %p, params %p.\n", iface, params);
+
+    if (!nvParams)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (nvParams->version != NVAPI_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_EX_PARAMS_VER1)
+        return NVAPI_INCOMPATIBLE_STRUCT_VERSION;
+
+    if (!nvParams->pDesc || (nvParams->numPostbuildInfoDescs && !nvParams->pPostbuildInfoDescs))
+        return NVAPI_INVALID_ARGUMENT;
+
+    desc = nvParams->pDesc;
+
+    if (!d3d12_device_supports_ray_tracing_tier_1_0(list->device))
+    {
+        WARN("Acceleration structure is not supported. Calling this is invalid.\n");
+        return NVAPI_ERROR;
+    }
+
+    /* Do not batch TLAS and BLAS builds into the same command, since doing so
+     * is disallowed if there are data dependencies between the builds. This
+     * happens in Cyberpunk 2077, which does not emit appropriate UAV barriers. */
+    if (rtas_batch->build_info_count && rtas_batch->build_type != desc->inputs.type)
+    {
+        d3d12_command_list_flush_rtas_batch(list);
+
+        memset(&vk_barrier, 0, sizeof(vk_barrier));
+        vk_barrier.sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2;
+        vk_barrier.srcStageMask = VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_BUILD_BIT_KHR;
+        vk_barrier.srcAccessMask = VK_ACCESS_2_ACCELERATION_STRUCTURE_WRITE_BIT_KHR;
+        vk_barrier.dstStageMask = VK_PIPELINE_STAGE_2_ACCELERATION_STRUCTURE_BUILD_BIT_KHR;
+        vk_barrier.dstAccessMask = VK_ACCESS_2_ACCELERATION_STRUCTURE_READ_BIT_KHR | VK_ACCESS_2_ACCELERATION_STRUCTURE_WRITE_BIT_KHR;
+
+        if (list->device->device_info.opacity_micromap_features.micromap)
+        {
+            vk_barrier.srcAccessMask |= VK_ACCESS_2_MICROMAP_READ_BIT_EXT;
+            vk_barrier.dstAccessMask |= VK_ACCESS_2_MICROMAP_READ_BIT_EXT;
+        }
+
+        memset(&dep_info, 0, sizeof(dep_info));
+        dep_info.sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO;
+        dep_info.memoryBarrierCount = 1;
+        dep_info.pMemoryBarriers = &vk_barrier;
+
+        VK_CALL(vkCmdPipelineBarrier2(list->cmd.vk_command_buffer, &dep_info));
+    }
+
+    rtas_batch->build_type = desc->inputs.type;
+
+    geometry_count = vkd3d_acceleration_structure_get_geometry_count_nv(&desc->inputs);
+
+#ifdef VKD3D_ENABLE_BREADCRUMBS
+    if (vkd3d_config_flags & VKD3D_CONFIG_FLAG_BREADCRUMBS)
+        primitive_counts = vkd3d_malloc(geometry_count * sizeof(*primitive_counts));
+#endif
+
+    if (!d3d12_command_list_allocate_rtas_build_info(list, geometry_count,
+            &build_info, &geometry_infos, &omm_infos, &range_infos))
+        return NVAPI_OUT_OF_MEMORY;
+
+    if (!vkd3d_acceleration_structure_convert_inputs_nv(list->device, &desc->inputs,
+            build_info, geometry_infos, omm_infos, range_infos, primitive_counts))
+    {
+        ERR("Failed to convert inputs.\n");
+        return NVAPI_ERROR;
+    }
+
+    if (desc->destAccelerationStructureData)
+    {
+        build_info->dstAccelerationStructure =
+                vkd3d_va_map_place_acceleration_structure(&list->device->memory_allocator.va_map,
+                        list->device, desc->destAccelerationStructureData);
+        if (build_info->dstAccelerationStructure == VK_NULL_HANDLE)
+        {
+            ERR("Failed to place destAccelerationStructure. Dropping call.\n");
+            return NVAPI_ERROR;
+        }
+    }
+
+    if (build_info->mode == VK_BUILD_ACCELERATION_STRUCTURE_MODE_UPDATE_KHR &&
+            desc->sourceAccelerationStructureData)
+    {
+        build_info->srcAccelerationStructure =
+                vkd3d_va_map_place_acceleration_structure(&list->device->memory_allocator.va_map,
+                        list->device, desc->sourceAccelerationStructureData);
+        if (build_info->srcAccelerationStructure == VK_NULL_HANDLE)
+        {
+            ERR("Failed to place srcAccelerationStructure. Dropping call.\n");
+            return NVAPI_ERROR;
+        }
+    }
+
+    build_info->scratchData.deviceAddress = desc->scratchAccelerationStructureData;
+
+    /* Immediately execute the RTAS build command here
+     * so that we don't have to copy micromap usage counts */
+    d3d12_command_list_flush_rtas_batch(list);
+
+#ifdef VKD3D_ENABLE_BREADCRUMBS
+    if (vkd3d_config_flags & VKD3D_CONFIG_FLAG_BREADCRUMBS)
+    {
+        VKD3D_BREADCRUMB_TAG("RTAS build [Dest VA, Source VA, Scratch VA]");
+        VKD3D_BREADCRUMB_AUX64(desc->destAccelerationStructureData);
+        VKD3D_BREADCRUMB_AUX64(desc->sourceAccelerationStructureData);
+        VKD3D_BREADCRUMB_AUX64(desc->scratchAccelerationStructureData);
+        VKD3D_BREADCRUMB_TAG((desc->inputs.flags & D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_PERFORM_UPDATE) ?
+                "Update" : "Create");
+        VKD3D_BREADCRUMB_TAG(desc->inputs.type == D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL ? "Top" : "Bottom");
+        {
+            VkAccelerationStructureBuildSizesInfoKHR size_info;
+
+            memset(&size_info, 0, sizeof(size_info));
+            size_info.sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_SIZES_INFO_KHR;
+
+            if (desc->inputs.flags & D3D12_RAYTRACING_ACCELERATION_STRUCTURE_BUILD_FLAG_PERFORM_UPDATE)
+            {
+                build_info->mode = VK_BUILD_ACCELERATION_STRUCTURE_MODE_BUILD_KHR;
+                build_info->flags |= VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_UPDATE_BIT_KHR;
+            }
+            VK_CALL(vkGetAccelerationStructureBuildSizesKHR(list->device->vk_device,
+                    VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR, build_info,
+                    primitive_counts, &size_info));
+            VKD3D_BREADCRUMB_TAG("Build requirements [Size, Build Scratch, Update Scratch]");
+            VKD3D_BREADCRUMB_AUX64(size_info.accelerationStructureSize);
+            VKD3D_BREADCRUMB_AUX64(size_info.buildScratchSize);
+            VKD3D_BREADCRUMB_AUX64(size_info.updateScratchSize);
+
+            if (desc->inputs.type == D3D12_RAYTRACING_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL)
+            {
+                VKD3D_BREADCRUMB_AUX64(desc->inputs.instanceDescs);
+                VKD3D_BREADCRUMB_AUX32(desc->inputs.numDescs);
+            }
+            else
+            {
+                unsigned int i;
+                for (i = 0; i < desc->inputs.numDescs; i++)
+                {
+                    const NVAPI_D3D12_RAYTRACING_GEOMETRY_DESC_EX *geom;
+                    if (desc->inputs.descsLayout == D3D12_ELEMENTS_LAYOUT_ARRAY)
+                        geom = &desc->inputs.pGeometryDescs[i];
+                    else
+                        geom = desc->inputs.ppGeometryDescs[i];
+
+                    switch (geom->type)
+                    {
+                        case NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_TRIANGLES_EX:
+                            VKD3D_BREADCRUMB_TAG("Triangle [Flags, VBO VA, VBO stride, IBO, Transform, VBO format, IBO format, V count, I count]");
+                            VKD3D_BREADCRUMB_AUX32(geom->flags);
+                            VKD3D_BREADCRUMB_AUX64(geom->triangles.VertexBuffer.StartAddress);
+                            VKD3D_BREADCRUMB_AUX64(geom->triangles.VertexBuffer.StrideInBytes);
+                            VKD3D_BREADCRUMB_AUX64(geom->triangles.IndexBuffer);
+                            VKD3D_BREADCRUMB_AUX64(geom->triangles.Transform3x4);
+                            VKD3D_BREADCRUMB_AUX32(geom->triangles.VertexFormat);
+                            VKD3D_BREADCRUMB_AUX32(geom->triangles.IndexFormat);
+                            VKD3D_BREADCRUMB_AUX32(geom->triangles.VertexCount);
+                            VKD3D_BREADCRUMB_AUX32(geom->triangles.IndexCount);
+                            break;
+
+                        case NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_PROCEDURAL_PRIMITIVE_AABBS_EX:
+                            VKD3D_BREADCRUMB_TAG("AABB [Flags, VA, stride, count]");
+                            VKD3D_BREADCRUMB_AUX32(geom->flags);
+                            VKD3D_BREADCRUMB_AUX64(geom->aabbs.AABBs.StartAddress);
+                            VKD3D_BREADCRUMB_AUX64(geom->aabbs.AABBs.StrideInBytes);
+                            VKD3D_BREADCRUMB_AUX64(geom->aabbs.AABBCount);
+                            break;
+
+                        case NVAPI_D3D12_RAYTRACING_GEOMETRY_TYPE_OMM_TRIANGLES_EX:
+                            VKD3D_BREADCRUMB_TAG("OMM Triangle [Flags, VBO VA, VBO stride, IBO, Transform, VBO format, IBO format, V count, I count, OMM IBO VA, OMM IBO stride, OMM IBO format, OMM base location, OMM array, OMM usage count]");
+                            VKD3D_BREADCRUMB_AUX32(geom->flags);
+                            VKD3D_BREADCRUMB_AUX64(geom->ommTriangles.triangles.VertexBuffer.StartAddress);
+                            VKD3D_BREADCRUMB_AUX64(geom->ommTriangles.triangles.VertexBuffer.StrideInBytes);
+                            VKD3D_BREADCRUMB_AUX64(geom->ommTriangles.triangles.IndexBuffer);
+                            VKD3D_BREADCRUMB_AUX64(geom->ommTriangles.triangles.Transform3x4);
+                            VKD3D_BREADCRUMB_AUX32(geom->ommTriangles.triangles.VertexFormat);
+                            VKD3D_BREADCRUMB_AUX32(geom->ommTriangles.triangles.IndexFormat);
+                            VKD3D_BREADCRUMB_AUX32(geom->ommTriangles.triangles.VertexCount);
+                            VKD3D_BREADCRUMB_AUX32(geom->ommTriangles.triangles.IndexCount);
+                            VKD3D_BREADCRUMB_AUX64(geom->ommTriangles.ommAttachment.opacityMicromapIndexBuffer.StartAddress);
+                            VKD3D_BREADCRUMB_AUX64(geom->ommTriangles.ommAttachment.opacityMicromapIndexBuffer.StrideInBytes);
+                            VKD3D_BREADCRUMB_AUX32(geom->ommTriangles.ommAttachment.opacityMicromapIndexFormat);
+                            VKD3D_BREADCRUMB_AUX32(geom->ommTriangles.ommAttachment.opacityMicromapBaseLocation);
+                            VKD3D_BREADCRUMB_AUX64(geom->ommTriangles.ommAttachment.opacityMicromapArray);
+                            VKD3D_BREADCRUMB_AUX32(geom->ommTriangles.ommAttachment.numOMMUsageCounts);
+                            break;
+                    }
+                }
+            }
+        }
+
+        vkd3d_free(primitive_counts);
+    }
+#endif
+
+    if (nvParams->numPostbuildInfoDescs)
+    {
+        vkd3d_acceleration_structure_emit_immediate_postbuild_info(list,
+                nvParams->numPostbuildInfoDescs, nvParams->pPostbuildInfoDescs,
+                build_info->dstAccelerationStructure);
+    }
+
+    VKD3D_BREADCRUMB_COMMAND(BUILD_RTAS);
+
+    return NVAPI_OK;
+}
+
+static HRESULT STDMETHODCALLTYPE d3d12_command_list_vkd3d_ext_BuildRaytracingOpacityMicromapArray(d3d12_command_list_vkd3d_ext_iface *iface,
+        void *params)
+{
+    struct d3d12_command_list *list = d3d12_command_list_from_ID3D12GraphicsCommandListExt(iface);
+    NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS *nvParams = params;
+    const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
+    const NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_DESC *desc;
+    struct vkd3d_opacity_micromap_build_info build_info;
+    TRACE("iface %p, params %p.\n", iface, params);
+
+    if (!nvParams)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (nvParams->version != NVAPI_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_PARAMS_VER1)
+        return NVAPI_INCOMPATIBLE_STRUCT_VERSION;
+
+    if (!nvParams->pDesc || (nvParams->numPostbuildInfoDescs && !nvParams->pPostbuildInfoDescs))
+        return NVAPI_INVALID_ARGUMENT;
+
+    desc = nvParams->pDesc;
+
+    if (!list->device->device_info.opacity_micromap_features.micromap)
+    {
+        ERR("Opacity micromap is not supported. Calling this is invalid.\n");
+        return NVAPI_NOT_SUPPORTED;
+    }
+
+    if (!vkd3d_opacity_micromap_convert_inputs_nv(list->device, &build_info, &nvParams->pDesc->inputs))
+    {
+        ERR("Failed to convert inputs.\n");
+        return NVAPI_ERROR;
+    }
+
+    if (desc->destOpacityMicromapArrayData)
+    {
+        build_info.build_info.dstMicromap =
+                vkd3d_va_map_place_opacity_micromap(&list->device->memory_allocator.va_map,
+                        list->device, desc->destOpacityMicromapArrayData);
+        if (build_info.build_info.dstMicromap == VK_NULL_HANDLE)
+        {
+            ERR("Failed to place dstMicromap. Dropping call.\n");
+            return NVAPI_ERROR;
+        }
+    }
+
+    build_info.build_info.scratchData.deviceAddress = desc->scratchOpacityMicromapArrayData;
+
+    d3d12_command_list_end_current_render_pass(list, true);
+    d3d12_command_list_end_transfer_batch(list);
+
+    VK_CALL(vkCmdBuildMicromapsEXT(list->cmd.vk_command_buffer, 1,
+            &build_info.build_info));
+
+#ifdef VKD3D_ENABLE_BREADCRUMBS
+    VKD3D_BREADCRUMB_TAG("OMM build [Dest VA, Scratch VA]");
+    VKD3D_BREADCRUMB_AUX64(desc->destOpacityMicromapArrayData);
+    VKD3D_BREADCRUMB_AUX64(desc->scratchOpacityMicromapArrayData);
+    {
+        VkMicromapBuildSizesInfoEXT size_info;
+        unsigned int i;
+
+        memset(&size_info, 0, sizeof(size_info));
+        size_info.sType = VK_STRUCTURE_TYPE_MICROMAP_BUILD_SIZES_INFO_EXT;
+
+        VK_CALL(vkGetMicromapBuildSizesEXT(list->device->vk_device,
+                VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR, &build_info.build_info,
+                &size_info));
+        VKD3D_BREADCRUMB_TAG("Build requirements [Size, Build Scratch, Discardable]");
+        VKD3D_BREADCRUMB_AUX64(size_info.micromapSize);
+        VKD3D_BREADCRUMB_AUX64(size_info.buildScratchSize);
+        VKD3D_BREADCRUMB_AUX32(size_info.discardable);
+
+        VKD3D_BREADCRUMB_TAG("Inputs [Flags, VA, Descs VA, Descs stride]");
+        VKD3D_BREADCRUMB_AUX32(desc->inputs.flags);
+        VKD3D_BREADCRUMB_AUX64(desc->inputs.inputBuffer);
+        VKD3D_BREADCRUMB_AUX64(desc->inputs.perOMMDescs.StartAddress);
+        VKD3D_BREADCRUMB_AUX64(desc->inputs.perOMMDescs.StrideInBytes);
+
+        for (i = 0; i < desc->inputs.numOMMUsageCounts; i++)
+        {
+            const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT *usage_count = &desc->inputs.pOMMUsageCounts[i];
+
+            VKD3D_BREADCRUMB_TAG("Usage Count [Count, Subdivision Level, Format]");
+            VKD3D_BREADCRUMB_AUX32(usage_count->count);
+            VKD3D_BREADCRUMB_AUX32(usage_count->subdivisionLevel);
+            VKD3D_BREADCRUMB_AUX32(usage_count->format);
+        }
+    }
+#endif
+
+    vkd3d_opacity_micromap_build_info_cleanup(&build_info);
+
+    if (nvParams->numPostbuildInfoDescs)
+    {
+        vkd3d_opacity_micromap_emit_immediate_postbuild_info_nv(list,
+                nvParams->numPostbuildInfoDescs, nvParams->pPostbuildInfoDescs,
+                build_info.build_info.dstMicromap);
+    }
+
+    VKD3D_BREADCRUMB_COMMAND(BUILD_OMM);
+
+    return NVAPI_OK;
+}
+
+static HRESULT STDMETHODCALLTYPE d3d12_command_list_vkd3d_ext_RelocateRaytracingOpacityMicromapArray(d3d12_command_list_vkd3d_ext_iface *iface,
+        const void *params)
+{
+    FIXME("iface %p, params %p stub.\n", iface, params);
+    return NVAPI_OK;
+}
+
+static HRESULT STDMETHODCALLTYPE d3d12_command_list_vkd3d_ext_EmitRaytracingOpacityMicromapArrayPostbuildInfo(d3d12_command_list_vkd3d_ext_iface *iface,
+        const void *params)
+{
+    struct d3d12_command_list *list = d3d12_command_list_from_ID3D12GraphicsCommandListExt(iface);
+    const NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS *nvParams = params;
+    TRACE("iface %p, params %p.\n", iface, params);
+
+    if (!params)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (!nvParams)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (nvParams->version != NVAPI_EMIT_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_PARAMS_VER1)
+        return NVAPI_INCOMPATIBLE_STRUCT_VERSION;
+
+    if (!nvParams->pDesc || (nvParams->numSources && !nvParams->pSources))
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (!list->device->device_info.opacity_micromap_features.micromap)
+    {
+        ERR("Opacity micromap is not supported. Calling this is invalid.\n");
+        return NVAPI_NOT_SUPPORTED;
+    }
+
+    d3d12_command_list_end_current_render_pass(list, true);
+    vkd3d_opacity_micromap_emit_postbuild_info_nv(list,
+            nvParams->pDesc, nvParams->numSources, nvParams->pSources);
+
+    VKD3D_BREADCRUMB_COMMAND(EMIT_OMM_POSTBUILD);
+
+    return NVAPI_OK;
+}
+
+CONST_VTBL struct ID3D12GraphicsCommandListExt2Vtbl d3d12_command_list_vkd3d_ext_vtbl =
 {
     /* IUnknown methods */
     d3d12_command_list_vkd3d_ext_QueryInterface,
@@ -133,5 +499,11 @@ CONST_VTBL struct ID3D12GraphicsCommandListExt1Vtbl d3d12_command_list_vkd3d_ext
 
     /* ID3D12GraphicsCommandListExt1 methods */
     d3d12_command_list_vkd3d_ext_LaunchCubinShaderEx,
+
+    /* ID3D12GraphicsCommandListExt2 methods */
+    d3d12_command_list_vkd3d_ext_BuildRaytracingAccelerationStructureEx,
+    d3d12_command_list_vkd3d_ext_BuildRaytracingOpacityMicromapArray,
+    d3d12_command_list_vkd3d_ext_RelocateRaytracingOpacityMicromapArray,
+    d3d12_command_list_vkd3d_ext_EmitRaytracingOpacityMicromapArrayPostbuildInfo,
 };
 
diff --git a/libs/vkd3d/device.c b/libs/vkd3d/device.c
index 13c10dca..6542c3a4 100644
--- a/libs/vkd3d/device.c
+++ b/libs/vkd3d/device.c
@@ -105,6 +105,7 @@ static const struct vkd3d_optional_extension_info optional_device_extensions[] =
     VK_EXTENSION(EXT_DYNAMIC_RENDERING_UNUSED_ATTACHMENTS, EXT_dynamic_rendering_unused_attachments),
     VK_EXTENSION(EXT_LINE_RASTERIZATION, EXT_line_rasterization),
     VK_EXTENSION(EXT_IMAGE_COMPRESSION_CONTROL, EXT_image_compression_control),
+    VK_EXTENSION_DISABLE_COND(EXT_OPACITY_MICROMAP, EXT_opacity_micromap, VKD3D_CONFIG_FLAG_NO_DXR),
     /* AMD extensions */
     VK_EXTENSION(AMD_BUFFER_MARKER, AMD_buffer_marker),
     VK_EXTENSION(AMD_DEVICE_COHERENT_MEMORY, AMD_device_coherent_memory),
@@ -1783,6 +1784,12 @@ static void vkd3d_physical_device_info_init(struct vkd3d_physical_device_info *i
         vk_prepend_struct(&info->properties2, &info->memory_decompression_properties);
     }
 
+    if (vulkan_info->EXT_opacity_micromap)
+    {
+        info->opacity_micromap_features.sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_OPACITY_MICROMAP_FEATURES_EXT;
+        vk_prepend_struct(&info->features2, &info->opacity_micromap_features);
+    }
+
     VK_CALL(vkGetPhysicalDeviceFeatures2(device->vk_physical_device, &info->features2));
     VK_CALL(vkGetPhysicalDeviceProperties2(device->vk_physical_device, &info->properties2));
 }
@@ -2189,6 +2196,11 @@ static void vkd3d_trace_physical_device_features(const struct vkd3d_physical_dev
     TRACE("  VkPhysicalDeviceLineRasterizationFeaturesEXT:\n");
     TRACE("    rectangularLines: %u\n", info->line_rasterization_features.rectangularLines);
     TRACE("    smoothLines: %u\n", info->line_rasterization_features.smoothLines);
+
+    TRACE("  VkPhysicalDeviceOpacityMicromapFeaturesEXT:\n");
+    TRACE("    micromap: %#x\n", info->opacity_micromap_features.micromap);
+    TRACE("    micromapCaptureReplay: %#x\n", info->opacity_micromap_features.micromapCaptureReplay);
+    TRACE("    micromapHostCommands: %#x\n", info->opacity_micromap_features.micromapHostCommands);
 }
 
 static HRESULT vkd3d_init_device_extensions(struct d3d12_device *device,
@@ -3225,7 +3237,8 @@ HRESULT STDMETHODCALLTYPE d3d12_device_QueryInterface(d3d12_device_iface *iface,
         return S_OK;
     }
 
-    if (IsEqualGUID(riid, &IID_ID3D12DeviceExt))
+    if (IsEqualGUID(riid, &IID_ID3D12DeviceExt)
+            || IsEqualGUID(riid, &IID_ID3D12DeviceExt1))
     {
         struct d3d12_device *device = impl_from_ID3D12Device(iface);
         d3d12_device_vkd3d_ext_AddRef(&device->ID3D12DeviceExt_iface);
@@ -8070,6 +8083,12 @@ static void vkd3d_init_shader_extensions(struct d3d12_device *device)
         device->vk_info.shader_extensions[device->vk_info.shader_extension_count++] =
                 VKD3D_SHADER_TARGET_EXTENSION_SUPPORT_SUBGROUP_PARTITIONED_NV;
     }
+
+    if (device->device_info.opacity_micromap_features.micromap)
+    {
+        device->vk_info.shader_extensions[device->vk_info.shader_extension_count++] =
+                VKD3D_SHADER_TARGET_EXTENSION_OPACITY_MICROMAP;
+    }
 }
 
 static void vkd3d_compute_shader_interface_key(struct d3d12_device *device)
@@ -8185,7 +8204,7 @@ static void d3d12_device_replace_vtable(struct d3d12_device *device)
     }
 }
 
-extern CONST_VTBL struct ID3D12DeviceExtVtbl d3d12_device_vkd3d_ext_vtbl;
+extern CONST_VTBL struct ID3D12DeviceExt1Vtbl d3d12_device_vkd3d_ext_vtbl;
 extern CONST_VTBL struct ID3D12DXVKInteropDeviceVtbl d3d12_dxvk_interop_device_vtbl;
 extern CONST_VTBL struct ID3DLowLatencyDeviceVtbl d3d_low_latency_device_vtbl;
 
@@ -8351,6 +8370,8 @@ static HRESULT d3d12_device_init(struct d3d12_device *device,
         vkd3d_renderdoc_begin_capture(device->vkd3d_instance->vk_instance);
 #endif
 
+    device->global_ray_tracing_pipeline_create_flags = 0;
+
     return S_OK;
 
 out_cleanup_descriptor_qa_global_info:
diff --git a/libs/vkd3d/device_vkd3d_ext.c b/libs/vkd3d/device_vkd3d_ext.c
index 5bb7eca8..7dc70847 100644
--- a/libs/vkd3d/device_vkd3d_ext.c
+++ b/libs/vkd3d/device_vkd3d_ext.c
@@ -69,6 +69,9 @@ static BOOL STDMETHODCALLTYPE d3d12_device_vkd3d_ext_GetExtensionSupport(ID3D12D
     TRACE("iface %p, extension %u \n", iface, extension);
     switch (extension)
     {
+        case D3D12_VK_EXT_OPACITY_MICROMAP:
+            ret_val = device->vk_info.EXT_opacity_micromap;
+            break;
         case D3D12_VK_NVX_BINARY_IMPORT:
             ret_val = device->vk_info.NVX_binary_import;
             break;
@@ -215,7 +218,208 @@ static HRESULT STDMETHODCALLTYPE d3d12_device_vkd3d_ext_CaptureUAVInfo(ID3D12Dev
     return S_OK;
 }
 
-CONST_VTBL struct ID3D12DeviceExtVtbl d3d12_device_vkd3d_ext_vtbl =
+static HRESULT STDMETHODCALLTYPE d3d12_device_vkd3d_ext_SetCreatePipelineStateOptions(d3d12_device_vkd3d_ext_iface *iface,
+        const void *params)
+{
+    const NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS *nvParams = params;
+    struct d3d12_device *device = d3d12_device_from_ID3D12DeviceExt(iface);
+
+    TRACE("iface %p, params %p.\n", iface, params);
+
+    if (!nvParams)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (nvParams->version != NVAPI_D3D12_SET_CREATE_PIPELINE_STATE_OPTIONS_PARAMS_VER1)
+        return NVAPI_INCOMPATIBLE_STRUCT_VERSION;
+
+    if (nvParams->flags & NVAPI_D3D12_PIPELINE_CREATION_STATE_FLAGS_ENABLE_OMM_SUPPORT)
+    {
+        if (!device->device_info.opacity_micromap_features.micromap)
+        {
+            ERR("Opacity micromap is not supported. Calling this is invalid.\n");
+            return NVAPI_NOT_SUPPORTED;
+        }
+
+        device->global_ray_tracing_pipeline_create_flags |= VK_PIPELINE_CREATE_RAY_TRACING_OPACITY_MICROMAP_BIT_EXT;
+    }
+    else
+    {
+        device->global_ray_tracing_pipeline_create_flags &= ~VK_PIPELINE_CREATE_RAY_TRACING_OPACITY_MICROMAP_BIT_EXT;
+    }
+
+    TRACE("flags #%x.\n", device->global_ray_tracing_pipeline_create_flags);
+
+    return NVAPI_OK;
+}
+
+static HRESULT STDMETHODCALLTYPE d3d12_device_vkd3d_ext_CheckDriverMatchingIdentifierEx(d3d12_device_vkd3d_ext_iface *iface,
+        void *params)
+{
+    NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS *nvParams = params;
+
+    TRACE("iface %p, params %p.\n", iface, params);
+
+    if (!nvParams)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (nvParams->version != NVAPI_CHECK_DRIVER_MATCHING_IDENTIFIER_EX_PARAMS_VER1)
+        return NVAPI_INCOMPATIBLE_STRUCT_VERSION;
+
+    if (nvParams->serializedDataType == NVAPI_D3D12_SERIALIZED_DATA_RAYTRACING_ACCELERATION_STRUCTURE_EX ||
+            nvParams->serializedDataType == NVAPI_D3D12_SERIALIZED_DATA_RAYTRACING_OPACITY_MICROMAP_ARRAY_EX)
+        nvParams->checkStatus = D3D12_DRIVER_MATCHING_IDENTIFIER_UNRECOGNIZED;
+    else
+        nvParams->checkStatus = D3D12_DRIVER_MATCHING_IDENTIFIER_UNSUPPORTED_TYPE;
+
+    return NVAPI_OK;
+}
+
+static HRESULT STDMETHODCALLTYPE d3d12_device_vkd3d_ext_GetRaytracingAccelerationStructurePrebuildInfoEx(d3d12_device_vkd3d_ext_iface *iface,
+        void *params)
+{
+    NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS *nvParams = params;
+    struct d3d12_device *device = d3d12_device_from_ID3D12DeviceExt(iface);
+
+    VkAccelerationStructureTrianglesOpacityMicromapEXT omms_stack[VKD3D_BUILD_INFO_STACK_COUNT];
+    VkAccelerationStructureGeometryKHR geometries_stack[VKD3D_BUILD_INFO_STACK_COUNT];
+    const struct vkd3d_vk_device_procs *vk_procs = &device->vk_procs;
+    uint32_t primitive_counts_stack[VKD3D_BUILD_INFO_STACK_COUNT];
+    D3D12_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO *info;
+    VkAccelerationStructureTrianglesOpacityMicromapEXT *omms;
+    VkAccelerationStructureBuildGeometryInfoKHR build_info;
+    VkAccelerationStructureBuildSizesInfoKHR size_info;
+    VkAccelerationStructureGeometryKHR *geometries;
+    uint32_t *primitive_counts;
+    uint32_t geometry_count;
+    HRESULT ns = NVAPI_OK;
+
+    TRACE("iface %p, params %p.\n", iface, params);
+
+    if (!params)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (nvParams->version != NVAPI_GET_RAYTRACING_ACCELERATION_STRUCTURE_PREBUILD_INFO_EX_PARAMS_VER1)
+        return NVAPI_INCOMPATIBLE_STRUCT_VERSION;
+
+    if (!nvParams->pDesc || !nvParams->pInfo)
+        return NVAPI_INVALID_ARGUMENT;
+
+    info = nvParams->pInfo;
+
+    if (!d3d12_device_supports_ray_tracing_tier_1_0(device))
+    {
+        ERR("Acceleration structure is not supported. Calling this is invalid.\n");
+        memset(info, 0, sizeof(*info));
+        return NVAPI_NOT_SUPPORTED;
+    }
+
+    geometry_count = vkd3d_acceleration_structure_get_geometry_count_nv(nvParams->pDesc);
+    primitive_counts = primitive_counts_stack;
+    geometries = geometries_stack;
+    omms = omms_stack;
+
+    if (geometry_count > VKD3D_BUILD_INFO_STACK_COUNT)
+    {
+        primitive_counts = vkd3d_malloc(geometry_count * sizeof(*primitive_counts));
+        geometries = vkd3d_malloc(geometry_count * sizeof(*geometries));
+        omms = vkd3d_malloc(geometry_count * sizeof(*omms));
+    }
+
+    if (!vkd3d_acceleration_structure_convert_inputs_nv(device,
+            nvParams->pDesc, &build_info, geometries, omms, NULL, primitive_counts))
+    {
+        ERR("Failed to convert inputs.\n");
+        memset(info, 0, sizeof(*info));
+        ns = NVAPI_ERROR;
+        goto cleanup;
+    }
+
+    build_info.pGeometries = geometries;
+
+    memset(&size_info, 0, sizeof(size_info));
+    size_info.sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_SIZES_INFO_KHR;
+
+    VK_CALL(vkGetAccelerationStructureBuildSizesKHR(device->vk_device,
+            VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR, &build_info,
+            primitive_counts, &size_info));
+
+    info->ResultDataMaxSizeInBytes = size_info.accelerationStructureSize;
+    info->ScratchDataSizeInBytes = size_info.buildScratchSize;
+    info->UpdateScratchDataSizeInBytes = size_info.updateScratchSize;
+
+    TRACE("ResultDataMaxSizeInBytes: %"PRIu64".\n", info->ResultDataMaxSizeInBytes);
+    TRACE("ScratchDatSizeInBytes: %"PRIu64".\n", info->ScratchDataSizeInBytes);
+    TRACE("UpdateScratchDataSizeInBytes: %"PRIu64".\n", info->UpdateScratchDataSizeInBytes);
+
+cleanup:
+
+    if (geometry_count > VKD3D_BUILD_INFO_STACK_COUNT)
+    {
+        vkd3d_free(primitive_counts);
+        vkd3d_free(geometries);
+        vkd3d_free(omms);
+    }
+
+    return ns;
+}
+
+static HRESULT STDMETHODCALLTYPE d3d12_device_vkd3d_ext_GetRaytracingOpacityMicromapArrayPrebuildInfo(d3d12_device_vkd3d_ext_iface *iface,
+        void *params)
+{
+    NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS *nvParams = params;
+    struct d3d12_device *device = d3d12_device_from_ID3D12DeviceExt(iface);
+    NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO *info;
+    const struct vkd3d_vk_device_procs *vk_procs = &device->vk_procs;
+    struct vkd3d_opacity_micromap_build_info build_info;
+    VkMicromapBuildSizesInfoEXT size_info;
+
+    TRACE("iface %p, params %p.\n", iface, params);
+
+    if (!nvParams)
+        return NVAPI_INVALID_ARGUMENT;
+
+    if (nvParams->version != NVAPI_GET_RAYTRACING_OPACITY_MICROMAP_ARRAY_PREBUILD_INFO_PARAMS_VER1)
+        return NVAPI_INCOMPATIBLE_STRUCT_VERSION;
+
+    if (!nvParams->pDesc || !nvParams->pInfo)
+        return NVAPI_INVALID_ARGUMENT;
+
+    info = nvParams->pInfo;
+
+    if (!device->device_info.opacity_micromap_features.micromap)
+    {
+        ERR("Opacity micromap is not supported. Calling this is invalid.\n");
+        memset(info, 0, sizeof(*info));
+        return NVAPI_NOT_SUPPORTED;
+    }
+
+    if (!vkd3d_opacity_micromap_convert_inputs_nv(device, &build_info, nvParams->pDesc))
+    {
+        ERR("Failed to convert inputs.\n");
+        memset(info, 0, sizeof(*info));
+        return NVAPI_ERROR;
+    }
+
+    memset(&size_info, 0, sizeof(size_info));
+    size_info.sType = VK_STRUCTURE_TYPE_MICROMAP_BUILD_SIZES_INFO_EXT;
+
+    VK_CALL(vkGetMicromapBuildSizesEXT(device->vk_device,
+            VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR,
+            &build_info.build_info, &size_info));
+
+    vkd3d_opacity_micromap_build_info_cleanup(&build_info);
+
+    info->resultDataMaxSizeInBytes = size_info.micromapSize;
+    info->scratchDataSizeInBytes = size_info.buildScratchSize;
+
+    TRACE("ResultDataMaxSizeInBytes: %"PRIu64".\n", info->resultDataMaxSizeInBytes);
+    TRACE("ScratchDatSizeInBytes: %"PRIu64".\n", info->scratchDataSizeInBytes);
+    TRACE("Micromap %s discardable.\n", size_info.discardable ? "is" : "is not");
+
+    return NVAPI_OK;
+}
+
+CONST_VTBL struct ID3D12DeviceExt1Vtbl d3d12_device_vkd3d_ext_vtbl =
 {
     /* IUnknown methods */
     d3d12_device_vkd3d_ext_QueryInterface,
@@ -229,7 +433,13 @@ CONST_VTBL struct ID3D12DeviceExtVtbl d3d12_device_vkd3d_ext_vtbl =
     d3d12_device_vkd3d_ext_DestroyCubinComputeShader,
     d3d12_device_vkd3d_ext_GetCudaTextureObject,
     d3d12_device_vkd3d_ext_GetCudaSurfaceObject,
-    d3d12_device_vkd3d_ext_CaptureUAVInfo
+    d3d12_device_vkd3d_ext_CaptureUAVInfo,
+
+    /* ID3D12DeviceExt1 methods */
+    d3d12_device_vkd3d_ext_SetCreatePipelineStateOptions,
+    d3d12_device_vkd3d_ext_CheckDriverMatchingIdentifierEx,
+    d3d12_device_vkd3d_ext_GetRaytracingAccelerationStructurePrebuildInfoEx,
+    d3d12_device_vkd3d_ext_GetRaytracingOpacityMicromapArrayPrebuildInfo,
 };
 
 
diff --git a/libs/vkd3d/meson.build b/libs/vkd3d/meson.build
index de322997..20feb0f9 100644
--- a/libs/vkd3d/meson.build
+++ b/libs/vkd3d/meson.build
@@ -74,6 +74,7 @@ vkd3d_src = [
   'vkd3d_main.c',
   'raytracing_pipeline.c',
   'acceleration_structure.c',
+  'opacity_micromap.c',
   'swapchain.c'
 ]
 
diff --git a/libs/vkd3d/opacity_micromap.c b/libs/vkd3d/opacity_micromap.c
new file mode 100644
index 00000000..64a325ef
--- /dev/null
+++ b/libs/vkd3d/opacity_micromap.c
@@ -0,0 +1,252 @@
+/*
+ * Copyright 2023 Krzysztof Bogacki
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#define VKD3D_DBG_CHANNEL VKD3D_DBG_CHANNEL_API
+#include "vkd3d_private.h"
+
+#define RT_TRACE TRACE
+
+void vkd3d_opacity_micromap_build_info_cleanup(
+        struct vkd3d_opacity_micromap_build_info *info)
+{
+    if (info->usages != info->usages_stack)
+        vkd3d_free(info->usages);
+}
+
+static VkBuildMicromapFlagsEXT nv_d3d12_build_flags_to_vk(
+        NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAGS flags)
+{
+    VkBuildMicromapFlagsEXT vk_flags = 0;
+
+    if (flags & NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAG_PREFER_FAST_TRACE)
+        vk_flags |= VK_BUILD_MICROMAP_PREFER_FAST_TRACE_BIT_EXT;
+    if (flags & NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_BUILD_FLAG_PREFER_FAST_BUILD)
+        vk_flags |= VK_BUILD_MICROMAP_PREFER_FAST_BUILD_BIT_EXT;
+
+    return vk_flags;
+}
+
+static VkOpacityMicromapFormatEXT nv_d3d12_format_to_vk(
+        NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT format)
+{
+    switch (format)
+    {
+        case NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT_OC1_2_STATE:
+            return VK_OPACITY_MICROMAP_FORMAT_2_STATE_EXT;
+        case NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT_OC1_4_STATE:
+            return VK_OPACITY_MICROMAP_FORMAT_4_STATE_EXT;
+        default:
+            FIXME("Unrecognized format #%x.\n", format);
+            return (VkOpacityMicromapFormatEXT)format;
+    }
+}
+
+static char const* debug_omm_format(
+        NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT format)
+{
+    switch (format)
+    {
+        #define ENUM_NAME(x) case x: return #x;
+        ENUM_NAME(NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT_OC1_2_STATE)
+        ENUM_NAME(NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT_OC1_4_STATE)
+        #undef ENUM_NAME
+    }
+
+    return vkd3d_dbg_sprintf("Unknown NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_FORMAT (%u)",
+        (uint32_t)format);
+}
+
+bool vkd3d_opacity_micromap_convert_inputs_nv(const struct d3d12_device *device,
+        struct vkd3d_opacity_micromap_build_info *info,
+        const NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_INPUTS *desc)
+{
+    const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_USAGE_COUNT *usage_count;
+    VkMicromapBuildInfoEXT *build_info;
+    VkMicromapUsageEXT *usage;
+    unsigned int i;
+
+    RT_TRACE("Converting inputs.\n");
+    RT_TRACE("=====================\n");
+
+    build_info = &info->build_info;
+    memset(build_info, 0, sizeof(*build_info));
+    build_info->sType = VK_STRUCTURE_TYPE_MICROMAP_BUILD_INFO_EXT;
+    build_info->type = VK_MICROMAP_TYPE_OPACITY_MICROMAP_EXT;
+    build_info->flags = nv_d3d12_build_flags_to_vk(desc->flags);
+    build_info->mode = VK_BUILD_MICROMAP_MODE_BUILD_EXT;
+    build_info->usageCountsCount = desc->numOMMUsageCounts;
+
+    info->usages = info->usages_stack;
+
+    if (desc->numOMMUsageCounts <= VKD3D_BUILD_INFO_STACK_COUNT)
+        memset(info->usages, 0, sizeof(*info->usages) * desc->numOMMUsageCounts);
+    else
+        info->usages = vkd3d_calloc(desc->numOMMUsageCounts, sizeof(*info->usages));
+
+    for (i = 0; i < desc->numOMMUsageCounts; i++)
+    {
+        RT_TRACE(" Usage %u:\n", i);
+
+        usage_count = &desc->pOMMUsageCounts[i];
+        usage = &info->usages[i];
+
+        usage->count = usage_count->count;
+        usage->subdivisionLevel = usage_count->subdivisionLevel;
+        usage->format = nv_d3d12_format_to_vk(usage_count->format);
+
+        RT_TRACE("  Count: %u\n", usage_count->count);
+        RT_TRACE("  Subdivision level: %u\n", usage_count->subdivisionLevel);
+        RT_TRACE("  Format: %s\n", debug_omm_format(usage_count->format));
+    }
+
+    build_info->pUsageCounts = info->usages;
+    build_info->data.deviceAddress = desc->inputBuffer;
+    build_info->triangleArray.deviceAddress = desc->perOMMDescs.StartAddress;
+    build_info->triangleArrayStride = desc->perOMMDescs.StrideInBytes;
+
+    RT_TRACE(" IBO VA: %"PRIx64"\n", desc->inputBuffer);
+    RT_TRACE(" Triangles VA: %"PRIx64"\n", desc->perOMMDescs.StartAddress);
+    RT_TRACE(" Triangles stride: %"PRIu64" bytes\n", desc->perOMMDescs.StrideInBytes);
+
+    RT_TRACE("=====================\n");
+    return true;
+}
+
+static void vkd3d_opacity_micromap_end_barrier(struct d3d12_command_list *list)
+{
+    /* We resolve the query in TRANSFER, but DXR expects UNORDERED_ACCESS. */
+    const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
+    VkDependencyInfo dep_info;
+    VkMemoryBarrier2 barrier;
+
+    memset(&barrier, 0, sizeof(barrier));
+    barrier.sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2;
+    barrier.srcStageMask = VK_PIPELINE_STAGE_2_COPY_BIT;
+    barrier.srcAccessMask = VK_ACCESS_2_TRANSFER_WRITE_BIT;
+    barrier.dstStageMask = VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT;
+
+    memset(&dep_info, 0, sizeof(dep_info));
+    dep_info.sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO;
+    dep_info.memoryBarrierCount = 1;
+    dep_info.pMemoryBarriers = &barrier;
+
+    VK_CALL(vkCmdPipelineBarrier2(list->cmd.vk_command_buffer, &dep_info));
+}
+
+static void vkd3d_opacity_micromap_write_postbuild_info(
+        struct d3d12_command_list *list,
+        const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC *desc,
+        VkDeviceSize desc_offset,
+        VkMicromapEXT vk_opacity_micromap)
+{
+    const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
+    const struct vkd3d_unique_resource *resource;
+    VkBuffer vk_buffer;
+    uint32_t offset;
+
+    resource = vkd3d_va_map_deref(&list->device->memory_allocator.va_map, desc->destBuffer);
+    if (!resource)
+    {
+        ERR("Invalid resource.\n");
+        return;
+    }
+
+    vk_buffer = resource->vk_buffer;
+    offset = desc->destBuffer - resource->va;
+    offset += desc_offset;
+
+    FIXME("Unsupported InfoType %u.\n", desc->infoType);
+    /* TODO: CURRENT_SIZE is something we cannot query in Vulkan, so
+        * we'll need to keep around a buffer to handle this.
+        * For now, just clear to 0. */
+    VK_CALL(vkCmdFillBuffer(list->cmd.vk_command_buffer, vk_buffer, offset,
+            sizeof(uint64_t), 0));
+}
+
+void vkd3d_opacity_micromap_emit_postbuild_info_nv(
+        struct d3d12_command_list *list,
+        const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC *desc,
+        uint32_t count,
+        const D3D12_GPU_VIRTUAL_ADDRESS *addresses)
+{
+    const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
+    VkMicromapEXT vk_opacity_micromap;
+    VkDependencyInfo dep_info;
+    VkMemoryBarrier2 barrier;
+    uint32_t i;
+
+    /* We resolve the query in TRANSFER, but DXR expects UNORDERED_ACCESS. */
+    memset(&barrier, 0, sizeof(barrier));
+    barrier.sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2;
+    barrier.srcStageMask = VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT;
+    barrier.dstStageMask = VK_PIPELINE_STAGE_2_COPY_BIT;
+    barrier.dstAccessMask = VK_ACCESS_2_TRANSFER_WRITE_BIT;
+
+    memset(&dep_info, 0, sizeof(dep_info));
+    dep_info.sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO;
+    dep_info.memoryBarrierCount = 1;
+    dep_info.pMemoryBarriers = &barrier;
+
+    VK_CALL(vkCmdPipelineBarrier2(list->cmd.vk_command_buffer, &dep_info));
+
+    for (i = 0; i < count; i++)
+    {
+        vk_opacity_micromap = vkd3d_va_map_place_opacity_micromap(
+                &list->device->memory_allocator.va_map, list->device, addresses[i]);
+        if (vk_opacity_micromap)
+            vkd3d_opacity_micromap_write_postbuild_info(list, desc, i * sizeof(uint64_t), vk_opacity_micromap);
+        else
+            ERR("Failed to query opacity micromap for VA 0x%"PRIx64".\n", addresses[i]);
+    }
+
+    vkd3d_opacity_micromap_end_barrier(list);
+}
+
+void vkd3d_opacity_micromap_emit_immediate_postbuild_info_nv(
+        struct d3d12_command_list *list, uint32_t count,
+        const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC *desc,
+        VkMicromapEXT vk_opacity_micromap)
+{
+    /* In D3D12 we are supposed to be able to emit without an explicit barrier,
+     * but we need to emit them for Vulkan. */
+
+    const struct vkd3d_vk_device_procs *vk_procs = &list->device->vk_procs;
+    VkDependencyInfo dep_info;
+    VkMemoryBarrier2 barrier;
+    uint32_t i;
+
+    memset(&barrier, 0, sizeof(barrier));
+    barrier.sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2;
+    barrier.srcStageMask = VK_PIPELINE_STAGE_2_ALL_COMMANDS_BIT;
+    barrier.srcAccessMask = VK_ACCESS_2_MICROMAP_WRITE_BIT_EXT;
+    /* The query accesses STRUCTURE_READ_BIT in BUILD_BIT stage. */
+    barrier.dstStageMask = VK_PIPELINE_STAGE_2_MICROMAP_BUILD_BIT_EXT | VK_PIPELINE_STAGE_2_COPY_BIT;
+    barrier.dstAccessMask = VK_ACCESS_2_MICROMAP_READ_BIT_EXT | VK_ACCESS_2_TRANSFER_WRITE_BIT;
+
+    memset(&dep_info, 0, sizeof(dep_info));
+    dep_info.sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO;
+    dep_info.memoryBarrierCount = 1;
+    dep_info.pMemoryBarriers = &barrier;
+
+    VK_CALL(vkCmdPipelineBarrier2(list->cmd.vk_command_buffer, &dep_info));
+
+    for (i = 0; i < count; i++)
+        vkd3d_opacity_micromap_write_postbuild_info(list, &desc[i], 0, vk_opacity_micromap);
+
+    vkd3d_opacity_micromap_end_barrier(list);
+}
diff --git a/libs/vkd3d/raytracing_pipeline.c b/libs/vkd3d/raytracing_pipeline.c
index 52202d2d..94ae4b84 100644
--- a/libs/vkd3d/raytracing_pipeline.c
+++ b/libs/vkd3d/raytracing_pipeline.c
@@ -2655,6 +2655,8 @@ static HRESULT d3d12_state_object_compile_pipeline_variant(struct d3d12_state_ob
     if (object->pipeline_config.Flags & D3D12_RAYTRACING_PIPELINE_FLAG_SKIP_PROCEDURAL_PRIMITIVES)
         pipeline_create_info.flags |= VK_PIPELINE_CREATE_RAY_TRACING_SKIP_AABBS_BIT_KHR;
 
+    pipeline_create_info.flags |= object->device->global_ray_tracing_pipeline_create_flags;
+
     library_info.sType = VK_STRUCTURE_TYPE_PIPELINE_LIBRARY_CREATE_INFO_KHR;
     library_info.pNext = NULL;
     library_info.libraryCount = data->vk_libraries_count;
diff --git a/libs/vkd3d/resource.c b/libs/vkd3d/resource.c
index 6c9a0057..4bf454a1 100644
--- a/libs/vkd3d/resource.c
+++ b/libs/vkd3d/resource.c
@@ -189,6 +189,14 @@ HRESULT vkd3d_create_buffer(struct d3d12_device *device,
         /* This is always allowed. Used for vertex/index buffer inputs to RTAS build. */
         buffer_info.usage |= VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_BUILD_INPUT_READ_ONLY_BIT_KHR |
                 VK_BUFFER_USAGE_SHADER_BINDING_TABLE_BIT_KHR;
+
+        if (device->device_info.opacity_micromap_features.micromap)
+        {
+            if (heap_type == D3D12_HEAP_TYPE_DEFAULT || !is_cpu_accessible_heap(heap_properties))
+                buffer_info.usage |= VK_BUFFER_USAGE_MICROMAP_STORAGE_BIT_EXT;
+
+            buffer_info.usage |= VK_BUFFER_USAGE_MICROMAP_BUILD_INPUT_READ_ONLY_BIT_EXT;
+        }
     }
 
     if (heap_type == D3D12_HEAP_TYPE_UPLOAD)
@@ -1022,6 +1030,7 @@ static uint32_t vkd3d_view_entry_hash(const void *key)
     {
         case VKD3D_VIEW_TYPE_BUFFER:
         case VKD3D_VIEW_TYPE_ACCELERATION_STRUCTURE:
+        case VKD3D_VIEW_TYPE_OPACITY_MICROMAP:
             hash = hash_uint64((uint64_t)k->u.buffer.buffer);
             hash = hash_combine(hash, hash_uint64(k->u.buffer.offset));
             hash = hash_combine(hash, hash_uint64(k->u.buffer.size));
@@ -1087,6 +1096,7 @@ static bool vkd3d_view_entry_compare(const void *key, const struct hash_map_entr
     {
         case VKD3D_VIEW_TYPE_BUFFER:
         case VKD3D_VIEW_TYPE_ACCELERATION_STRUCTURE:
+        case VKD3D_VIEW_TYPE_OPACITY_MICROMAP:
             return k->u.buffer.buffer == e->key.u.buffer.buffer &&
                     k->u.buffer.format == e->key.u.buffer.format &&
                     k->u.buffer.offset == e->key.u.buffer.offset &&
@@ -1238,6 +1248,10 @@ struct vkd3d_view *vkd3d_view_map_create_view(struct vkd3d_view_map *view_map,
             success = vkd3d_create_acceleration_structure_view(device, &key->u.buffer, &view);
             break;
 
+        case VKD3D_VIEW_TYPE_OPACITY_MICROMAP:
+            success = vkd3d_create_opacity_micromap_view(device, &key->u.buffer, &view);
+            break;
+
         default:
             ERR("Unsupported view type %u.\n", key->view_type);
             success = false;
@@ -3818,6 +3832,9 @@ static void vkd3d_view_destroy(struct vkd3d_view *view, struct d3d12_device *dev
         case VKD3D_VIEW_TYPE_ACCELERATION_STRUCTURE:
             VK_CALL(vkDestroyAccelerationStructureKHR(device->vk_device, view->vk_acceleration_structure, NULL));
             break;
+        case VKD3D_VIEW_TYPE_OPACITY_MICROMAP:
+            VK_CALL(vkDestroyMicromapEXT(device->vk_device, view->vk_micromap, NULL));
+            break;
         default:
             WARN("Unhandled view type %d.\n", view->type);
     }
@@ -4163,6 +4180,42 @@ bool vkd3d_create_acceleration_structure_view(struct d3d12_device *device, const
     return true;
 }
 
+bool vkd3d_create_opacity_micromap_view(struct d3d12_device *device, const struct vkd3d_buffer_view_desc *desc,
+        struct vkd3d_view **view)
+{
+    const struct vkd3d_vk_device_procs *vk_procs = &device->vk_procs;
+    VkMicromapCreateInfoEXT create_info;
+    VkMicromapEXT vk_micromap;
+    struct vkd3d_view *object;
+    VkResult vr;
+
+    create_info.sType = VK_STRUCTURE_TYPE_MICROMAP_CREATE_INFO_EXT;
+    create_info.pNext = NULL;
+    create_info.type = VK_MICROMAP_TYPE_OPACITY_MICROMAP_EXT;
+    create_info.createFlags = 0;
+    create_info.deviceAddress = 0;
+    create_info.buffer = desc->buffer;
+    create_info.offset = desc->offset;
+    create_info.size = desc->size;
+
+    vr = VK_CALL(vkCreateMicromapEXT(device->vk_device, &create_info, NULL, &vk_micromap));
+    if (vr != VK_SUCCESS)
+        return false;
+
+    if (!(object = vkd3d_view_create(VKD3D_VIEW_TYPE_OPACITY_MICROMAP)))
+    {
+        VK_CALL(vkDestroyMicromapEXT(device->vk_device, vk_micromap, NULL));
+        return false;
+    }
+
+    object->vk_micromap = vk_micromap;
+    object->format = desc->format;
+    object->info.buffer.offset = desc->offset;
+    object->info.buffer.size = desc->size;
+    *view = object;
+    return true;
+}
+
 #define VKD3D_VIEW_RAW_BUFFER 0x1
 
 static void vkd3d_get_metadata_buffer_view_for_resource(struct d3d12_device *device,
@@ -8486,6 +8539,13 @@ HRESULT vkd3d_memory_info_init(struct vkd3d_memory_info *info,
                 VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_STORAGE_BIT_KHR |
                 VK_BUFFER_USAGE_SHADER_BINDING_TABLE_BIT_KHR |
                 VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_BUILD_INPUT_READ_ONLY_BIT_KHR;
+
+        if (device->device_info.opacity_micromap_features.micromap)
+        {
+            buffer_info.usage |=
+                    VK_BUFFER_USAGE_MICROMAP_STORAGE_BIT_EXT |
+                    VK_BUFFER_USAGE_MICROMAP_BUILD_INPUT_READ_ONLY_BIT_EXT;
+        }
     }
 
     VK_CALL(vkGetDeviceBufferMemoryRequirements(device->vk_device, &buffer_requirement_info, &memory_requirements));
diff --git a/libs/vkd3d/va_map.c b/libs/vkd3d/va_map.c
index 56b99852..5ba71449 100644
--- a/libs/vkd3d/va_map.c
+++ b/libs/vkd3d/va_map.c
@@ -300,6 +300,55 @@ VkAccelerationStructureKHR vkd3d_va_map_place_acceleration_structure(struct vkd3
     return view->vk_acceleration_structure;
 }
 
+VkMicromapEXT vkd3d_va_map_place_opacity_micromap(struct vkd3d_va_map *va_map,
+        struct d3d12_device *device,
+        VkDeviceAddress va)
+{
+    struct vkd3d_unique_resource *resource;
+    struct vkd3d_view_map *old_view_map;
+    struct vkd3d_view_map *view_map;
+    const struct vkd3d_view *view;
+    struct vkd3d_view_key key;
+
+    resource = vkd3d_va_map_deref_mutable(va_map, va);
+    if (!resource || !resource->va)
+        return VK_NULL_HANDLE;
+
+    view_map = vkd3d_atomic_ptr_load_explicit(&resource->view_map, vkd3d_memory_order_acquire);
+    if (!view_map)
+    {
+        view_map = vkd3d_malloc(sizeof(*view_map));
+        if (!view_map)
+            return VK_NULL_HANDLE;
+
+        if (FAILED(vkd3d_view_map_init(view_map)))
+        {
+            vkd3d_free(view_map);
+            return VK_NULL_HANDLE;
+        }
+
+        old_view_map = vkd3d_atomic_ptr_compare_exchange(&resource->view_map, NULL, view_map,
+                vkd3d_memory_order_release, vkd3d_memory_order_acquire);
+        if (old_view_map)
+        {
+            vkd3d_view_map_destroy(view_map, device);
+            vkd3d_free(view_map);
+            view_map = old_view_map;
+        }
+    }
+
+    key.view_type = VKD3D_VIEW_TYPE_OPACITY_MICROMAP;
+    key.u.buffer.buffer = resource->vk_buffer;
+    key.u.buffer.offset = va - resource->va;
+    key.u.buffer.size = resource->size - key.u.buffer.offset;
+    key.u.buffer.format = NULL;
+
+    view = vkd3d_view_map_create_view(view_map, device, &key);
+    if (!view)
+        return VK_NULL_HANDLE;
+    return view->vk_micromap;
+}
+
 void vkd3d_va_map_init(struct vkd3d_va_map *va_map)
 {
     memset(va_map, 0, sizeof(*va_map));
diff --git a/libs/vkd3d/vkd3d_private.h b/libs/vkd3d/vkd3d_private.h
index 24c35181..c5bd8573 100644
--- a/libs/vkd3d/vkd3d_private.h
+++ b/libs/vkd3d/vkd3d_private.h
@@ -42,6 +42,7 @@
 #include "vkd3d_file_utils.h"
 #include "vkd3d_native_sync_handle.h"
 #include "copy_utils.h"
+#include "nvapi.h"
 #include <assert.h>
 #include <inttypes.h>
 #include <limits.h>
@@ -153,6 +154,7 @@ struct vkd3d_vulkan_info
     bool EXT_dynamic_rendering_unused_attachments;
     bool EXT_line_rasterization;
     bool EXT_image_compression_control;
+    bool EXT_opacity_micromap;
     /* AMD device extensions */
     bool AMD_buffer_marker;
     bool AMD_device_coherent_memory;
@@ -288,6 +290,9 @@ const struct vkd3d_unique_resource *vkd3d_va_map_deref(struct vkd3d_va_map *va_m
 VkAccelerationStructureKHR vkd3d_va_map_place_acceleration_structure(struct vkd3d_va_map *va_map,
         struct d3d12_device *device,
         VkDeviceAddress va);
+VkMicromapEXT vkd3d_va_map_place_opacity_micromap(struct vkd3d_va_map *va_map,
+        struct d3d12_device *device,
+        VkDeviceAddress va);
 void vkd3d_va_map_init(struct vkd3d_va_map *va_map);
 void vkd3d_va_map_cleanup(struct vkd3d_va_map *va_map);
 
@@ -1081,7 +1086,8 @@ enum vkd3d_view_type
     VKD3D_VIEW_TYPE_BUFFER,
     VKD3D_VIEW_TYPE_IMAGE,
     VKD3D_VIEW_TYPE_SAMPLER,
-    VKD3D_VIEW_TYPE_ACCELERATION_STRUCTURE
+    VKD3D_VIEW_TYPE_ACCELERATION_STRUCTURE,
+    VKD3D_VIEW_TYPE_OPACITY_MICROMAP
 };
 
 struct vkd3d_view
@@ -1096,6 +1102,7 @@ struct vkd3d_view
         VkImageView vk_image_view;
         VkSampler vk_sampler;
         VkAccelerationStructureKHR vk_acceleration_structure;
+        VkMicromapEXT vk_micromap;
     };
     const struct vkd3d_format *format;
     union
@@ -1152,6 +1159,8 @@ bool vkd3d_create_raw_r32ui_vk_buffer_view(struct d3d12_device *device,
         VkBuffer vk_buffer, VkDeviceSize offset, VkDeviceSize range, VkBufferView *vk_view);
 bool vkd3d_create_acceleration_structure_view(struct d3d12_device *device,
         const struct vkd3d_buffer_view_desc *desc, struct vkd3d_view **view);
+bool vkd3d_create_opacity_micromap_view(struct d3d12_device *device,
+        const struct vkd3d_buffer_view_desc *desc, struct vkd3d_view **view);
 bool vkd3d_create_texture_view(struct d3d12_device *device,
         const struct vkd3d_texture_view_desc *desc, struct vkd3d_view **view);
 
@@ -2553,7 +2562,7 @@ struct vkd3d_rendering_info
 };
 
 /* ID3D12CommandListExt */
-typedef ID3D12GraphicsCommandListExt1 d3d12_command_list_vkd3d_ext_iface;
+typedef ID3D12GraphicsCommandListExt2 d3d12_command_list_vkd3d_ext_iface;
 
 struct d3d12_state_object;
 
@@ -2662,6 +2671,9 @@ struct d3d12_rtas_batch_state
     size_t geometry_info_count;
     size_t geometry_info_size;
 
+    VkAccelerationStructureTrianglesOpacityMicromapEXT *omm_infos;
+    size_t omm_info_size;
+
     VkAccelerationStructureBuildRangeInfoKHR *range_infos;
     size_t range_info_size;
 
@@ -2855,6 +2867,14 @@ HRESULT d3d12_command_list_create(struct d3d12_device *device,
         UINT node_mask, D3D12_COMMAND_LIST_TYPE type, struct d3d12_command_list **list);
 bool d3d12_command_list_reset_query(struct d3d12_command_list *list,
         VkQueryPool vk_pool, uint32_t index);
+void d3d12_command_list_end_current_render_pass(struct d3d12_command_list *list, bool suspend);
+void d3d12_command_list_end_transfer_batch(struct d3d12_command_list *list);
+bool d3d12_command_list_allocate_rtas_build_info(struct d3d12_command_list *list, uint32_t geometry_count,
+        VkAccelerationStructureBuildGeometryInfoKHR **build_info,
+        VkAccelerationStructureGeometryKHR **geometry_infos,
+        VkAccelerationStructureTrianglesOpacityMicromapEXT **omm_infos,
+        VkAccelerationStructureBuildRangeInfoKHR **range_infos);
+void d3d12_command_list_flush_rtas_batch(struct d3d12_command_list *list);
 
 static inline struct vkd3d_pipeline_bindings *d3d12_command_list_get_bindings(
         struct d3d12_command_list *list, enum vkd3d_pipeline_type pipeline_type)
@@ -3275,6 +3295,8 @@ enum vkd3d_breadcrumb_command_type
     VKD3D_BREADCRUMB_COMMAND_BUILD_RTAS,
     VKD3D_BREADCRUMB_COMMAND_COPY_RTAS,
     VKD3D_BREADCRUMB_COMMAND_EMIT_RTAS_POSTBUILD,
+    VKD3D_BREADCRUMB_COMMAND_BUILD_OMM,
+    VKD3D_BREADCRUMB_COMMAND_EMIT_OMM_POSTBUILD,
     VKD3D_BREADCRUMB_COMMAND_TRACE_RAYS,
     VKD3D_BREADCRUMB_COMMAND_BARRIER,
     VKD3D_BREADCRUMB_COMMAND_AUX32, /* Used to report arbitrary 32-bit words as arguments to other commands. */
@@ -4300,6 +4322,7 @@ struct vkd3d_physical_device_info
     VkPhysicalDeviceMaintenance5FeaturesKHR maintenance_5_features;
     VkPhysicalDeviceLineRasterizationFeaturesEXT line_rasterization_features;
     VkPhysicalDeviceImageCompressionControlFeaturesEXT image_compression_control_features;
+    VkPhysicalDeviceOpacityMicromapFeaturesEXT opacity_micromap_features;
 
     VkPhysicalDeviceFeatures2 features2;
 
@@ -4376,7 +4399,7 @@ struct vkd3d_descriptor_qa_global_info;
 struct vkd3d_descriptor_qa_heap_buffer_data;
 
 /* ID3D12DeviceExt */
-typedef ID3D12DeviceExt d3d12_device_vkd3d_ext_iface;
+typedef ID3D12DeviceExt1 d3d12_device_vkd3d_ext_iface;
 
 /* ID3D12DXVKInteropDevice */
 typedef ID3D12DXVKInteropDevice d3d12_dxvk_interop_device_iface;
@@ -4465,6 +4488,7 @@ struct d3d12_device

     struct vkd3d_device_swapchain_info swapchain_info;
     struct vkd3d_device_frame_markers frame_markers;
+    VkPipelineCreateFlags global_ray_tracing_pipeline_create_flags;
 };
 
 HRESULT d3d12_device_create(struct vkd3d_instance *instance,
@@ -5214,12 +5238,21 @@ struct vkd3d_view *vkd3d_view_map_create_view(struct vkd3d_view_map *view_map,
 
 uint32_t vkd3d_acceleration_structure_get_geometry_count(
         const D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS *desc);
+uint32_t vkd3d_acceleration_structure_get_geometry_count_nv(
+        const NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX *desc);
 bool vkd3d_acceleration_structure_convert_inputs(const struct d3d12_device *device,
         const D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS *desc,
         VkAccelerationStructureBuildGeometryInfoKHR *build_info,
         VkAccelerationStructureGeometryKHR *geometry_infos,
         VkAccelerationStructureBuildRangeInfoKHR *range_infos,
         uint32_t *primitive_counts);
+bool vkd3d_acceleration_structure_convert_inputs_nv(struct d3d12_device *device,
+        const NVAPI_D3D12_BUILD_RAYTRACING_ACCELERATION_STRUCTURE_INPUTS_EX *desc,
+        VkAccelerationStructureBuildGeometryInfoKHR *build_info,
+        VkAccelerationStructureGeometryKHR *geometry_infos,
+        VkAccelerationStructureTrianglesOpacityMicromapEXT *omm_infos,
+        VkAccelerationStructureBuildRangeInfoKHR *range_infos,
+        uint32_t *primitive_counts);
 void vkd3d_acceleration_structure_emit_postbuild_info(
         struct d3d12_command_list *list,
         const D3D12_RAYTRACING_ACCELERATION_STRUCTURE_POSTBUILD_INFO_DESC *desc,
@@ -5233,6 +5266,29 @@ void vkd3d_acceleration_structure_copy(
         D3D12_GPU_VIRTUAL_ADDRESS dst, D3D12_GPU_VIRTUAL_ADDRESS src,
         D3D12_RAYTRACING_ACCELERATION_STRUCTURE_COPY_MODE mode);
 
+/* Opacity micromap helpers. */
+struct vkd3d_opacity_micromap_build_info
+{
+    VkMicromapUsageEXT usages_stack[VKD3D_BUILD_INFO_STACK_COUNT];
+    VkMicromapBuildInfoEXT build_info;
+    VkMicromapUsageEXT *usages;
+};
+
+void vkd3d_opacity_micromap_build_info_cleanup(
+        struct vkd3d_opacity_micromap_build_info *info);
+bool vkd3d_opacity_micromap_convert_inputs_nv(const struct d3d12_device *device,
+        struct vkd3d_opacity_micromap_build_info *info,
+        const NVAPI_D3D12_BUILD_RAYTRACING_OPACITY_MICROMAP_ARRAY_INPUTS *desc);
+void vkd3d_opacity_micromap_emit_postbuild_info_nv(
+        struct d3d12_command_list *list,
+        const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC *desc,
+        uint32_t count,
+        const D3D12_GPU_VIRTUAL_ADDRESS *addresses);
+void vkd3d_opacity_micromap_emit_immediate_postbuild_info_nv(
+        struct d3d12_command_list *list, uint32_t count,
+        const NVAPI_D3D12_RAYTRACING_OPACITY_MICROMAP_ARRAY_POSTBUILD_INFO_DESC *desc,
+        VkMicromapEXT vk_opacity_micromap);
+
 typedef enum D3D11_USAGE
 {
     D3D11_USAGE_DEFAULT,
diff --git a/libs/vkd3d/vulkan_procs.h b/libs/vkd3d/vulkan_procs.h
index 6b32bca1..12cf7456 100644
--- a/libs/vkd3d/vulkan_procs.h
+++ b/libs/vkd3d/vulkan_procs.h
@@ -347,6 +347,12 @@ VK_DEVICE_EXT_PFN(vkSetDeviceMemoryPriorityEXT)
 VK_DEVICE_EXT_PFN(vkCmdDecompressMemoryNV)
 VK_DEVICE_EXT_PFN(vkCmdDecompressMemoryIndirectCountNV)
 
+/* VK_EXT_opacity_micromap */
+VK_DEVICE_EXT_PFN(vkGetMicromapBuildSizesEXT)
+VK_DEVICE_EXT_PFN(vkCreateMicromapEXT)
+VK_DEVICE_EXT_PFN(vkDestroyMicromapEXT)
+VK_DEVICE_EXT_PFN(vkCmdBuildMicromapsEXT)
+
 #undef VK_INSTANCE_PFN
 #undef VK_INSTANCE_EXT_PFN
 #undef VK_DEVICE_PFN
